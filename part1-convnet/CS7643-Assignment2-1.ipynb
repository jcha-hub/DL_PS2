{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MIkt4yxKpzgS"
   },
   "source": [
    "# CS 7643 Assignment 2 Part 1:  Implement and train a network on CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5eLeqVzpzgV"
   },
   "source": [
    "Convolutional Neural Networks (CNNs) are one of the major advancements in\n",
    "computer vision over the past decade. In this assignment, you will complete\n",
    "a simple CNN architecture from scratch and learn how to implement CNNs\n",
    "with PyTorch, one of the most commonly used deep learning frameworks.\n",
    "You will also run different experiments on imbalanced datasets to evaluate\n",
    "your model and techniques to deal with imbalanced data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kx3nM2xMpzgW"
   },
   "source": [
    "### Load Extensions\n",
    "Before getting started we need to run some standard code to set up our environment. You'll need to execute this code again each time you start the notebook.\n",
    "\n",
    "First, run this cell to load the [autoreload](https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html?highlight=autoreload) extension. This enables us to modify `.py` source files and reintegrate them into the notebook, ensuring a smooth editing and debugging experience.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "j22uun9OpzgX",
    "ExecuteTime": {
     "end_time": "2025-09-18T18:19:27.213702Z",
     "start_time": "2025-09-18T18:19:27.179245Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9pOTy-9dpzgY"
   },
   "source": [
    "### Google Colab Setup\n",
    "Next we need to run a few commands to set up our environment on Google Colab. If you are running this notebook on a local machine you can skip this section.\n",
    "\n",
    "Run the following cell to mount your Google Drive. Follow the link, sign in to your Google account (the same account you used to store this notebook!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zujgqHl3pzgZ"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAQYM7TWpzgZ"
   },
   "source": [
    "Now remember the path in your Google Drive where you uploaded this notebook, fill it in below. If all functions properly, executing the next cell should display the filenames from the assignment:\n",
    "\n",
    "```\n",
    "['CS7643-Assignment2-1.ipynb', 'cs7643', 'data', 'configs', 'models', 'optimizer', 'tests']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UiGZhhG8pzga",
    "ExecuteTime": {
     "end_time": "2025-09-17T20:51:55.569681Z",
     "start_time": "2025-09-17T20:51:55.394430Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "# TODO: Fill in the Google Drive path where you uploaded assignment1\n",
    "# Example: If you create a Fall2023 folder and put all the files under A1 folder, then 'Fall2023/A1'\n",
    "GOOGLE_DRIVE_PATH_POST_MYDRIVE = None\n",
    "GOOGLE_DRIVE_PATH = os.path.join('/content', 'drive', 'MyDrive', GOOGLE_DRIVE_PATH_POST_MYDRIVE)\n",
    "print(os.listdir(GOOGLE_DRIVE_PATH))"
   ],
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "join() argument must be str, bytes, or os.PathLike object, not 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 6\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# TODO: Fill in the Google Drive path where you uploaded assignment1\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Example: If you create a Fall2023 folder and put all the files under A1 folder, then 'Fall2023/A1'\u001B[39;00m\n\u001B[0;32m      5\u001B[0m GOOGLE_DRIVE_PATH_POST_MYDRIVE \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m GOOGLE_DRIVE_PATH \u001B[38;5;241m=\u001B[39m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/content\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdrive\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mMyDrive\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mGOOGLE_DRIVE_PATH_POST_MYDRIVE\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(os\u001B[38;5;241m.\u001B[39mlistdir(GOOGLE_DRIVE_PATH))\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\cs7643-a2\\Lib\\ntpath.py:149\u001B[0m, in \u001B[0;36mjoin\u001B[1;34m(path, *paths)\u001B[0m\n\u001B[0;32m    147\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result_drive \u001B[38;5;241m+\u001B[39m result_root \u001B[38;5;241m+\u001B[39m result_path\n\u001B[0;32m    148\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mAttributeError\u001B[39;00m, \u001B[38;5;167;01mBytesWarning\u001B[39;00m):\n\u001B[1;32m--> 149\u001B[0m     \u001B[43mgenericpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_arg_types\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mjoin\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpaths\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    150\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\cs7643-a2\\Lib\\genericpath.py:164\u001B[0m, in \u001B[0;36m_check_arg_types\u001B[1;34m(funcname, *args)\u001B[0m\n\u001B[0;32m    162\u001B[0m         hasbytes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    163\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 164\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfuncname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m() argument must be str, bytes, or \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    165\u001B[0m                         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mos.PathLike object, not \u001B[39m\u001B[38;5;132;01m{\u001B[39;00ms\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    166\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m hasstr \u001B[38;5;129;01mand\u001B[39;00m hasbytes:\n\u001B[0;32m    167\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCan\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt mix strings and bytes in path components\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mTypeError\u001B[0m: join() argument must be str, bytes, or os.PathLike object, not 'NoneType'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QeqHoG1Dpzga"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(GOOGLE_DRIVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TJAHYCutjXA4"
   },
   "source": [
    "### Local Setup OR Google Drive\n",
    "Run the cell below regardless of whether you are using google drive or local setup."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "N0TK4ozDjX8B",
    "ExecuteTime": {
     "end_time": "2025-09-18T18:19:32.561895Z",
     "start_time": "2025-09-18T18:19:31.849340Z"
    }
   },
   "source": [
    "# if running locally set GOOGLE PATH\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "  print(f'Running in google colab. Our path is `{GOOGLE_DRIVE_PATH}`')\n",
    "else:\n",
    "  GOOGLE_DRIVE_PATH = '.'\n",
    "  print('Running locally.')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C48GISpDpzga"
   },
   "source": [
    "After successfully identifying the path to this assignment, execute the following cell to enable us to import from the `.py` files of this assignment. If it works correctly, it should print the message:\n",
    "\n",
    "```\n",
    "Roger that from conv_classifier.py!\n",
    "Roger that from softmax_ce.py!\n",
    "Roger that from linear.py!\n",
    "Roger that from relu.py!\n",
    "Roger that from max_pool.py!\n",
    "Roger that from convolution.py!\n",
    "\n",
    "Roger that from _base_optimizer.py!\n",
    "Roger that from sgd.py!\n",
    "```\n",
    "\n",
    "as well as the last edit time for the files `_conv_classifier.py`, `convolution.py`, `linear.py`, `max_pool.py`, `relu.py`, `softmax_ce.py`, `_base_optimizer.py`, and `sgd.py`. You may have to try running the cell twice if the first time fails."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QeqHoG1Dpzga",
    "ExecuteTime": {
     "end_time": "2025-09-18T18:19:36.367572Z",
     "start_time": "2025-09-18T18:19:36.187163Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from cs7643.env_prob import say_hello_do_you_copy\n",
    "\n",
    "say_hello_do_you_copy(GOOGLE_DRIVE_PATH)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Modules ------------------\n",
      "Roger that from conv_classifier.py!\n",
      "Roger that from softmax_ce.py!\n",
      "Roger that from linear.py!\n",
      "Roger that from relu.py!\n",
      "Roger that from max_pool.py!\n",
      "Roger that from convolution.py!\n",
      "conv_classifier.py last edited on Mon Sep  8 20:15:29 2025\n",
      "softmax_ce.py last edited on Mon Sep  8 20:15:29 2025\n",
      "linear.py last edited on Wed Sep 17 18:25:51 2025\n",
      "relu.py last edited on Thu Sep 11 16:32:36 2025\n",
      "max_pool.py last edited on Mon Sep 15 17:54:03 2025\n",
      "convolution.py last edited on Thu Sep 18 14:18:58 2025\n",
      "\n",
      "---------- Optimizer ------------------\n",
      "Roger that from _base_optimizer.py!\n",
      "Roger that from sgd.py!\n",
      "_base_optimizer.py last edited on Mon Sep  8 20:15:29 2025\n",
      "sgd.py last edited on Mon Sep  8 20:15:29 2025\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9bM0Yujpzga"
   },
   "source": [
    "# Load the CIFAR10 dataset\n",
    "Data loading is the very first step of any machine learning pipelines. Run the following cell to download the CIFAR10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LrhqVZ9jpzgb",
    "ExecuteTime": {
     "end_time": "2025-09-18T18:19:39.920630Z",
     "start_time": "2025-09-18T18:19:38.499398Z"
    }
   },
   "source": [
    "from cs7643.cifar10 import CIFAR10\n",
    "\n",
    "train_ds = CIFAR10(GOOGLE_DRIVE_PATH + '/data/cifar10', download=True, train=True)\n",
    "test_ds = CIFAR10(GOOGLE_DRIVE_PATH + '/data/cifar10', download=True, train=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tgfHDh0pzgb"
   },
   "source": [
    "# Implementing CNN from Scratch\n",
    "You will work in `./part1-convnet` for this part of the assignment. **Note that\n",
    "vectorization is not a requirement for this part of the assignment**.\n",
    "\n",
    "## Module Implementation\n",
    "You will now learn how to build CNN from scratch. Typically, a convolutional\n",
    "neural network is composed of several different modules and these modules\n",
    "work together to make the network effective. For each module, you will\n",
    "implement a forward pass (computing forwarding results) and a backward\n",
    "pass (computing gradients). Therefore, your tasks are as follows:\n",
    "\n",
    "Follow the instructions in the code to complete each module in `./modules`. Specifically, modules to be implemented are 2D convolution, 2D\n",
    "Max Pooling, ReLU, and Linear. These will be the building blocks of\n",
    "the full network. The file `./modules/conv_classifier.py` ties each of the\n",
    "aforementioned modules together and is the subject of the next section. Run the following cells to test your implementations."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "X97MN9JvcMQY",
    "ExecuteTime": {
     "end_time": "2025-09-17T22:22:00.297906Z",
     "start_time": "2025-09-17T22:21:59.229269Z"
    }
   },
   "source": [
    "#Let's test your implementation of Linear\n",
    "!pytest -s {GOOGLE_DRIVE_PATH.replace(' ', '\\ ') + '/tests/test_linear.py'}"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:1: SyntaxWarning: invalid escape sequence '\\ '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m============================= test session starts =============================\u001B[0m\n",
      "platform win32 -- Python 3.12.0, pytest-8.4.1, pluggy-1.5.0\n",
      "rootdir: C:\\Users\\julie\\CSE_7643_DL\\DL_PS2\\part1-convnet\n",
      "plugins: anyio-4.7.0\n",
      "collected 2 items\n",
      "\n",
      "tests\\test_linear.py \u001B[32m.\u001B[0m\u001B[32m.\u001B[0m\n",
      "\n",
      "\u001B[32m============================== \u001B[32m\u001B[1m2 passed\u001B[0m\u001B[32m in 0.12s\u001B[0m\u001B[32m ==============================\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5PSgh7FpKERP",
    "ExecuteTime": {
     "end_time": "2025-09-17T22:22:06.957963Z",
     "start_time": "2025-09-17T22:22:06.167839Z"
    }
   },
   "source": [
    "#Let's test your implementation of Max Pooling\n",
    "!pytest -s {GOOGLE_DRIVE_PATH.replace(' ', '\\ ') + '/tests/test_maxpool.py'}"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:1: SyntaxWarning: invalid escape sequence '\\ '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m============================= test session starts =============================\u001B[0m\n",
      "platform win32 -- Python 3.12.0, pytest-8.4.1, pluggy-1.5.0\n",
      "rootdir: C:\\Users\\julie\\CSE_7643_DL\\DL_PS2\\part1-convnet\n",
      "plugins: anyio-4.7.0\n",
      "collected 2 items\n",
      "\n",
      "tests\\test_maxpool.py dx_num:  [[0.         0.        ]\n",
      " [0.         0.73032674]]\n",
      "\u001B[32m.\u001B[0m\u001B[32m.\u001B[0m\n",
      "\n",
      "\u001B[32m============================== \u001B[32m\u001B[1m2 passed\u001B[0m\u001B[32m in 0.29s\u001B[0m\u001B[32m ==============================\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Db0t0IChKK0h",
    "ExecuteTime": {
     "end_time": "2025-09-17T22:22:11.614155Z",
     "start_time": "2025-09-17T22:22:11.005536Z"
    }
   },
   "source": [
    "#Let's test your implementation of RELU\n",
    "!pytest -s {GOOGLE_DRIVE_PATH.replace(' ', '\\ ') + '/tests/test_relu.py'}"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:1: SyntaxWarning: invalid escape sequence '\\ '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m============================= test session starts =============================\u001B[0m\n",
      "platform win32 -- Python 3.12.0, pytest-8.4.1, pluggy-1.5.0\n",
      "rootdir: C:\\Users\\julie\\CSE_7643_DL\\DL_PS2\\part1-convnet\n",
      "plugins: anyio-4.7.0\n",
      "collected 2 items\n",
      "\n",
      "tests\\test_relu.py \u001B[32m.\u001B[0m\u001B[32m.\u001B[0m\n",
      "\n",
      "\u001B[32m============================== \u001B[32m\u001B[1m2 passed\u001B[0m\u001B[32m in 0.11s\u001B[0m\u001B[32m ==============================\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zaXbxcApKPNw",
    "ExecuteTime": {
     "end_time": "2025-09-18T18:58:41.269412Z",
     "start_time": "2025-09-18T18:58:39.807968Z"
    }
   },
   "source": [
    "#Let's test your implementation of Conv2D\n",
    "!pytest -s {GOOGLE_DRIVE_PATH.replace(' ', '\\ ') + '/tests/test_conv.py'}"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:1: SyntaxWarning: invalid escape sequence '\\ '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m============================= test session starts =============================\u001B[0m\n",
      "platform win32 -- Python 3.12.0, pytest-8.4.1, pluggy-1.5.0\n",
      "rootdir: C:\\Users\\julie\\CSE_7643_DL\\DL_PS2\\part1-convnet\n",
      "plugins: anyio-4.7.0\n",
      "collected 2 items\n",
      "\n",
      "tests\\test_conv.py dx (4, 3, 5, 5)\n",
      "\u001B[32m.\u001B[0m\u001B[32m.\u001B[0m\n",
      "\n",
      "\u001B[32m============================== \u001B[32m\u001B[1m2 passed\u001B[0m\u001B[32m in 0.82s\u001B[0m\u001B[32m ==============================\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D68rtzAZpzgc"
   },
   "source": [
    "## Network Implementation\n",
    "After finishing each module, it's time to put things together to form a real\n",
    "convolutional neural network.\n",
    "\n",
    "Follow the instructions in the code to complete a CNN network in `./modules/conv_classifier.py`. The network is constructed by a list of module definitions in order and should handle both forward and backward communication between modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vr0bG_Ecpzgd"
   },
   "source": [
    "# Optimizer\n",
    "You have implemented a simple SGD optimizer in assignment-1. In practice, it is common to use a momentum term in SGD for better convergence. Specifically, we introduce a new velocity term $v_t$ and the update rule is as follows:\n",
    "\n",
    "$$\n",
    "v_t = \\beta v_{t-1} - \\eta \\frac{\\partial L}{\\partial w} \\\\\n",
    "w = w + v_t\n",
    "$$\n",
    "\n",
    "where $\\beta$ denotes the momentum coefficient and $\\eta$ denotes the learning rate.\n",
    "\n",
    "Follow the instructions in the code to complete SGD with momentum\n",
    "in `./optimizer/sgd.py`. **Hint**: you will need to store and use the velocity\n",
    "from the previous iteration of SGD to compute the new gradient for\n",
    "the current iteration. Feel free to add member variable(s) to achieve\n",
    "this."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FUEYEuHBpzgd",
    "ExecuteTime": {
     "end_time": "2025-09-18T22:57:02.238560Z",
     "start_time": "2025-09-18T22:57:01.474823Z"
    }
   },
   "source": [
    "# Test your SGD implementation\n",
    "!pytest -s {GOOGLE_DRIVE_PATH.replace(' ', '\\ ') + '/tests/test_sgd.py'}"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:1: SyntaxWarning: invalid escape sequence '\\ '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m============================= test session starts =============================\u001B[0m\n",
      "platform win32 -- Python 3.12.0, pytest-8.4.1, pluggy-1.5.0\n",
      "rootdir: C:\\Users\\julie\\CSE_7643_DL\\DL_PS2\\part1-convnet\n",
      "plugins: anyio-4.7.0\n",
      "collected 1 item\n",
      "\n",
      "tests\\test_sgd.py \u001B[31mF\u001B[0m\n",
      "\n",
      "================================== FAILURES ===================================\n",
      "\u001B[31m\u001B[1m______________________________ TestSGD.test_sgd _______________________________\u001B[0m\n",
      "\n",
      "self = <tests.test_sgd.TestSGD testMethod=test_sgd>\n",
      "\n",
      "    \u001B[0m\u001B[94mdef\u001B[39;49;00m \u001B[92mtest_sgd\u001B[39;49;00m(\u001B[96mself\u001B[39;49;00m):\u001B[90m\u001B[39;49;00m\n",
      "        model_list = [\u001B[96mdict\u001B[39;49;00m(\u001B[96mtype\u001B[39;49;00m=\u001B[33m'\u001B[39;49;00m\u001B[33mLinear\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m, in_dim=\u001B[94m128\u001B[39;49;00m, out_dim=\u001B[94m10\u001B[39;49;00m)]\u001B[90m\u001B[39;49;00m\n",
      "        criterion = \u001B[96mdict\u001B[39;49;00m(\u001B[96mtype\u001B[39;49;00m=\u001B[33m'\u001B[39;49;00m\u001B[33mSoftmaxCrossEntropy\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m)\u001B[90m\u001B[39;49;00m\n",
      "        model = ConvNet(model_list, criterion)\u001B[90m\u001B[39;49;00m\n",
      "    \u001B[90m\u001B[39;49;00m\n",
      "        optimizer = SGD(model)\u001B[90m\u001B[39;49;00m\n",
      "    \u001B[90m\u001B[39;49;00m\n",
      "        \u001B[90m# forward once\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "        np.random.seed(\u001B[94m1024\u001B[39;49;00m)\u001B[90m\u001B[39;49;00m\n",
      "        x = np.random.randn(\u001B[94m32\u001B[39;49;00m, \u001B[94m128\u001B[39;49;00m)\u001B[90m\u001B[39;49;00m\n",
      "        np.random.seed(\u001B[94m1024\u001B[39;49;00m)\u001B[90m\u001B[39;49;00m\n",
      "        y = np.random.randint(\u001B[94m10\u001B[39;49;00m, size=\u001B[94m32\u001B[39;49;00m)\u001B[90m\u001B[39;49;00m\n",
      "        tmp = model.forward(x, y)\u001B[90m\u001B[39;49;00m\n",
      ">       model.backward()\u001B[90m\u001B[39;49;00m\n",
      "\n",
      "\u001B[1m\u001B[31mtests\\test_sgd.py\u001B[0m:51: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001B[1m\u001B[31mmodules\\conv_classifier.py\u001B[0m:139: in backward\n",
      "    \u001B[0mm.backward(dout)\u001B[90m\u001B[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "self = <modules.linear.Linear object at 0x0000023F4978BDD0>, dout = None\n",
      "\n",
      "    \u001B[0m\u001B[94mdef\u001B[39;49;00m \u001B[92mbackward\u001B[39;49;00m(\u001B[96mself\u001B[39;49;00m, dout):\u001B[90m\u001B[39;49;00m\n",
      "    \u001B[90m    \u001B[39;49;00m\u001B[33m\"\"\"\u001B[39;49;00m\n",
      "    \u001B[33m    Computes the backward pass of linear layer\u001B[39;49;00m\n",
      "    \u001B[33m    :param dout: Upstream gradients, (N, self.out_dim)\u001B[39;49;00m\n",
      "    \u001B[33m    :return: nothing but dx, dw, and db of self should be updated\u001B[39;49;00m\n",
      "    \u001B[33m    \"\"\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "        x = \u001B[96mself\u001B[39;49;00m.cache\u001B[90m\u001B[39;49;00m\n",
      "    \u001B[90m\u001B[39;49;00m\n",
      "        \u001B[90m#############################################################################\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "        \u001B[90m# TODO: Implement the linear backward pass.                                 #\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "        \u001B[90m#############################################################################\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "        w = \u001B[96mself\u001B[39;49;00m.weight\u001B[90m\u001B[39;49;00m\n",
      "        b = \u001B[96mself\u001B[39;49;00m.bias\u001B[90m\u001B[39;49;00m\n",
      "    \u001B[90m\u001B[39;49;00m\n",
      "        out = np.dot(x, w) + b\u001B[90m\u001B[39;49;00m\n",
      "    \u001B[90m\u001B[39;49;00m\n",
      "        \u001B[90m# #input shapes\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "        \u001B[90m# print('x', x.shape)         #x(10, 6)\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "        \u001B[90m# print('w', w.shape)         #w(6, 5)\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "        \u001B[90m# print('b', b.shape)         #b(5, )\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "        \u001B[90m# print('out', out.shape)     #out(10, 5)\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "    \u001B[90m\u001B[39;49;00m\n",
      "        dout_dw = x.T\u001B[90m\u001B[39;49;00m\n",
      "        dout_dx = w.T\u001B[90m\u001B[39;49;00m\n",
      "    \u001B[90m\u001B[39;49;00m\n",
      ">       dw = np.dot(dout_dw, dout)              \u001B[90m# must be (6,5) -> (6,10) (10,5)\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31mE       TypeError: unsupported operand type(s) for *: 'float' and 'NoneType'\u001B[0m\n",
      "\n",
      "\u001B[1m\u001B[31mmodules\\linear.py\u001B[0m:101: TypeError\n",
      "\u001B[36m\u001B[1m=========================== short test summary info ===========================\u001B[0m\n",
      "\u001B[31mFAILED\u001B[0m tests/test_sgd.py::\u001B[1mTestSGD::test_sgd\u001B[0m - TypeError: unsupported operand type(s) for *: 'float' and 'NoneType'\n",
      "\u001B[31m============================== \u001B[31m\u001B[1m1 failed\u001B[0m\u001B[31m in 0.18s\u001B[0m\u001B[31m ==============================\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P77ODmqHpzgd"
   },
   "source": [
    "# Experiments\n",
    "Now, you have completed coding the entire training process. It’s time to play with your model a little. If you're already attempted to train your implementation, you might have noticed that it is extremely slow. Therefore, we only want to deliberately overfit the model with a small portion of data to verify whether the model is learning something or not.\n",
    "\n",
    "You will train a small CNN with only 50 samples in CIFAR-10 dataset. The script will make a plot on the training data only and **be sure to include the plot in your report**. Your final accuracy should be slightly under `0.9` with the given network in the script. To start the training, execute the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OXlEUeySNIoq"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from modules import ConvNet\n",
    "from optimizer import SGD\n",
    "from cs7643.solver import Solver\n",
    "from data import get_CIFAR10_data\n",
    "\n",
    "root = GOOGLE_DRIVE_PATH + '/data/cifar10/cifar-10-batches-py'\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_CIFAR10_data(root)\n",
    "\n",
    "print(f'Number of training samples {len(X_train)}')\n",
    "\n",
    "model_list = [dict(type='Conv2D', in_channels=3, out_channels=32, kernel_size=5, stride=1, padding=2),\n",
    "              dict(type='ReLU'),\n",
    "              dict(type='MaxPooling', kernel_size=2, stride=2),\n",
    "              dict(type='Linear', in_dim=8192, out_dim=10)]\n",
    "criterion = dict(type='SoftmaxCrossEntropy')\n",
    "model = ConvNet(model_list, criterion)\n",
    "optimizer = SGD(model, learning_rate=0.0001, reg=0.001, momentum=0.9)\n",
    "\n",
    "trainer = Solver()\n",
    "\n",
    "loss_history, train_acc_history = trainer.train(\n",
    "    X_train[:50], y_train[:50], model, batch_size=10, num_epochs=10,\n",
    "    verbose=True, optimizer=optimizer\n",
    "    )\n",
    "\n",
    "plt.plot(train_acc_history)\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.savefig(GOOGLE_DRIVE_PATH + '/train.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjZK5lqLFsor"
   },
   "source": [
    "# Submit Your Work\n",
    "After completing the notebook for this assignment (`assignment2_1.ipynb`), run the following cell to create a `.zip` file for you to download and to upload to Gradescope.\n",
    "\n",
    "**Please MANUALLY SAVE `*.py` files before executing the following cell:**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uPREUKv7FwPS",
    "ExecuteTime": {
     "end_time": "2025-09-18T18:58:48.791948Z",
     "start_time": "2025-09-18T18:58:48.742872Z"
    }
   },
   "source": [
    "from cs7643.submit import make_a2_1_submission\n",
    "\n",
    "make_a2_1_submission(GOOGLE_DRIVE_PATH)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing zip file to:  .\\assignment_2_1_submission.zip\n"
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
