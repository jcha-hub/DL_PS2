{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-16T23:47:10.491674Z",
     "start_time": "2025-09-16T23:47:10.486457Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import math"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T19:15:01.312672Z",
     "start_time": "2025-09-11T19:15:01.294711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def hello_do_you_copy():\n",
    "    \"\"\"\n",
    "    This is a sample function that we will try to import and run to ensure that\n",
    "    our environment is correctly set up on Google Colab.\n",
    "    \"\"\"\n",
    "    print(\"Roger that from relu.py!\")\n",
    "\n",
    "class ReLU:\n",
    "    \"\"\"\n",
    "    An implementation of rectified linear units(ReLU)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.cache = None\n",
    "        self.dx = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        The forward pass of ReLU. Save necessary variables for backward\n",
    "        :param x: input data\n",
    "        :return: output of the ReLU function\n",
    "        '''\n",
    "        out = np.maximum(0, x)\n",
    "        #############################################################################\n",
    "        # TODO: Implement the ReLU forward pass.                                    #\n",
    "        #############################################################################\n",
    "\n",
    "        #############################################################################\n",
    "        #                              END OF YOUR CODE                             #\n",
    "        #############################################################################\n",
    "        self.cache = x\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        \"\"\"\n",
    "        :param dout: the upstream gradients\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        dx, x = None, self.cache\n",
    "\n",
    "        dx = np.greater(x, 0).astype(int)\n",
    "        dx = dx*dout  #unsure on order\n",
    "        #############################################################################\n",
    "        # TODO: Implement the ReLU backward pass.                                   #\n",
    "        #############################################################################\n",
    "\n",
    "        #############################################################################\n",
    "        #                              END OF YOUR CODE                             #\n",
    "        #############################################################################\n",
    "        self.dx = dx\n",
    "\n",
    "\n",
    "def rel_error(x, y):\n",
    "    \"\"\" returns relative error \"\"\"\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
    "\n",
    "\n",
    "def eval_numerical_gradient(f, x, verbose=True, h=0.00001):\n",
    "    \"\"\"\n",
    "    a naive implementation of numerical gradient of f at x\n",
    "    - f should be a function that takes a single argument\n",
    "    - x is the point (numpy array) to evaluate the gradient at\n",
    "    \"\"\"\n",
    "\n",
    "    fx = f(x)  # evaluate function value at original point\n",
    "    grad = np.zeros_like(x)\n",
    "    # iterate over all indexes in x\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "\n",
    "        # evaluate function at x+h\n",
    "        ix = it.multi_index\n",
    "        oldval = x[ix]\n",
    "        x[ix] = oldval + h  # increment by h\n",
    "        fxph = f(x)  # evalute f(x + h)\n",
    "        x[ix] = oldval - h\n",
    "        fxmh = f(x)  # evaluate f(x - h)\n",
    "        x[ix] = oldval  # restore\n",
    "\n",
    "        # compute the partial derivative with centered formula\n",
    "        grad[ix] = (fxph - fxmh) / (2 * h)  # the slope\n",
    "        if verbose:\n",
    "            print(ix, grad[ix])\n",
    "        it.iternext()  # step to next dimension\n",
    "\n",
    "    return grad\n",
    "\n",
    "\n",
    "def eval_numerical_gradient_array(f, x, df, h=1e-5):\n",
    "    \"\"\"\n",
    "    Evaluate a numeric gradient for a function that accepts a numpy\n",
    "    array and returns a numpy array.\n",
    "    \"\"\"\n",
    "    grad = np.zeros_like(x)\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        ix = it.multi_index\n",
    "\n",
    "        oldval = x[ix]\n",
    "        x[ix] = oldval + h\n",
    "        pos = f(x)\n",
    "        x[ix] = oldval - h\n",
    "        neg = f(x)\n",
    "        x[ix] = oldval\n",
    "\n",
    "        grad[ix] = np.sum((pos - neg) * df) / (2 * h)\n",
    "        it.iternext()\n",
    "    return grad"
   ],
   "id": "f3a320ac97d79f92",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T19:43:17.961659Z",
     "start_time": "2025-09-11T19:43:17.950659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "#check ReLU\n",
    "\n",
    "def _relu_forward(x):\n",
    "    relu = ReLU()\n",
    "    return relu.forward(x)\n",
    "\n",
    "def test_forward():\n",
    "    x = np.linspace(-0.5, 0.5, num=12).reshape(3, 4)\n",
    "    relu = ReLU()\n",
    "    out = relu.forward(x)\n",
    "    correct_out = np.array([[0., 0., 0., 0., ],\n",
    "                            [0., 0., 0.04545455, 0.13636364, ],\n",
    "                            [0.22727273, 0.31818182, 0.40909091, 0.5, ]])\n",
    "    diff = rel_error(out, correct_out)\n",
    "    print(diff)\n",
    "\n",
    "def test_backward():\n",
    "    x = np.random.randn(10, 10)\n",
    "    dout = np.random.randn(*x.shape)\n",
    "\n",
    "    dx_num = eval_numerical_gradient_array(lambda x: _relu_forward(x), x, dout)\n",
    "\n",
    "    relu = ReLU()\n",
    "    out = relu.forward(x)\n",
    "    relu.backward(dout)\n",
    "    dx = relu.dx\n",
    "\n",
    "    print(\"dx_num shape: \", dx_num.shape, 'dx shape: ', dx.shape, \"out shape\", out.shape)\n",
    "    print(out)\n",
    "    print(dx_num)\n",
    "\n",
    "test_backward()"
   ],
   "id": "5044e6448dda06aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dx_num shape:  (10, 10) dx shape:  (10, 10) out shape (10, 10)\n",
      "[[0.         0.         0.         0.48935178 1.16253407 0.29912946\n",
      "  0.86840123 0.26602623 0.         0.4459056 ]\n",
      " [0.         0.49350853 0.         0.59829199 0.         0.\n",
      "  0.46273842 0.32473276 0.         0.76115997]\n",
      " [0.         0.         0.         0.8710263  0.         0.\n",
      "  0.         0.         0.         0.17183249]\n",
      " [0.73248082 0.         0.64344148 0.33818439 0.         0.\n",
      "  1.50892657 0.         0.         0.57025269]\n",
      " [0.         0.         0.         0.         0.         1.01276412\n",
      "  1.1309099  0.         0.         0.        ]\n",
      " [0.88505655 0.68887457 0.0946157  0.         1.44432825 2.04198305\n",
      "  0.         0.         1.45888539 0.        ]\n",
      " [1.0331871  0.54801606 0.83363271 0.         1.63566713 1.24234057\n",
      "  0.         0.         0.00760195 0.9472641 ]\n",
      " [0.         2.7575342  0.75156802 0.73110151 0.         0.\n",
      "  1.74563556 0.         0.         0.87005336]\n",
      " [0.         0.3651147  0.         0.         0.0429053  0.02887775\n",
      "  0.80517591 1.2542503  1.74315537 2.09973015]\n",
      " [0.         1.29060587 0.66074631 0.         0.2779046  0.\n",
      "  0.         0.         0.         0.61457826]]\n",
      "[[ 0.          0.          0.         -0.57221939 -1.10131795 -0.48205612\n",
      "  -0.30940237 -0.03719703  0.          1.31642309]\n",
      " [ 0.         -0.95126673  0.         -2.66235282  0.          0.\n",
      "  -1.10323581 -0.38354635  0.         -1.17092817]\n",
      " [ 0.          0.          0.          0.11932492  0.          0.\n",
      "   0.          0.          0.         -0.13254571]\n",
      " [-0.92656016  0.          0.58190305 -0.47954673  0.          0.\n",
      "  -0.74151662  0.          0.         -0.52355768]\n",
      " [ 0.          0.          0.          0.          0.          1.36445728\n",
      "  -0.8116192   0.          0.          0.        ]\n",
      " [ 0.10609721  0.50892165 -1.5473412   0.         -0.76262105 -0.37448847\n",
      "   0.          0.         -0.46122226  0.        ]\n",
      " [ 0.37463517 -0.84370425  0.89276048  0.          1.16257243 -0.01638865\n",
      "   0.          0.          0.03916767 -0.38124359]\n",
      " [ 0.          1.17731148 -1.01572302  0.66124349  0.          0.\n",
      "   2.06939354  0.          0.         -1.30342168]\n",
      " [ 0.         -1.0760888   0.          0.         -1.92376714 -0.74311068\n",
      "  -0.896829    0.38896304 -0.51363757  1.08304602]\n",
      " [ 0.          1.09933649 -0.02445726  0.          0.54864358  0.\n",
      "   0.          0.          0.         -0.68371615]]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T21:01:09.039148Z",
     "start_time": "2025-09-15T21:01:09.029298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#check max_pool\n",
    "class MaxPooling:\n",
    "    \"\"\"\n",
    "    Max Pooling of input\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.cache = None\n",
    "        self.dx = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of max pooling\n",
    "        :param x: input, (N, C, H, W)\n",
    "        :return: The output by max pooling with kernel_size and stride\n",
    "        \"\"\"\n",
    "        N = x.shape[0]\n",
    "        C = x.shape[1]\n",
    "        H = x.shape[2]\n",
    "        W = x.shape[3]\n",
    "        H_out = math.floor((H - self.kernel_size)/self.stride + 1)\n",
    "        W_out = math.floor((W - self.kernel_size)/self.stride + 1)\n",
    "\n",
    "        #initialize output\n",
    "        out = np.zeros((N, C, H_out, W_out))\n",
    "\n",
    "        for n in range(N):\n",
    "            for c in range(C):\n",
    "                for hi in range(H_out):\n",
    "                    for wi in range(W_out):\n",
    "                            out[n, c, hi, wi] = np.max(x[n, c, hi*self.stride:(hi*self.stride + self.kernel_size), wi*self.stride:(wi*self.stride + self.kernel_size)])\n",
    "\n",
    "        self.cache = (x, H_out, W_out)\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "\n",
    "        x, H_out, W_out = self.cache\n",
    "\n",
    "        #dL_dx = 1 only for index positions in input array x in which value was the max value in pooling operation\n",
    "        out = self.forward(x)\n",
    "        self.dx = np.zeros_like(x)\n",
    "\n",
    "        N = x.shape[0]\n",
    "        C = x.shape[1]\n",
    "        H = x.shape[2]\n",
    "        W = x.shape[3]\n",
    "\n",
    "        for n in range(N):\n",
    "            for c in range(C):\n",
    "                for hi in range(H_out):\n",
    "                    for wi in range(W_out):\n",
    "                            slice = x[n, c, hi*self.stride:(hi*self.stride + self.kernel_size), wi*self.stride:(wi*self.stride + self.kernel_size)]\n",
    "                            # print(slice.flatten())\n",
    "                            max_idx = np.argmax(slice)\n",
    "                            # print(max_idx)\n",
    "                            max_pos = list(np.unravel_index(max_idx, (1,1,self.kernel_size, self.kernel_size)))\n",
    "                            #correct index for which area of x max pool came from - H, W increased by stride and kernel size\n",
    "                            max_pos[2] = max_pos[2] + hi*self.stride   #height position\n",
    "                            max_pos[3]  = max_pos[3] + wi*self.stride    #width position\n",
    "\n",
    "                            #troubleshooting\n",
    "                            # print(\"max idx \", max_idx)\n",
    "                            print(\"max_pos: \", max_pos)\n",
    "                            self.dx[tuple(max_pos)] = 1\n",
    "\n",
    "#test function\n",
    "\n",
    "x_shape = (2, 3, 4, 4)\n",
    "x = np.linspace(-0.3, 0.4, num=np.prod(x_shape)).reshape(x_shape)\n",
    "maxpool = MaxPooling(kernel_size=2, stride=2)\n",
    "out = maxpool.forward(x)\n",
    "\n",
    "correct_out = np.array([[[[-0.26315789, -0.24842105],\n",
    "                          [-0.20421053, -0.18947368]],\n",
    "                         [[-0.14526316, -0.13052632],\n",
    "                          [-0.08631579, -0.07157895]],\n",
    "                         [[-0.02736842, -0.01263158],\n",
    "                          [0.03157895, 0.04631579]]],\n",
    "                        [[[0.09052632, 0.10526316],\n",
    "                          [0.14947368, 0.16421053]],\n",
    "                         [[0.20842105, 0.22315789],\n",
    "                          [0.26736842, 0.28210526]],\n",
    "                             [[0.32631579, 0.34105263],\n",
    "                              [0.38526316, 0.4]]]])\n",
    "# print(correct_out.shape)\n",
    "# print(out.shape)\n",
    "# print(out)"
   ],
   "id": "63bddd18f4df85b8",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T21:43:24.104477Z",
     "start_time": "2025-09-11T21:43:24.088343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#check backprop\n",
    "# print(x)\n",
    "maxpool.backward(out)\n",
    "dx = maxpool.dx\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: maxpool._pool_forward(x), x, dout)\n",
    "print(\"correct ans: \", dx_num)\n",
    "print(dx)"
   ],
   "id": "b81f2b201c443900",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_pos:  [0, 0, 1, 1]\n",
      "max_pos:  [0, 0, 1, 3]\n",
      "max_pos:  [0, 0, 3, 1]\n",
      "max_pos:  [0, 0, 3, 3]\n",
      "max_pos:  [0, 0, 1, 1]\n",
      "max_pos:  [0, 0, 1, 3]\n",
      "max_pos:  [0, 0, 3, 1]\n",
      "max_pos:  [0, 0, 3, 3]\n",
      "max_pos:  [0, 0, 1, 1]\n",
      "max_pos:  [0, 0, 1, 3]\n",
      "max_pos:  [0, 0, 3, 1]\n",
      "max_pos:  [0, 0, 3, 3]\n",
      "max_pos:  [0, 0, 1, 1]\n",
      "max_pos:  [0, 0, 1, 3]\n",
      "max_pos:  [0, 0, 3, 1]\n",
      "max_pos:  [0, 0, 3, 3]\n",
      "max_pos:  [0, 0, 1, 1]\n",
      "max_pos:  [0, 0, 1, 3]\n",
      "max_pos:  [0, 0, 3, 1]\n",
      "max_pos:  [0, 0, 3, 3]\n",
      "max_pos:  [0, 0, 1, 1]\n",
      "max_pos:  [0, 0, 1, 3]\n",
      "max_pos:  [0, 0, 3, 1]\n",
      "max_pos:  [0, 0, 3, 3]\n",
      "[[[[0. 0. 0. 0.]\n",
      "   [0. 1. 0. 1.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 1. 0. 1.]]\n",
      "\n",
      "  [[0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]]]]\n"
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T20:59:11.539111Z",
     "start_time": "2025-09-15T20:59:11.531650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#understand np.unravel_index - unlike sample_array.argmax(), it shows the index of the multi-dimensional array where the max is, not the index of the flattened version\n",
    "\n",
    "arr = np.arange(20).reshape(5, 4)\n",
    "print(\"arr: \", arr)\n",
    "x = arr.argmax()\n",
    "print(\"x: \", x)\n",
    "dims = arr.shape\n",
    "print(\"dims array: \", dims)\n",
    "idx = np.unravel_index(x, dims)\n",
    "print(\"idx using unravel_index: \", idx)\n",
    "print(arr[idx] == arr.max())\n",
    "\n"
   ],
   "id": "e3d12d22f58a8aa8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr:  [[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]\n",
      " [12 13 14 15]\n",
      " [16 17 18 19]]\n",
      "x:  19\n",
      "dims array:  (5, 4)\n",
      "idx using unravel_index:  (4, 3)\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T21:00:32.683616Z",
     "start_time": "2025-09-15T21:00:32.679265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#for np.unravel_index, input indices for flattened version of array, get back tuple of two arrays (row positions array, col positions array) if list of inputs, or single tuple if single input\n",
    "#so 22 -> (3,4), 41 -> (6,5) 37 -> (6,1)\n",
    "max_indices = np.unravel_index([22, 41, 37], (7,6))\n",
    "print('max indices: ', max_indices)\n",
    "print('max for 22: ', max_indices[0][0], max_indices[1][0])"
   ],
   "id": "36ce3f56a652d5a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max indices:  (array([3, 6, 6], dtype=int64), array([4, 5, 1], dtype=int64))\n",
      "max for 22:  3 4\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T21:01:46.479317Z",
     "start_time": "2025-09-15T21:01:46.475169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "max_pos = np.unravel_index(2, (2,3,2,2))\n",
    "\n",
    "temp = out.copy()\n",
    "# print(\"temp: \", temp)\n",
    "print(\"max pos\", max_pos)\n",
    "temp[max_pos] = 1\n",
    "print(\"temp: \", temp)"
   ],
   "id": "b794ff529c2acd3c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max pos (0, 0, 1, 0)\n",
      "temp:  [[[[-0.26315789 -0.24842105]\n",
      "   [ 1.         -0.18947368]]\n",
      "\n",
      "  [[-0.14526316 -0.13052632]\n",
      "   [-0.08631579 -0.07157895]]\n",
      "\n",
      "  [[-0.02736842 -0.01263158]\n",
      "   [ 0.03157895  0.04631579]]]\n",
      "\n",
      "\n",
      " [[[ 0.09052632  0.10526316]\n",
      "   [ 0.14947368  0.16421053]]\n",
      "\n",
      "  [[ 0.20842105  0.22315789]\n",
      "   [ 0.26736842  0.28210526]]\n",
      "\n",
      "  [[ 0.32631579  0.34105263]\n",
      "   [ 0.38526316  0.4       ]]]]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T21:18:57.803371Z",
     "start_time": "2025-09-11T21:18:57.798381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#max_pooling back prop\n",
    "np.argmax(out)"
   ],
   "id": "d9986ed8637b972d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T23:53:26.127267Z",
     "start_time": "2025-09-16T23:53:26.122198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#practice reshaping\n",
    "num_inputs = 2\n",
    "input_shape = (4, 5, 6)\n",
    "output_dim = 3\n",
    "\n",
    "input_size = num_inputs * np.prod(input_shape)\n",
    "weight_size = output_dim * np.prod(input_shape)\n",
    "\n",
    "x = np.linspace(-0.1, 0.5, num=input_size).reshape(num_inputs, *input_shape)\n",
    "w = np.linspace(-0.2, 0.3, num=weight_size).reshape(np.prod(input_shape), output_dim)\n",
    "b = np.linspace(-0.3, 0.1, num=output_dim)\n",
    "\n",
    "print(x.shape)\n",
    "x = np.reshape(x, (x.shape[0], np.prod(np.array(x.shape[1:]))))\n",
    "print(x.shape)"
   ],
   "id": "1ec7bbc589cf3285",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4, 5, 6)\n",
      "(2, 120)\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
