{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MIkt4yxKpzgS"
   },
   "source": [
    "# CS 7643 Assignment 2 Part 2:  Implement and train a network on CIFAR-10 using Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5eLeqVzpzgV"
   },
   "source": [
    "Convolutional Neural Networks (CNNs) are one of the major advancements in\n",
    "computer vision over the past decade. In this assignment, you will complete\n",
    "a simple CNN architecture from scratch and learn how to implement CNNs\n",
    "with PyTorch, one of the most commonly used deep learning frameworks.\n",
    "You will also run different experiments on imbalanced datasets to evaluate\n",
    "your model and techniques to deal with imbalanced data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kx3nM2xMpzgW"
   },
   "source": [
    "# Setup Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l86tglWzpzgX"
   },
   "source": [
    "Before getting started we need to run some standard code to set up our environment. You'll need to execute this code again each time you start the notebook.\n",
    "\n",
    "First, run this cell to load the [autoreload](https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html?highlight=autoreload) extension. This enables us to modify `.py` source files and reintegrate them into the notebook, ensuring a smooth editing and debugging experience.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "j22uun9OpzgX",
    "ExecuteTime": {
     "end_time": "2025-09-20T19:25:38.853620Z",
     "start_time": "2025-09-20T19:25:38.825619Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9pOTy-9dpzgY"
   },
   "source": [
    "### Google Colab Setup\n",
    "Next we need to run a few commands to set up our environment on Google Colab. If you are running this notebook on a local machine you can skip this section.\n",
    "\n",
    "Run the following cell to mount your Google Drive. Follow the link, sign in to your Google account (the same account you used to store this notebook!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zujgqHl3pzgZ"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAQYM7TWpzgZ"
   },
   "source": [
    "Now remember the path in your Google Drive where you uploaded this notebook, fill it in below. If all functions properly, executing the next cell should display the filenames from the assignment:\n",
    "\n",
    "```\n",
    "['CS7643-Assignment2-2.ipynb', 'cs7643', 'checkpoints', 'losses', 'configs', 'models', 'tests']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UiGZhhG8pzga",
    "ExecuteTime": {
     "end_time": "2025-09-20T19:25:42.683445Z",
     "start_time": "2025-09-20T19:25:41.817828Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "# TODO: Fill in the Google Drive path where you uploaded assignment1\n",
    "# Example: If you create a Fall2023 folder and put all the files under A1 folder, then 'Fall2023/A1'\n",
    "GOOGLE_DRIVE_PATH_POST_MYDRIVE = None\n",
    "#GOOGLE_DRIVE_PATH_POST_MYDRIVE = r\"CSE 7643 - DL/DL PS 2/DL_HW_2_collab/part2-pytorch\"\n",
    "GOOGLE_DRIVE_PATH = os.path.join('/content', 'drive', 'MyDrive', GOOGLE_DRIVE_PATH_POST_MYDRIVE)\n",
    "print(os.listdir(GOOGLE_DRIVE_PATH))"
   ],
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "join() argument must be str, bytes, or os.PathLike object, not 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 6\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# TODO: Fill in the Google Drive path where you uploaded assignment1\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Example: If you create a Fall2023 folder and put all the files under A1 folder, then 'Fall2023/A1'\u001B[39;00m\n\u001B[0;32m      5\u001B[0m GOOGLE_DRIVE_PATH_POST_MYDRIVE \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m GOOGLE_DRIVE_PATH \u001B[38;5;241m=\u001B[39m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/content\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdrive\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mMyDrive\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mGOOGLE_DRIVE_PATH_POST_MYDRIVE\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(os\u001B[38;5;241m.\u001B[39mlistdir(GOOGLE_DRIVE_PATH))\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\cs7643-a2\\Lib\\ntpath.py:149\u001B[0m, in \u001B[0;36mjoin\u001B[1;34m(path, *paths)\u001B[0m\n\u001B[0;32m    147\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result_drive \u001B[38;5;241m+\u001B[39m result_root \u001B[38;5;241m+\u001B[39m result_path\n\u001B[0;32m    148\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mAttributeError\u001B[39;00m, \u001B[38;5;167;01mBytesWarning\u001B[39;00m):\n\u001B[1;32m--> 149\u001B[0m     \u001B[43mgenericpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_arg_types\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mjoin\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpaths\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    150\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\cs7643-a2\\Lib\\genericpath.py:164\u001B[0m, in \u001B[0;36m_check_arg_types\u001B[1;34m(funcname, *args)\u001B[0m\n\u001B[0;32m    162\u001B[0m         hasbytes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    163\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 164\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfuncname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m() argument must be str, bytes, or \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    165\u001B[0m                         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mos.PathLike object, not \u001B[39m\u001B[38;5;132;01m{\u001B[39;00ms\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    166\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m hasstr \u001B[38;5;129;01mand\u001B[39;00m hasbytes:\n\u001B[0;32m    167\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCan\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt mix strings and bytes in path components\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mTypeError\u001B[0m: join() argument must be str, bytes, or os.PathLike object, not 'NoneType'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svKml_u_mwNn"
   },
   "source": [
    "### Local Setup or Google Colab\n",
    "Run the cell below regardless of setup to set the path "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "itp51CmXmy03",
    "ExecuteTime": {
     "end_time": "2025-09-20T19:25:44.914867Z",
     "start_time": "2025-09-20T19:25:44.883244Z"
    }
   },
   "source": [
    "# if running locally set GOOGLE PATH\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "  print(f'Running in google colab. Our path is `{GOOGLE_DRIVE_PATH}`')\n",
    "else:\n",
    "  GOOGLE_DRIVE_PATH = '.'\n",
    "  print('Running locally.')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C48GISpDpzga"
   },
   "source": [
    "After successfully mounting your Google Drive and identifying the path to this assignment, execute the following cell to enable us to import from the `.py` files of this assignment. If it works correctly, it should print the message (note, you may need to retry this twice if it fails):\n",
    "\n",
    "```\n",
    "Roger that from cnn.py!\n",
    "Roger that from my_model.py!\n",
    "Roger that from resnet.py!\n",
    "Roger that from twolayer.py!\n",
    "\n",
    "Roger that from focal_loss.py!\n",
    "```\n",
    "\n",
    "as well as the last edit time for the files `cnn.py`, `my_model.py`, `resnet.py`, `twolayer.py`, and `focal_loss.py`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QeqHoG1Dpzga",
    "ExecuteTime": {
     "end_time": "2025-09-20T19:25:47.475699Z",
     "start_time": "2025-09-20T19:25:47.337051Z"
    }
   },
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "sys.path.append(GOOGLE_DRIVE_PATH)\n",
    "\n",
    "from cs7643.env_prob import say_hello_do_you_copy\n",
    "\n",
    "say_hello_do_you_copy(GOOGLE_DRIVE_PATH)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Models ------------------\n",
      "Roger that from cnn.py!\n",
      "Roger that from my_model.py!\n",
      "Roger that from resnet.py!\n",
      "Roger that from twolayer.py!\n",
      "cnn.py last edited on Mon Sep  8 20:15:29 2025\n",
      "my_model.py last edited on Mon Sep  8 20:15:29 2025\n",
      "resnet.py last edited on Mon Sep  8 20:15:29 2025\n",
      "twolayer.py last edited on Mon Sep  8 20:15:29 2025\n",
      "\n",
      "---------- Losses ------------------\n",
      "Roger that from focal_loss.py!\n",
      "focal_loss.py last edited on Mon Sep  8 20:15:29 2025\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rev2Ozk1KGj3"
   },
   "source": [
    "# Load the CIFAR10 dataset\n",
    "Data loading is the very first step of any machine learning pipelines. Run the following cell to download the CIFAR10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kHlccnRMKXTw",
    "ExecuteTime": {
     "end_time": "2025-09-20T19:25:50.516327Z",
     "start_time": "2025-09-20T19:25:49.669431Z"
    }
   },
   "source": [
    "from cs7643.cifar10 import CIFAR10\n",
    "\n",
    "cifar10_ds = CIFAR10(GOOGLE_DRIVE_PATH + '/data/cifar10', download=True, train=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pf2FgYgT3W03"
   },
   "source": [
    "We will use GPUs to accelerate our computation in this notebook. Run the following to make sure GPUs are enabled:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kuHZ057d3Uwx",
    "ExecuteTime": {
     "end_time": "2025-09-20T19:25:53.275584Z",
     "start_time": "2025-09-20T19:25:53.240436Z"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "device = 'mps' if torch.backends.mps.is_available() else ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device = \" + device)\n",
    "if device == 'cpu':\n",
    "    print(\"WARNING: Using CPU will cause slower train times\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device = cpu\n",
      "WARNING: Using CPU will cause slower train times\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tgfHDh0pzgb"
   },
   "source": [
    "# Training\n",
    "The first thing of working with PyTorch is to get yourself familiarized with\n",
    "the basic training step of PyTorch. Read through the [PyTorch Tutorial](https://pytorch.org/tutorials/beginner/basics/intro.html) and complete __compute_loss_update_params_ function in `./solver.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AuL2J65znk9R"
   },
   "source": [
    "## PyTorch Model\n",
    "You will now implement some actual networks with PyTorch. We provide\n",
    "some starter files for you in `./models`. The models for you to implement are\n",
    "as follows:\n",
    "\n",
    "* **Two-Layer Network**. This is the same network you have implemented from scratch in assignment 1. You will build the model with two fully connected layers and a sigmoid activation function in between the two layers. Please implement the model as instructed in `./models/twolayer.py`.\n",
    "\n",
    "* **Vanilla Convolutional Neural Network**. You will build the model with a\n",
    "convolution layer, a ReLU activation, a max-pooling layer, followed by a fully connected layer for classification. Your convolution layer should use **32 output channels**, a **kernel size of 7** with **stride 1** and **zero padding**. You max-pooling should use a **kernel size of 2** and **stride of 2**. The fully connected layer should have **10 output features**. Please implement the model as instructed in `./models/cnn.py`.\n",
    "\n",
    "* Your Own Network. You are now free to build your own model. Notice that it's okay for you to borrow some insights from existing well-known networks, however, directly using those networks as-is is **NOT** allowed.\n",
    "In other words, you have to build your model from scratch, which also means using any sort of pre-trained weights is also **NOT** allowed. Please implement your model in `./models/my_model.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JgEN4027oF9j"
   },
   "source": [
    "We provide you configuration files for these three models respectively. For\n",
    "Two-Layer Network and Vanilla CNN, you need to train the model without modifying the configuration file. The script automatically saves the weights of the best model at the end of training. We will evaluate your implementation by loading your model weights and evaluating the model on CIFAR-10 test data. You should expect the accuracy of Two-Layer Network and Vanilla CNN to be around 0.3 and 0.4 respectively.\n",
    "\n",
    "For your own network, you are free to tune any hyper-parameters to\n",
    "obtain better accuracy. Your final accuracy must be above 0.5 to receive\n",
    "at least partial credit. Please refer to the GradeScope auto-test results\n",
    "for the requirement of full credits. Try to keep your submission **under\n",
    "100mb or GradeScope may not accept it**. All in all, please make sure\n",
    "the checkpoints of each model are saved into `./checkpoints`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vbYkRflMMQR-"
   },
   "source": [
    "Select a configuration file from the list then run the cell to train your model. To select a custom config, select \"Show code\" and specify the path to your config file. **Note that you may have to restart the jupyter kernel after updating the files above before running the below snippet.**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "G4HceY6Fy2vx",
    "ExecuteTime": {
     "end_time": "2025-09-20T23:51:49.257886Z",
     "start_time": "2025-09-20T23:51:43.285066Z"
    }
   },
   "source": [
    "import yaml\n",
    "from solver import Solver\n",
    "\n",
    "#CHANGE HERE FOR EACH MODEL!!\n",
    "config_file = \"config_mymodel\" # feel free to change to  [\"config_mymodel\", \"config_twolayer\", \"config_vanilla_cnn\", or other]\n",
    "\n",
    "config_file = GOOGLE_DRIVE_PATH + \"/configs/\" + config_file + \".yaml\"\n",
    "\n",
    "print(\"Training a model using configuration file \" + config_file)\n",
    "\n",
    "with open(config_file, \"r\") as read_file:\n",
    "  config = yaml.safe_load(read_file)\n",
    "\n",
    "kwargs = {}\n",
    "for key in config:\n",
    "  for k, v in config[key].items():\n",
    "    if k != 'description':\n",
    "      kwargs[k] = v\n",
    "\n",
    "kwargs['device'] = device\n",
    "kwargs['path_prefix'] = GOOGLE_DRIVE_PATH\n",
    "\n",
    "print(kwargs)\n",
    "\n",
    "solver = Solver(**kwargs)\n",
    "solver.train()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a model using configuration file ./configs/config_mymodel.yaml\n",
      "{'batch_size': 128, 'learning_rate': 0.0001, 'reg': 0.0005, 'epochs': 10, 'steps': [6, 8], 'warmup': 0, 'momentum': 0.9, 'gamma': 1, 'model': 'MyModel', 'imbalance': 'regular', 'save_best': True, 'loss_type': 'CE', 'device': 'cpu', 'path_prefix': '.'}\n",
      "MyModel(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
      "  (fc3): Linear(in_features=60, out_features=10, bias=True)\n",
      ")\n",
      "Epoch: [0][0/391]\tTime 0.016 (0.016)\tLoss 2.3087 (2.3087)\tPrec @1 0.0938 (0.0938)\t\n",
      "Epoch: [0][10/391]\tTime 0.013 (0.014)\tLoss 2.3047 (2.3033)\tPrec @1 0.0938 (0.0966)\t\n",
      "Epoch: [0][20/391]\tTime 0.013 (0.013)\tLoss 2.3067 (2.3055)\tPrec @1 0.1172 (0.0945)\t\n",
      "Epoch: [0][30/391]\tTime 0.013 (0.013)\tLoss 2.2975 (2.3057)\tPrec @1 0.1094 (0.0938)\t\n",
      "Epoch: [0][40/391]\tTime 0.013 (0.013)\tLoss 2.3012 (2.3043)\tPrec @1 0.0859 (0.0972)\t\n",
      "Epoch: [0][50/391]\tTime 0.013 (0.013)\tLoss 2.3117 (2.3040)\tPrec @1 0.1328 (0.0997)\t\n",
      "Epoch: [0][60/391]\tTime 0.014 (0.013)\tLoss 2.3040 (2.3039)\tPrec @1 0.1094 (0.1000)\t\n",
      "Epoch: [0][70/391]\tTime 0.013 (0.013)\tLoss 2.3043 (2.3044)\tPrec @1 0.0938 (0.1005)\t\n",
      "Epoch: [0][80/391]\tTime 0.012 (0.013)\tLoss 2.3057 (2.3042)\tPrec @1 0.1016 (0.1019)\t\n",
      "Epoch: [0][90/391]\tTime 0.013 (0.013)\tLoss 2.3040 (2.3040)\tPrec @1 0.1094 (0.1022)\t\n",
      "Epoch: [0][100/391]\tTime 0.013 (0.013)\tLoss 2.2951 (2.3039)\tPrec @1 0.1562 (0.1028)\t\n",
      "Epoch: [0][110/391]\tTime 0.013 (0.013)\tLoss 2.3012 (2.3036)\tPrec @1 0.1172 (0.1030)\t\n",
      "Epoch: [0][120/391]\tTime 0.012 (0.013)\tLoss 2.3067 (2.3034)\tPrec @1 0.0703 (0.1033)\t\n",
      "Epoch: [0][130/391]\tTime 0.013 (0.013)\tLoss 2.2975 (2.3035)\tPrec @1 0.1250 (0.1034)\t\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[34], line 26\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28mprint\u001B[39m(kwargs)\n\u001B[0;32m     25\u001B[0m solver \u001B[38;5;241m=\u001B[39m Solver(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m---> 26\u001B[0m \u001B[43msolver\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\CSE_7643_DL\\DL_PS2\\part2-pytorch\\solver.py:166\u001B[0m, in \u001B[0;36mSolver.train\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    163\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_adjust_learning_rate(epoch)\n\u001B[0;32m    165\u001B[0m \u001B[38;5;66;03m# train loop\u001B[39;00m\n\u001B[1;32m--> 166\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_train_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    168\u001B[0m \u001B[38;5;66;03m# validation loop\u001B[39;00m\n\u001B[0;32m    169\u001B[0m acc, cm \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_evaluate(epoch)\n",
      "File \u001B[1;32m~\\CSE_7643_DL\\DL_PS2\\part2-pytorch\\solver.py:195\u001B[0m, in \u001B[0;36mSolver._train_step\u001B[1;34m(self, epoch)\u001B[0m\n\u001B[0;32m    191\u001B[0m acc \u001B[38;5;241m=\u001B[39m AverageMeter()\n\u001B[0;32m    193\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[1;32m--> 195\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_loader\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[0;32m    196\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstart\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtime\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    198\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:734\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    731\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    732\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    733\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 734\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    735\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    736\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    737\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[0;32m    738\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    739\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[0;32m    740\u001B[0m ):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:790\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    788\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    789\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 790\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    791\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    792\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     50\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 52\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torchvision\\datasets\\cifar.py:119\u001B[0m, in \u001B[0;36mCIFAR10.__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m    116\u001B[0m img \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mfromarray(img)\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 119\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    121\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_transform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    122\u001B[0m     target \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_transform(target)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001B[0m, in \u001B[0;36mCompose.__call__\u001B[1;34m(self, img)\u001B[0m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, img):\n\u001B[0;32m     94\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransforms:\n\u001B[1;32m---> 95\u001B[0m         img \u001B[38;5;241m=\u001B[39m \u001B[43mt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1771\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1772\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1773\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1779\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1780\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1781\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1782\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1783\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1784\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1786\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1787\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:712\u001B[0m, in \u001B[0;36mRandomHorizontalFlip.forward\u001B[1;34m(self, img)\u001B[0m\n\u001B[0;32m    704\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, img):\n\u001B[0;32m    705\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    706\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m    707\u001B[0m \u001B[38;5;124;03m        img (PIL Image or Tensor): Image to be flipped.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    710\u001B[0m \u001B[38;5;124;03m        PIL Image or Tensor: Randomly flipped image.\u001B[39;00m\n\u001B[0;32m    711\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 712\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrand\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mp:\n\u001B[0;32m    713\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mhflip(img)\n\u001B[0;32m    714\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zWfbgzB4Uiu"
   },
   "source": [
    "Let's test your models implementation. **Make sure to train your models and create checkpoints before running the following tests**."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Db0t0IChKK0h",
    "ExecuteTime": {
     "end_time": "2025-09-20T22:13:03.333388Z",
     "start_time": "2025-09-20T22:12:51.483978Z"
    }
   },
   "source": [
    "#Let's test your implementation of two layer\n",
    "!pytest -s {GOOGLE_DRIVE_PATH + '/tests/test_twolayer.py'}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m============================= test session starts =============================\u001B[0m\n",
      "platform win32 -- Python 3.12.0, pytest-8.4.1, pluggy-1.5.0\n",
      "rootdir: C:\\Users\\julie\\CSE_7643_DL\\DL_PS2\\part2-pytorch\n",
      "plugins: anyio-4.7.0\n",
      "collected 1 item\n",
      "\n",
      "tests\\test_twolayer.py \u001B[32m.\u001B[0m\n",
      "\n",
      "\u001B[32m============================= \u001B[32m\u001B[1m1 passed\u001B[0m\u001B[32m in 10.23s\u001B[0m\u001B[32m ==============================\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "X97MN9JvcMQY",
    "ExecuteTime": {
     "end_time": "2025-09-20T23:55:49.056862Z",
     "start_time": "2025-09-20T23:55:43.496680Z"
    }
   },
   "source": [
    "#Let's test your implementation of my_model\n",
    "!pytest -s { GOOGLE_DRIVE_PATH + '/tests/test_mymodel.py'}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m============================= test session starts =============================\u001B[0m\n",
      "platform win32 -- Python 3.12.0, pytest-8.4.1, pluggy-1.5.0\n",
      "rootdir: C:\\Users\\julie\\CSE_7643_DL\\DL_PS2\\part2-pytorch\n",
      "plugins: anyio-4.7.0\n",
      "collected 3 items\n",
      "\n",
      "tests\\test_mymodel.py \u001B[31mE\u001B[0m\u001B[31mE\u001B[0m\u001B[31mE\u001B[0m\n",
      "\n",
      "=================================== ERRORS ====================================\n",
      "\u001B[31m\u001B[1m______________ ERROR at setup of TestMyModel.test_accuracy_easy _______________\u001B[0m\n",
      "\n",
      "cls = <class 'tests.test_mymodel.TestMyModel'>\n",
      "\n",
      "    \u001B[0m\u001B[37m@classmethod\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "    \u001B[94mdef\u001B[39;49;00m \u001B[92msetUpClass\u001B[39;49;00m(\u001B[96mcls\u001B[39;49;00m):\u001B[90m\u001B[39;49;00m\n",
      "    \u001B[90m    \u001B[39;49;00m\u001B[33m\"\"\"Define the functions to be tested here.\"\"\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "        basedir = pathlib.Path(\u001B[91m__file__\u001B[39;49;00m).parent.parent.resolve()\u001B[90m\u001B[39;49;00m\n",
      "        model = MyModel()\u001B[90m\u001B[39;49;00m\n",
      "        model.eval()\u001B[90m\u001B[39;49;00m\n",
      "        model.load_state_dict(\u001B[90m\u001B[39;49;00m\n",
      ">           torch.load(\u001B[96mstr\u001B[39;49;00m(basedir) + \u001B[33m\"\u001B[39;49;00m\u001B[33m/checkpoints/mymodel.pth\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, weights_only=\u001B[94mTrue\u001B[39;49;00m)\u001B[90m\u001B[39;49;00m\n",
      "        )\u001B[90m\u001B[39;49;00m\n",
      "\n",
      "\u001B[1m\u001B[31mtests\\test_mymodel.py\u001B[0m:74: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:1484: in load\n",
      "    \u001B[0m\u001B[94mwith\u001B[39;49;00m _open_file_like(f, \u001B[33m\"\u001B[39;49;00m\u001B[33mrb\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m) \u001B[94mas\u001B[39;49;00m opened_file:\u001B[90m\u001B[39;49;00m\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:759: in _open_file_like\n",
      "    \u001B[0m\u001B[94mreturn\u001B[39;49;00m _open_file(name_or_buffer, mode)\u001B[90m\u001B[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "self = <torch.serialization._open_file object at 0x0000020050CB14C0>\n",
      "name = 'C:\\\\Users\\\\julie\\\\CSE_7643_DL\\\\DL_PS2\\\\part2-pytorch/checkpoints/mymodel.pth'\n",
      "mode = 'rb'\n",
      "\n",
      "    \u001B[0m\u001B[94mdef\u001B[39;49;00m \u001B[92m__init__\u001B[39;49;00m(\u001B[96mself\u001B[39;49;00m, name: Union[\u001B[96mstr\u001B[39;49;00m, os.PathLike[\u001B[96mstr\u001B[39;49;00m]], mode: \u001B[96mstr\u001B[39;49;00m) -> \u001B[94mNone\u001B[39;49;00m:\u001B[90m\u001B[39;49;00m\n",
      ">       \u001B[96msuper\u001B[39;49;00m().\u001B[92m__init__\u001B[39;49;00m(\u001B[96mopen\u001B[39;49;00m(name, mode))\u001B[90m\u001B[39;49;00m\n",
      "                         ^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31mE       FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\julie\\\\CSE_7643_DL\\\\DL_PS2\\\\part2-pytorch/checkpoints/mymodel.pth'\u001B[0m\n",
      "\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:740: FileNotFoundError\n",
      "\u001B[31m\u001B[1m______________ ERROR at setup of TestMyModel.test_accuracy_hard _______________\u001B[0m\n",
      "\n",
      "cls = <class 'tests.test_mymodel.TestMyModel'>\n",
      "\n",
      "    \u001B[0m\u001B[37m@classmethod\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "    \u001B[94mdef\u001B[39;49;00m \u001B[92msetUpClass\u001B[39;49;00m(\u001B[96mcls\u001B[39;49;00m):\u001B[90m\u001B[39;49;00m\n",
      "    \u001B[90m    \u001B[39;49;00m\u001B[33m\"\"\"Define the functions to be tested here.\"\"\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "        basedir = pathlib.Path(\u001B[91m__file__\u001B[39;49;00m).parent.parent.resolve()\u001B[90m\u001B[39;49;00m\n",
      "        model = MyModel()\u001B[90m\u001B[39;49;00m\n",
      "        model.eval()\u001B[90m\u001B[39;49;00m\n",
      "        model.load_state_dict(\u001B[90m\u001B[39;49;00m\n",
      ">           torch.load(\u001B[96mstr\u001B[39;49;00m(basedir) + \u001B[33m\"\u001B[39;49;00m\u001B[33m/checkpoints/mymodel.pth\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, weights_only=\u001B[94mTrue\u001B[39;49;00m)\u001B[90m\u001B[39;49;00m\n",
      "        )\u001B[90m\u001B[39;49;00m\n",
      "\n",
      "\u001B[1m\u001B[31mtests\\test_mymodel.py\u001B[0m:74: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:1484: in load\n",
      "    \u001B[0m\u001B[94mwith\u001B[39;49;00m _open_file_like(f, \u001B[33m\"\u001B[39;49;00m\u001B[33mrb\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m) \u001B[94mas\u001B[39;49;00m opened_file:\u001B[90m\u001B[39;49;00m\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:759: in _open_file_like\n",
      "    \u001B[0m\u001B[94mreturn\u001B[39;49;00m _open_file(name_or_buffer, mode)\u001B[90m\u001B[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "self = <torch.serialization._open_file object at 0x0000020050CB14C0>\n",
      "name = 'C:\\\\Users\\\\julie\\\\CSE_7643_DL\\\\DL_PS2\\\\part2-pytorch/checkpoints/mymodel.pth'\n",
      "mode = 'rb'\n",
      "\n",
      "    \u001B[0m\u001B[94mdef\u001B[39;49;00m \u001B[92m__init__\u001B[39;49;00m(\u001B[96mself\u001B[39;49;00m, name: Union[\u001B[96mstr\u001B[39;49;00m, os.PathLike[\u001B[96mstr\u001B[39;49;00m]], mode: \u001B[96mstr\u001B[39;49;00m) -> \u001B[94mNone\u001B[39;49;00m:\u001B[90m\u001B[39;49;00m\n",
      ">       \u001B[96msuper\u001B[39;49;00m().\u001B[92m__init__\u001B[39;49;00m(\u001B[96mopen\u001B[39;49;00m(name, mode))\u001B[90m\u001B[39;49;00m\n",
      "                         ^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31mE       FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\julie\\\\CSE_7643_DL\\\\DL_PS2\\\\part2-pytorch/checkpoints/mymodel.pth'\u001B[0m\n",
      "\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:740: FileNotFoundError\n",
      "\u001B[31m\u001B[1m_____________ ERROR at setup of TestMyModel.test_accuracy_medium ______________\u001B[0m\n",
      "\n",
      "cls = <class 'tests.test_mymodel.TestMyModel'>\n",
      "\n",
      "    \u001B[0m\u001B[37m@classmethod\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "    \u001B[94mdef\u001B[39;49;00m \u001B[92msetUpClass\u001B[39;49;00m(\u001B[96mcls\u001B[39;49;00m):\u001B[90m\u001B[39;49;00m\n",
      "    \u001B[90m    \u001B[39;49;00m\u001B[33m\"\"\"Define the functions to be tested here.\"\"\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "        basedir = pathlib.Path(\u001B[91m__file__\u001B[39;49;00m).parent.parent.resolve()\u001B[90m\u001B[39;49;00m\n",
      "        model = MyModel()\u001B[90m\u001B[39;49;00m\n",
      "        model.eval()\u001B[90m\u001B[39;49;00m\n",
      "        model.load_state_dict(\u001B[90m\u001B[39;49;00m\n",
      ">           torch.load(\u001B[96mstr\u001B[39;49;00m(basedir) + \u001B[33m\"\u001B[39;49;00m\u001B[33m/checkpoints/mymodel.pth\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, weights_only=\u001B[94mTrue\u001B[39;49;00m)\u001B[90m\u001B[39;49;00m\n",
      "        )\u001B[90m\u001B[39;49;00m\n",
      "\n",
      "\u001B[1m\u001B[31mtests\\test_mymodel.py\u001B[0m:74: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:1484: in load\n",
      "    \u001B[0m\u001B[94mwith\u001B[39;49;00m _open_file_like(f, \u001B[33m\"\u001B[39;49;00m\u001B[33mrb\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m) \u001B[94mas\u001B[39;49;00m opened_file:\u001B[90m\u001B[39;49;00m\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:759: in _open_file_like\n",
      "    \u001B[0m\u001B[94mreturn\u001B[39;49;00m _open_file(name_or_buffer, mode)\u001B[90m\u001B[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "self = <torch.serialization._open_file object at 0x0000020050CB14C0>\n",
      "name = 'C:\\\\Users\\\\julie\\\\CSE_7643_DL\\\\DL_PS2\\\\part2-pytorch/checkpoints/mymodel.pth'\n",
      "mode = 'rb'\n",
      "\n",
      "    \u001B[0m\u001B[94mdef\u001B[39;49;00m \u001B[92m__init__\u001B[39;49;00m(\u001B[96mself\u001B[39;49;00m, name: Union[\u001B[96mstr\u001B[39;49;00m, os.PathLike[\u001B[96mstr\u001B[39;49;00m]], mode: \u001B[96mstr\u001B[39;49;00m) -> \u001B[94mNone\u001B[39;49;00m:\u001B[90m\u001B[39;49;00m\n",
      ">       \u001B[96msuper\u001B[39;49;00m().\u001B[92m__init__\u001B[39;49;00m(\u001B[96mopen\u001B[39;49;00m(name, mode))\u001B[90m\u001B[39;49;00m\n",
      "                         ^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31mE       FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\julie\\\\CSE_7643_DL\\\\DL_PS2\\\\part2-pytorch/checkpoints/mymodel.pth'\u001B[0m\n",
      "\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:740: FileNotFoundError\n",
      "\u001B[36m\u001B[1m=========================== short test summary info ===========================\u001B[0m\n",
      "\u001B[31mERROR\u001B[0m tests/test_mymodel.py::\u001B[1mTestMyModel::test_accuracy_easy\u001B[0m - FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\julie\\\\...\n",
      "\u001B[31mERROR\u001B[0m tests/test_mymodel.py::\u001B[1mTestMyModel::test_accuracy_hard\u001B[0m - FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\julie\\\\...\n",
      "\u001B[31mERROR\u001B[0m tests/test_mymodel.py::\u001B[1mTestMyModel::test_accuracy_medium\u001B[0m - FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\julie\\\\...\n",
      "\u001B[31m============================== \u001B[31m\u001B[1m3 errors\u001B[0m\u001B[31m in 3.80s\u001B[0m\u001B[31m ==============================\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zaXbxcApKPNw",
    "ExecuteTime": {
     "end_time": "2025-09-20T22:49:25.900041Z",
     "start_time": "2025-09-20T22:49:15.040423Z"
    }
   },
   "source": [
    "#Let's test your implementation of Vanilla CNN\n",
    "!pytest -s {GOOGLE_DRIVE_PATH + '/tests/test_vanilla_cnn.py'}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m============================= test session starts =============================\u001B[0m\n",
      "platform win32 -- Python 3.12.0, pytest-8.4.1, pluggy-1.5.0\n",
      "rootdir: C:\\Users\\julie\\CSE_7643_DL\\DL_PS2\\part2-pytorch\n",
      "plugins: anyio-4.7.0\n",
      "collected 1 item\n",
      "\n",
      "tests\\test_vanilla_cnn.py \u001B[32m.\u001B[0m\n",
      "\n",
      "\u001B[32m============================== \u001B[32m\u001B[1m1 passed\u001B[0m\u001B[32m in 9.56s\u001B[0m\u001B[32m ==============================\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D68rtzAZpzgc"
   },
   "source": [
    "# Data Wrangling\n",
    "So far we have worked with well-balanced datasets (samples of each class are\n",
    "evenly distributed). However, in practice, datasets are often not balanced.\n",
    "In this section, you will explore the limitation of standard training strategy\n",
    "on this type of dataset. This being an exploration, it is up to you to design\n",
    "experiments or tests to validate these methods are correct and effective.\n",
    "You will work with an unbalanced version of CIFAR-10 in this section, and you should use the ResNet-32 model in `./models/resnet.py`.\n",
    "\n",
    "## Class-Balanced Focal Loss\n",
    "You will implement one possible solution to the imbalance problem: ClassBalanced Focal Loss using this CVPR-19 paper [Class-Balanced Loss Based on Effective Number of Samples](https://arxiv.org/pdf/1901.05555.pdf). You may also refer to the original paper of [Focal Loss](https://arxiv.org/abs/1708.02002) for more details if you are interested. Please implement CB Focal\n",
    "Loss in `./losses/focal_loss.py`.\n",
    "\n",
    "**Note**: The CVPR-19 paper uses SigmoidÌ² CB focal loss (section 4). Softmax CB focal loss is not described in the paper, but it is easy to derive from the mentioned papers. You must implement the softmax version to pass the\n",
    "tests.\n",
    "\n",
    "Hint: Make sure you are using torch operations througout your focal loss implementation otherwise the torch computation graph will not be built properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FUEYEuHBpzgd"
   },
   "outputs": [],
   "source": [
    "# Test your Focal Loss implementation\n",
    "!pytest -s {GOOGLE_DRIVE_PATH + '/tests/test_focalloss.py'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, follow the instructions in the report template to obtain the best results possible for Resnet with regular CE loss (you may need to perform extra hyperparameter tuning). Then experiment with the beta parameter. Finally,  obtain the best possible results for Resnet using focal loss. You are welcome to change other hyperparameters in the config file as necessary. Make sure to set the `imbalance` config parameter as appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjZK5lqLFsor"
   },
   "source": [
    "# Submit Your Work\n",
    "After completing the notebook for this assignment (`assignment2_2.ipynb`), run the following cell to create a `.zip` file for you to download and then upload to Gradescope.\n",
    "\n",
    "**Please MANUALLY SAVE `*.py` files before executing the following cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uPREUKv7FwPS"
   },
   "outputs": [],
   "source": [
    "from cs7643.submit import make_a2_2_submission\n",
    "\n",
    "make_a2_2_submission(GOOGLE_DRIVE_PATH)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
