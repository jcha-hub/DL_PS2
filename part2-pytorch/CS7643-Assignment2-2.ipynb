{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MIkt4yxKpzgS"
   },
   "source": [
    "# CS 7643 Assignment 2 Part 2:  Implement and train a network on CIFAR-10 using Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5eLeqVzpzgV"
   },
   "source": [
    "Convolutional Neural Networks (CNNs) are one of the major advancements in\n",
    "computer vision over the past decade. In this assignment, you will complete\n",
    "a simple CNN architecture from scratch and learn how to implement CNNs\n",
    "with PyTorch, one of the most commonly used deep learning frameworks.\n",
    "You will also run different experiments on imbalanced datasets to evaluate\n",
    "your model and techniques to deal with imbalanced data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kx3nM2xMpzgW"
   },
   "source": [
    "# Setup Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l86tglWzpzgX"
   },
   "source": [
    "Before getting started we need to run some standard code to set up our environment. You'll need to execute this code again each time you start the notebook.\n",
    "\n",
    "First, run this cell to load the [autoreload](https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html?highlight=autoreload) extension. This enables us to modify `.py` source files and reintegrate them into the notebook, ensuring a smooth editing and debugging experience.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "j22uun9OpzgX",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1758413732313,
     "user_tz": 240,
     "elapsed": 74,
     "user": {
      "displayName": "Julie Cha",
      "userId": "02094140184777567318"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-09-23T22:25:58.081705Z",
     "start_time": "2025-09-23T22:25:58.027922Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9pOTy-9dpzgY"
   },
   "source": [
    "### Google Colab Setup\n",
    "Next we need to run a few commands to set up our environment on Google Colab. If you are running this notebook on a local machine you can skip this section.\n",
    "\n",
    "Run the following cell to mount your Google Drive. Follow the link, sign in to your Google account (the same account you used to store this notebook!)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zujgqHl3pzgZ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1758413770030,
     "user_tz": 240,
     "elapsed": 23129,
     "user": {
      "displayName": "Julie Cha",
      "userId": "02094140184777567318"
     }
    },
    "outputId": "368a1695-a05e-4551-bf41-5c66fd4bfa83",
    "ExecuteTime": {
     "end_time": "2025-09-22T18:27:10.580842Z",
     "start_time": "2025-09-22T18:27:10.525623Z"
    }
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[31], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgoogle\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcolab\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m drive\n\u001B[0;32m      2\u001B[0m drive\u001B[38;5;241m.\u001B[39mmount(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/content/drive\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'google.colab'"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAQYM7TWpzgZ"
   },
   "source": [
    "Now remember the path in your Google Drive where you uploaded this notebook, fill it in below. If all functions properly, executing the next cell should display the filenames from the assignment:\n",
    "\n",
    "```\n",
    "['CS7643-Assignment2-2.ipynb', 'cs7643', 'checkpoints', 'losses', 'configs', 'models', 'tests']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UiGZhhG8pzga",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1758413778024,
     "user_tz": 240,
     "elapsed": 2988,
     "user": {
      "displayName": "Julie Cha",
      "userId": "02094140184777567318"
     }
    },
    "outputId": "0ec53e81-80e6-40bc-9991-f6a1e895bc39",
    "ExecuteTime": {
     "end_time": "2025-09-23T19:57:29.582444Z",
     "start_time": "2025-09-23T19:57:29.518790Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "# TODO: Fill in the Google Drive path where you uploaded assignment1\n",
    "# Example: If you create a Fall2023 folder and put all the files under A1 folder, then 'Fall2023/A1'\\\n",
    "\n",
    "GOOGLE_DRIVE_PATH_POST_MYDRIVE = None\n",
    "# GOOGLE_DRIVE_PATH_POST_MYDRIVE = r\"CSE 7643 - DL/DL PS 2/DL_HW_2_collab/part2-pytorch\"\n",
    "\n",
    "GOOGLE_DRIVE_PATH = os.path.join('/content', 'drive', 'MyDrive', GOOGLE_DRIVE_PATH_POST_MYDRIVE)\n",
    "print(os.listdir(GOOGLE_DRIVE_PATH))"
   ],
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "join() argument must be str, bytes, or os.PathLike object, not 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 9\u001B[0m\n\u001B[0;32m      6\u001B[0m GOOGLE_DRIVE_PATH_POST_MYDRIVE \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# GOOGLE_DRIVE_PATH_POST_MYDRIVE = r\"CSE 7643 - DL/DL PS 2/DL_HW_2_collab/part2-pytorch\"\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m GOOGLE_DRIVE_PATH \u001B[38;5;241m=\u001B[39m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/content\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdrive\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mMyDrive\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mGOOGLE_DRIVE_PATH_POST_MYDRIVE\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m(os\u001B[38;5;241m.\u001B[39mlistdir(GOOGLE_DRIVE_PATH))\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\cs7643-a2\\Lib\\ntpath.py:149\u001B[0m, in \u001B[0;36mjoin\u001B[1;34m(path, *paths)\u001B[0m\n\u001B[0;32m    147\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result_drive \u001B[38;5;241m+\u001B[39m result_root \u001B[38;5;241m+\u001B[39m result_path\n\u001B[0;32m    148\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mAttributeError\u001B[39;00m, \u001B[38;5;167;01mBytesWarning\u001B[39;00m):\n\u001B[1;32m--> 149\u001B[0m     \u001B[43mgenericpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_arg_types\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mjoin\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpaths\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    150\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\cs7643-a2\\Lib\\genericpath.py:164\u001B[0m, in \u001B[0;36m_check_arg_types\u001B[1;34m(funcname, *args)\u001B[0m\n\u001B[0;32m    162\u001B[0m         hasbytes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    163\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 164\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfuncname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m() argument must be str, bytes, or \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    165\u001B[0m                         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mos.PathLike object, not \u001B[39m\u001B[38;5;132;01m{\u001B[39;00ms\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    166\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m hasstr \u001B[38;5;129;01mand\u001B[39;00m hasbytes:\n\u001B[0;32m    167\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCan\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt mix strings and bytes in path components\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mTypeError\u001B[0m: join() argument must be str, bytes, or os.PathLike object, not 'NoneType'"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svKml_u_mwNn"
   },
   "source": [
    "### Local Setup or Google Colab\n",
    "Run the cell below regardless of setup to set the path"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "itp51CmXmy03",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1758413782124,
     "user_tz": 240,
     "elapsed": 53,
     "user": {
      "displayName": "Julie Cha",
      "userId": "02094140184777567318"
     }
    },
    "outputId": "33fb5853-3e48-4759-a88c-df81678e32aa",
    "ExecuteTime": {
     "end_time": "2025-09-23T22:26:02.984281Z",
     "start_time": "2025-09-23T22:26:02.937151Z"
    }
   },
   "source": [
    "# if running locally set GOOGLE PATH\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "  print(f'Running in google colab. Our path is `{GOOGLE_DRIVE_PATH}`')\n",
    "else:\n",
    "  GOOGLE_DRIVE_PATH = '.'\n",
    "  print('Running locally.')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C48GISpDpzga"
   },
   "source": [
    "After successfully mounting your Google Drive and identifying the path to this assignment, execute the following cell to enable us to import from the `.py` files of this assignment. If it works correctly, it should print the message (note, you may need to retry this twice if it fails):\n",
    "\n",
    "```\n",
    "Roger that from cnn.py!\n",
    "Roger that from my_model.py!\n",
    "Roger that from resnet.py!\n",
    "Roger that from twolayer.py!\n",
    "\n",
    "Roger that from focal_loss.py!\n",
    "```\n",
    "\n",
    "as well as the last edit time for the files `cnn.py`, `my_model.py`, `resnet.py`, `twolayer.py`, and `focal_loss.py`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QeqHoG1Dpzga",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1758413821919,
     "user_tz": 240,
     "elapsed": 36353,
     "user": {
      "displayName": "Julie Cha",
      "userId": "02094140184777567318"
     }
    },
    "outputId": "55db4d2b-9639-4981-f773-5324bfbf97e0",
    "ExecuteTime": {
     "end_time": "2025-09-23T22:26:06.828475Z",
     "start_time": "2025-09-23T22:26:06.697124Z"
    }
   },
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "sys.path.append(GOOGLE_DRIVE_PATH)\n",
    "\n",
    "from cs7643.env_prob import say_hello_do_you_copy\n",
    "\n",
    "say_hello_do_you_copy(GOOGLE_DRIVE_PATH)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Models ------------------\n",
      "Roger that from cnn.py!\n",
      "Roger that from my_model.py!\n",
      "Roger that from resnet.py!\n",
      "Roger that from twolayer.py!\n",
      "cnn.py last edited on Sat Sep 20 19:48:59 2025\n",
      "my_model.py last edited on Tue Sep 23 18:25:44 2025\n",
      "resnet.py last edited on Mon Sep  8 20:15:29 2025\n",
      "twolayer.py last edited on Sat Sep 20 18:09:41 2025\n",
      "\n",
      "---------- Losses ------------------\n",
      "Roger that from focal_loss.py!\n",
      "focal_loss.py last edited on Mon Sep 22 14:05:24 2025\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rev2Ozk1KGj3"
   },
   "source": [
    "# Load the CIFAR10 dataset\n",
    "Data loading is the very first step of any machine learning pipelines. Run the following cell to download the CIFAR10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kHlccnRMKXTw",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1758413842741,
     "user_tz": 240,
     "elapsed": 14974,
     "user": {
      "displayName": "Julie Cha",
      "userId": "02094140184777567318"
     }
    },
    "outputId": "140e9d1b-c7bb-4b8b-ca0e-14c37412313d",
    "ExecuteTime": {
     "end_time": "2025-09-23T22:26:09.813309Z",
     "start_time": "2025-09-23T22:26:08.880635Z"
    }
   },
   "source": [
    "from cs7643.cifar10 import CIFAR10\n",
    "\n",
    "cifar10_ds = CIFAR10(GOOGLE_DRIVE_PATH + '/data/cifar10', download=True, train=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pf2FgYgT3W03"
   },
   "source": [
    "We will use GPUs to accelerate our computation in this notebook. Run the following to make sure GPUs are enabled:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kuHZ057d3Uwx",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1758413869728,
     "user_tz": 240,
     "elapsed": 210,
     "user": {
      "displayName": "Julie Cha",
      "userId": "02094140184777567318"
     }
    },
    "outputId": "b1c313fa-fc37-46a1-aa94-9e6cd492d914",
    "ExecuteTime": {
     "end_time": "2025-09-23T22:26:10.812110Z",
     "start_time": "2025-09-23T22:26:10.756818Z"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "device = 'mps' if torch.backends.mps.is_available() else ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device = \" + device)\n",
    "if device == 'cpu':\n",
    "    print(\"WARNING: Using CPU will cause slower train times\")\n",
    "\n",
    "# !nvidia-smi\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device = cpu\n",
      "WARNING: Using CPU will cause slower train times\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tgfHDh0pzgb"
   },
   "source": [
    "# Training\n",
    "The first thing of working with PyTorch is to get yourself familiarized with\n",
    "the basic training step of PyTorch. Read through the [PyTorch Tutorial](https://pytorch.org/tutorials/beginner/basics/intro.html) and complete __compute_loss_update_params_ function in `./solver.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AuL2J65znk9R"
   },
   "source": [
    "## PyTorch Model\n",
    "You will now implement some actual networks with PyTorch. We provide\n",
    "some starter files for you in `./models`. The models for you to implement are\n",
    "as follows:\n",
    "\n",
    "* **Two-Layer Network**. This is the same network you have implemented from scratch in assignment 1. You will build the model with two fully connected layers and a sigmoid activation function in between the two layers. Please implement the model as instructed in `./models/twolayer.py`.\n",
    "\n",
    "* **Vanilla Convolutional Neural Network**. You will build the model with a\n",
    "convolution layer, a ReLU activation, a max-pooling layer, followed by a fully connected layer for classification. Your convolution layer should use **32 output channels**, a **kernel size of 7** with **stride 1** and **zero padding**. You max-pooling should use a **kernel size of 2** and **stride of 2**. The fully connected layer should have **10 output features**. Please implement the model as instructed in `./models/cnn.py`.\n",
    "\n",
    "* Your Own Network. You are now free to build your own model. Notice that it's okay for you to borrow some insights from existing well-known networks, however, directly using those networks as-is is **NOT** allowed.\n",
    "In other words, you have to build your model from scratch, which also means using any sort of pre-trained weights is also **NOT** allowed. Please implement your model in `./models/my_model.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JgEN4027oF9j"
   },
   "source": [
    "We provide you configuration files for these three models respectively. For\n",
    "Two-Layer Network and Vanilla CNN, you need to train the model without modifying the configuration file. The script automatically saves the weights of the best model at the end of training. We will evaluate your implementation by loading your model weights and evaluating the model on CIFAR-10 test data. You should expect the accuracy of Two-Layer Network and Vanilla CNN to be around 0.3 and 0.4 respectively.\n",
    "\n",
    "For your own network, you are free to tune any hyper-parameters to\n",
    "obtain better accuracy. Your final accuracy must be above 0.5 to receive\n",
    "at least partial credit. Please refer to the GradeScope auto-test results\n",
    "for the requirement of full credits. Try to keep your submission **under\n",
    "100mb or GradeScope may not accept it**. All in all, please make sure\n",
    "the checkpoints of each model are saved into `./checkpoints`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vbYkRflMMQR-"
   },
   "source": [
    "Select a configuration file from the list then run the cell to train your model. To select a custom config, select \"Show code\" and specify the path to your config file. **Note that you may have to restart the jupyter kernel after updating the files above before running the below snippet.**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "G4HceY6Fy2vx",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1758414190179,
     "user_tz": 240,
     "elapsed": 308301,
     "user": {
      "displayName": "Julie Cha",
      "userId": "02094140184777567318"
     }
    },
    "outputId": "03502e9a-8e1b-437b-820e-e2eb3684d1f0",
    "ExecuteTime": {
     "end_time": "2025-09-23T22:35:00.214318Z",
     "start_time": "2025-09-23T22:34:51.422538Z"
    }
   },
   "source": [
    "import yaml\n",
    "from solver import Solver\n",
    "\n",
    "#CHANGE HERE FOR EACH MODEL!!\n",
    "config_file = \"config_mymodel\" # feel free to change to  [\"config_mymodel\", \"config_twolayer\", \"config_vanilla_cnn\", or other]\n",
    "\n",
    "config_file = GOOGLE_DRIVE_PATH + \"/configs/\" + config_file + \".yaml\"\n",
    "\n",
    "print(\"Training a model using configuration file \" + config_file)\n",
    "\n",
    "with open(config_file, \"r\") as read_file:\n",
    "  config = yaml.safe_load(read_file)\n",
    "\n",
    "kwargs = {}\n",
    "for key in config:\n",
    "  for k, v in config[key].items():\n",
    "    if k != 'description':\n",
    "      kwargs[k] = v\n",
    "\n",
    "kwargs['device'] = device\n",
    "kwargs['path_prefix'] = GOOGLE_DRIVE_PATH\n",
    "\n",
    "print(kwargs)\n",
    "\n",
    "solver = Solver(**kwargs)\n",
    "solver.train()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a model using configuration file ./configs/config_mymodel.yaml\n",
      "{'batch_size': 96, 'learning_rate': 0.01, 'reg': 0.0001, 'epochs': 15, 'steps': [6, 8], 'warmup': 0, 'momentum': 0.95, 'gamma': 1, 'model': 'MyModel', 'imbalance': 'regular', 'save_best': True, 'loss_type': 'CE', 'device': 'cpu', 'path_prefix': '.'}\n",
      "MyModel(\n",
      "  (conv1): Conv2d(3, 96, kernel_size=(7, 7), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(96, 128, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "  (conv4): Conv2d(128, 160, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (conv5): Conv2d(160, 192, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (conv6): Conv2d(192, 224, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=896, out_features=200, bias=True)\n",
      "  (fc2): Linear(in_features=200, out_features=80, bias=True)\n",
      "  (fc3): Linear(in_features=80, out_features=10, bias=True)\n",
      ")\n",
      "Epoch: [0][0/521]\tTime 0.224 (0.224)\tLoss 2.2972 (2.2972)\tPrec @1 0.0833 (0.0833)\t\n",
      "Epoch: [0][10/521]\tTime 0.229 (0.231)\tLoss 2.3017 (2.3032)\tPrec @1 0.1146 (0.1127)\t\n",
      "Epoch: [0][20/521]\tTime 0.229 (0.237)\tLoss 2.3017 (2.3030)\tPrec @1 0.1042 (0.1042)\t\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 26\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28mprint\u001B[39m(kwargs)\n\u001B[0;32m     25\u001B[0m solver \u001B[38;5;241m=\u001B[39m Solver(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m---> 26\u001B[0m \u001B[43msolver\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\CSE_7643_DL\\DL_PS2\\part2-pytorch\\solver.py:166\u001B[0m, in \u001B[0;36mSolver.train\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    163\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_adjust_learning_rate(epoch)\n\u001B[0;32m    165\u001B[0m \u001B[38;5;66;03m# train loop\u001B[39;00m\n\u001B[1;32m--> 166\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_train_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    168\u001B[0m \u001B[38;5;66;03m# validation loop\u001B[39;00m\n\u001B[0;32m    169\u001B[0m acc, cm \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_evaluate(epoch)\n",
      "File \u001B[1;32m~\\CSE_7643_DL\\DL_PS2\\part2-pytorch\\solver.py:201\u001B[0m, in \u001B[0;36mSolver._train_step\u001B[1;34m(self, epoch)\u001B[0m\n\u001B[0;32m    198\u001B[0m data \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m    199\u001B[0m target \u001B[38;5;241m=\u001B[39m target\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m--> 201\u001B[0m out, loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compute_loss_update_params\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    203\u001B[0m batch_acc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_accuracy(out, target)\n\u001B[0;32m    205\u001B[0m losses\u001B[38;5;241m.\u001B[39mupdate(loss\u001B[38;5;241m.\u001B[39mitem(), out\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m])\n",
      "File \u001B[1;32m~\\CSE_7643_DL\\DL_PS2\\part2-pytorch\\solver.py:299\u001B[0m, in \u001B[0;36mSolver._compute_loss_update_params\u001B[1;34m(self, data, target)\u001B[0m\n\u001B[0;32m    291\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    292\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mtraining:\n\u001B[0;32m    293\u001B[0m     \u001B[38;5;66;03m#############################################################################\u001B[39;00m\n\u001B[0;32m    294\u001B[0m     \u001B[38;5;66;03m# TODO: Complete the body of training loop                                  #\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    297\u001B[0m     \u001B[38;5;66;03m#       3. Compute gradients and update model parameters                    #\u001B[39;00m\n\u001B[0;32m    298\u001B[0m     \u001B[38;5;66;03m#############################################################################\u001B[39;00m\n\u001B[1;32m--> 299\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    300\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcriterion(output, target)\n\u001B[0;32m    302\u001B[0m     \u001B[38;5;66;03m#backprop\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1771\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1772\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1773\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1779\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1780\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1781\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1782\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1783\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1784\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1786\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1787\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\CSE_7643_DL\\DL_PS2\\part2-pytorch\\models\\my_model.py:57\u001B[0m, in \u001B[0;36mMyModel.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     55\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpool(F\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv3(x)))\n\u001B[0;32m     56\u001B[0m x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv4(x))\n\u001B[1;32m---> 57\u001B[0m x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv5\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     58\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpool(F\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv6(x)))\n\u001B[0;32m     59\u001B[0m x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mdropout(x, \u001B[38;5;241m0.25\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1771\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1772\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1773\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1779\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1780\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1781\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1782\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1783\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1784\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1786\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1787\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    547\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 548\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:543\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[1;34m(self, input, weight, bias)\u001B[0m\n\u001B[0;32m    531\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(\n\u001B[0;32m    533\u001B[0m         F\u001B[38;5;241m.\u001B[39mpad(\n\u001B[0;32m    534\u001B[0m             \u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    541\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups,\n\u001B[0;32m    542\u001B[0m     )\n\u001B[1;32m--> 543\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    544\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\n\u001B[0;32m    545\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zWfbgzB4Uiu"
   },
   "source": [
    "Let's test your models implementation. **Make sure to train your models and create checkpoints before running the following tests**."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Db0t0IChKK0h",
    "outputId": "133b0ce1-b1af-48c5-801c-edc8805d67ef",
    "ExecuteTime": {
     "end_time": "2025-09-21T00:29:32.613262Z",
     "start_time": "2025-09-21T00:29:21.802146Z"
    }
   },
   "source": [
    "#Let's test your implementation of two layer\n",
    "!pytest -s {GOOGLE_DRIVE_PATH + '/tests/test_twolayer.py'}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m============================= test session starts =============================\u001B[0m\n",
      "platform win32 -- Python 3.12.0, pytest-8.4.1, pluggy-1.5.0\n",
      "rootdir: C:\\Users\\julie\\CSE_7643_DL\\DL_PS2\\part2-pytorch\n",
      "plugins: anyio-4.7.0\n",
      "collected 1 item\n",
      "\n",
      "tests\\test_twolayer.py \u001B[32m.\u001B[0m\n",
      "\n",
      "\u001B[32m============================== \u001B[32m\u001B[1m1 passed\u001B[0m\u001B[32m in 9.65s\u001B[0m\u001B[32m ==============================\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "X97MN9JvcMQY",
    "outputId": "08cd7e8f-7f5a-4a44-ab93-1c22bc29486c",
    "ExecuteTime": {
     "end_time": "2025-09-21T00:29:38.861677Z",
     "start_time": "2025-09-21T00:29:34.878405Z"
    }
   },
   "source": [
    "#Let's test your implementation of my_model\n",
    "!pytest -s { GOOGLE_DRIVE_PATH + '/tests/test_mymodel.py'}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m============================= test session starts =============================\u001B[0m\n",
      "platform win32 -- Python 3.12.0, pytest-8.4.1, pluggy-1.5.0\n",
      "rootdir: C:\\Users\\julie\\CSE_7643_DL\\DL_PS2\\part2-pytorch\n",
      "plugins: anyio-4.7.0\n",
      "collected 3 items\n",
      "\n",
      "tests\\test_mymodel.py \u001B[31mE\u001B[0m\u001B[31mE\u001B[0m\u001B[31mE\u001B[0m\n",
      "\n",
      "=================================== ERRORS ====================================\n",
      "\u001B[31m\u001B[1m______________ ERROR at setup of TestMyModel.test_accuracy_easy _______________\u001B[0m\n",
      "\n",
      "cls = <class 'tests.test_mymodel.TestMyModel'>\n",
      "\n",
      "    \u001B[0m\u001B[37m@classmethod\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "    \u001B[94mdef\u001B[39;49;00m \u001B[92msetUpClass\u001B[39;49;00m(\u001B[96mcls\u001B[39;49;00m):\u001B[90m\u001B[39;49;00m\n",
      "    \u001B[90m    \u001B[39;49;00m\u001B[33m\"\"\"Define the functions to be tested here.\"\"\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "        basedir = pathlib.Path(\u001B[91m__file__\u001B[39;49;00m).parent.parent.resolve()\u001B[90m\u001B[39;49;00m\n",
      "        model = MyModel()\u001B[90m\u001B[39;49;00m\n",
      "        model.eval()\u001B[90m\u001B[39;49;00m\n",
      "        model.load_state_dict(\u001B[90m\u001B[39;49;00m\n",
      ">           torch.load(\u001B[96mstr\u001B[39;49;00m(basedir) + \u001B[33m\"\u001B[39;49;00m\u001B[33m/checkpoints/mymodel.pth\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, weights_only=\u001B[94mTrue\u001B[39;49;00m)\u001B[90m\u001B[39;49;00m\n",
      "        )\u001B[90m\u001B[39;49;00m\n",
      "\n",
      "\u001B[1m\u001B[31mtests\\test_mymodel.py\u001B[0m:74: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:1521: in load\n",
      "    \u001B[0m\u001B[94mreturn\u001B[39;49;00m _load(\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:2119: in _load\n",
      "    \u001B[0mresult = unpickler.load()\u001B[90m\u001B[39;49;00m\n",
      "             ^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\_weights_only_unpickler.py\u001B[0m:532: in load\n",
      "    \u001B[0m\u001B[96mself\u001B[39;49;00m.append(\u001B[96mself\u001B[39;49;00m.persistent_load(pid))\u001B[90m\u001B[39;49;00m\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:2083: in persistent_load\n",
      "    \u001B[0mtyped_storage = load_tensor(\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:2049: in load_tensor\n",
      "    \u001B[0mwrap_storage = restore_location(storage, location)\u001B[90m\u001B[39;49;00m\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:698: in default_restore_location\n",
      "    \u001B[0mresult = fn(storage, location)\u001B[90m\u001B[39;49;00m\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:636: in _deserialize\n",
      "    \u001B[0mdevice = _validate_device(location, backend_name)\u001B[90m\u001B[39;49;00m\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "location = 'cuda:0', backend_name = 'cuda'\n",
      "\n",
      "    \u001B[0m\u001B[94mdef\u001B[39;49;00m \u001B[92m_validate_device\u001B[39;49;00m(location, backend_name):\u001B[90m\u001B[39;49;00m\n",
      "    \u001B[90m    \u001B[39;49;00m\u001B[33m\"\"\"\u001B[39;49;00m\n",
      "    \u001B[33m    Check whether the device index of specified backend is valid\u001B[39;49;00m\n",
      "    \u001B[33m\u001B[39;49;00m\n",
      "    \u001B[33m    In case of privateuse1 backend, your must first register a device_module for\u001B[39;49;00m\n",
      "    \u001B[33m    privateuse1 using torch._register_device_module. Implement the following\u001B[39;49;00m\n",
      "    \u001B[33m    methods in device_module like cuda: device_module._utils._get_device_index(location, True),\u001B[39;49;00m\n",
      "    \u001B[33m    device_module.device_count().\u001B[39;49;00m\n",
      "    \u001B[33m\u001B[39;49;00m\n",
      "    \u001B[33m    Args:\u001B[39;49;00m\n",
      "    \u001B[33m        location: string of device\u001B[39;49;00m\n",
      "    \u001B[33m        backend_name: the backend name or the name of privateuse1, which can be renamed\u001B[39;49;00m\n",
      "    \u001B[33m\u001B[39;49;00m\n",
      "    \u001B[33m    Returns:\u001B[39;49;00m\n",
      "    \u001B[33m        device_index: int\u001B[39;49;00m\n",
      "    \u001B[33m    \"\"\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "        \u001B[94mif\u001B[39;49;00m \u001B[95mnot\u001B[39;49;00m \u001B[96mhasattr\u001B[39;49;00m(torch, backend_name):\u001B[90m\u001B[39;49;00m\n",
      "            \u001B[94mraise\u001B[39;49;00m \u001B[96mRuntimeError\u001B[39;49;00m(\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33mf\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[33mThe \u001B[39;49;00m\u001B[33m{\u001B[39;49;00mbackend_name.upper()\u001B[33m}\u001B[39;49;00m\u001B[33m device module is not registered. \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33m\"\u001B[39;49;00m\u001B[33mIf you are running on a CPU-only machine, \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33m\"\u001B[39;49;00m\u001B[33mplease use torch.load with map_location=torch.device(\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m\u001B[33mcpu\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m\u001B[33m) \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33m\"\u001B[39;49;00m\u001B[33mto map your storages to the CPU.\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "            )\u001B[90m\u001B[39;49;00m\n",
      "        device_module = \u001B[96mgetattr\u001B[39;49;00m(torch, backend_name)\u001B[90m\u001B[39;49;00m\n",
      "        \u001B[94mif\u001B[39;49;00m \u001B[96mhasattr\u001B[39;49;00m(device_module, \u001B[33m\"\u001B[39;49;00m\u001B[33m_utils\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m) \u001B[95mand\u001B[39;49;00m \u001B[96mhasattr\u001B[39;49;00m(\u001B[90m\u001B[39;49;00m\n",
      "            device_module._utils, \u001B[33m\"\u001B[39;49;00m\u001B[33m_get_device_index\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "        ):\u001B[90m\u001B[39;49;00m\n",
      "            device_index = device_module._utils._get_device_index(location, \u001B[94mTrue\u001B[39;49;00m)\u001B[90m\u001B[39;49;00m\n",
      "            device = torch.device(backend_name, device_index)\u001B[90m\u001B[39;49;00m\n",
      "        \u001B[94melse\u001B[39;49;00m:\u001B[90m\u001B[39;49;00m\n",
      "            device = torch.device(location)\u001B[90m\u001B[39;49;00m\n",
      "            device_index = device.index \u001B[94mif\u001B[39;49;00m device.index \u001B[94melse\u001B[39;49;00m \u001B[94m0\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "        \u001B[94mif\u001B[39;49;00m \u001B[96mhasattr\u001B[39;49;00m(device_module, \u001B[33m\"\u001B[39;49;00m\u001B[33mis_available\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m) \u001B[95mand\u001B[39;49;00m \u001B[95mnot\u001B[39;49;00m device_module.is_available():\u001B[90m\u001B[39;49;00m\n",
      ">           \u001B[94mraise\u001B[39;49;00m \u001B[96mRuntimeError\u001B[39;49;00m(\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33mf\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[33mAttempting to deserialize object on a \u001B[39;49;00m\u001B[33m{\u001B[39;49;00mbackend_name.upper()\u001B[33m}\u001B[39;49;00m\u001B[33m \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33mf\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[33mdevice but torch.\u001B[39;49;00m\u001B[33m{\u001B[39;49;00mbackend_name\u001B[33m}\u001B[39;49;00m\u001B[33m.is_available() is False. \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33m\"\u001B[39;49;00m\u001B[33mIf you are running on a CPU-only machine, \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33m\"\u001B[39;49;00m\u001B[33mplease use torch.load with map_location=torch.device(\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m\u001B[33mcpu\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m\u001B[33m) \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33m\"\u001B[39;49;00m\u001B[33mto map your storages to the CPU.\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "            )\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31mE           RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.\u001B[0m\n",
      "\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:605: RuntimeError\n",
      "\u001B[31m\u001B[1m______________ ERROR at setup of TestMyModel.test_accuracy_hard _______________\u001B[0m\n",
      "\n",
      "cls = <class 'tests.test_mymodel.TestMyModel'>\n",
      "\n",
      "    \u001B[0m\u001B[37m@classmethod\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "    \u001B[94mdef\u001B[39;49;00m \u001B[92msetUpClass\u001B[39;49;00m(\u001B[96mcls\u001B[39;49;00m):\u001B[90m\u001B[39;49;00m\n",
      "    \u001B[90m    \u001B[39;49;00m\u001B[33m\"\"\"Define the functions to be tested here.\"\"\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "        basedir = pathlib.Path(\u001B[91m__file__\u001B[39;49;00m).parent.parent.resolve()\u001B[90m\u001B[39;49;00m\n",
      "        model = MyModel()\u001B[90m\u001B[39;49;00m\n",
      "        model.eval()\u001B[90m\u001B[39;49;00m\n",
      "        model.load_state_dict(\u001B[90m\u001B[39;49;00m\n",
      ">           torch.load(\u001B[96mstr\u001B[39;49;00m(basedir) + \u001B[33m\"\u001B[39;49;00m\u001B[33m/checkpoints/mymodel.pth\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, weights_only=\u001B[94mTrue\u001B[39;49;00m)\u001B[90m\u001B[39;49;00m\n",
      "        )\u001B[90m\u001B[39;49;00m\n",
      "\n",
      "\u001B[1m\u001B[31mtests\\test_mymodel.py\u001B[0m:74: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:1521: in load\n",
      "    \u001B[0m\u001B[94mreturn\u001B[39;49;00m _load(\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:2119: in _load\n",
      "    \u001B[0mresult = unpickler.load()\u001B[90m\u001B[39;49;00m\n",
      "             ^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\_weights_only_unpickler.py\u001B[0m:532: in load\n",
      "    \u001B[0m\u001B[96mself\u001B[39;49;00m.append(\u001B[96mself\u001B[39;49;00m.persistent_load(pid))\u001B[90m\u001B[39;49;00m\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:2083: in persistent_load\n",
      "    \u001B[0mtyped_storage = load_tensor(\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:2049: in load_tensor\n",
      "    \u001B[0mwrap_storage = restore_location(storage, location)\u001B[90m\u001B[39;49;00m\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:698: in default_restore_location\n",
      "    \u001B[0mresult = fn(storage, location)\u001B[90m\u001B[39;49;00m\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:636: in _deserialize\n",
      "    \u001B[0mdevice = _validate_device(location, backend_name)\u001B[90m\u001B[39;49;00m\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "location = 'cuda:0', backend_name = 'cuda'\n",
      "\n",
      "    \u001B[0m\u001B[94mdef\u001B[39;49;00m \u001B[92m_validate_device\u001B[39;49;00m(location, backend_name):\u001B[90m\u001B[39;49;00m\n",
      "    \u001B[90m    \u001B[39;49;00m\u001B[33m\"\"\"\u001B[39;49;00m\n",
      "    \u001B[33m    Check whether the device index of specified backend is valid\u001B[39;49;00m\n",
      "    \u001B[33m\u001B[39;49;00m\n",
      "    \u001B[33m    In case of privateuse1 backend, your must first register a device_module for\u001B[39;49;00m\n",
      "    \u001B[33m    privateuse1 using torch._register_device_module. Implement the following\u001B[39;49;00m\n",
      "    \u001B[33m    methods in device_module like cuda: device_module._utils._get_device_index(location, True),\u001B[39;49;00m\n",
      "    \u001B[33m    device_module.device_count().\u001B[39;49;00m\n",
      "    \u001B[33m\u001B[39;49;00m\n",
      "    \u001B[33m    Args:\u001B[39;49;00m\n",
      "    \u001B[33m        location: string of device\u001B[39;49;00m\n",
      "    \u001B[33m        backend_name: the backend name or the name of privateuse1, which can be renamed\u001B[39;49;00m\n",
      "    \u001B[33m\u001B[39;49;00m\n",
      "    \u001B[33m    Returns:\u001B[39;49;00m\n",
      "    \u001B[33m        device_index: int\u001B[39;49;00m\n",
      "    \u001B[33m    \"\"\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "        \u001B[94mif\u001B[39;49;00m \u001B[95mnot\u001B[39;49;00m \u001B[96mhasattr\u001B[39;49;00m(torch, backend_name):\u001B[90m\u001B[39;49;00m\n",
      "            \u001B[94mraise\u001B[39;49;00m \u001B[96mRuntimeError\u001B[39;49;00m(\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33mf\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[33mThe \u001B[39;49;00m\u001B[33m{\u001B[39;49;00mbackend_name.upper()\u001B[33m}\u001B[39;49;00m\u001B[33m device module is not registered. \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33m\"\u001B[39;49;00m\u001B[33mIf you are running on a CPU-only machine, \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33m\"\u001B[39;49;00m\u001B[33mplease use torch.load with map_location=torch.device(\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m\u001B[33mcpu\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m\u001B[33m) \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33m\"\u001B[39;49;00m\u001B[33mto map your storages to the CPU.\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "            )\u001B[90m\u001B[39;49;00m\n",
      "        device_module = \u001B[96mgetattr\u001B[39;49;00m(torch, backend_name)\u001B[90m\u001B[39;49;00m\n",
      "        \u001B[94mif\u001B[39;49;00m \u001B[96mhasattr\u001B[39;49;00m(device_module, \u001B[33m\"\u001B[39;49;00m\u001B[33m_utils\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m) \u001B[95mand\u001B[39;49;00m \u001B[96mhasattr\u001B[39;49;00m(\u001B[90m\u001B[39;49;00m\n",
      "            device_module._utils, \u001B[33m\"\u001B[39;49;00m\u001B[33m_get_device_index\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "        ):\u001B[90m\u001B[39;49;00m\n",
      "            device_index = device_module._utils._get_device_index(location, \u001B[94mTrue\u001B[39;49;00m)\u001B[90m\u001B[39;49;00m\n",
      "            device = torch.device(backend_name, device_index)\u001B[90m\u001B[39;49;00m\n",
      "        \u001B[94melse\u001B[39;49;00m:\u001B[90m\u001B[39;49;00m\n",
      "            device = torch.device(location)\u001B[90m\u001B[39;49;00m\n",
      "            device_index = device.index \u001B[94mif\u001B[39;49;00m device.index \u001B[94melse\u001B[39;49;00m \u001B[94m0\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "        \u001B[94mif\u001B[39;49;00m \u001B[96mhasattr\u001B[39;49;00m(device_module, \u001B[33m\"\u001B[39;49;00m\u001B[33mis_available\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m) \u001B[95mand\u001B[39;49;00m \u001B[95mnot\u001B[39;49;00m device_module.is_available():\u001B[90m\u001B[39;49;00m\n",
      ">           \u001B[94mraise\u001B[39;49;00m \u001B[96mRuntimeError\u001B[39;49;00m(\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33mf\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[33mAttempting to deserialize object on a \u001B[39;49;00m\u001B[33m{\u001B[39;49;00mbackend_name.upper()\u001B[33m}\u001B[39;49;00m\u001B[33m \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33mf\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[33mdevice but torch.\u001B[39;49;00m\u001B[33m{\u001B[39;49;00mbackend_name\u001B[33m}\u001B[39;49;00m\u001B[33m.is_available() is False. \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33m\"\u001B[39;49;00m\u001B[33mIf you are running on a CPU-only machine, \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33m\"\u001B[39;49;00m\u001B[33mplease use torch.load with map_location=torch.device(\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m\u001B[33mcpu\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m\u001B[33m) \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33m\"\u001B[39;49;00m\u001B[33mto map your storages to the CPU.\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "            )\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31mE           RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.\u001B[0m\n",
      "\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:605: RuntimeError\n",
      "\u001B[31m\u001B[1m_____________ ERROR at setup of TestMyModel.test_accuracy_medium ______________\u001B[0m\n",
      "\n",
      "cls = <class 'tests.test_mymodel.TestMyModel'>\n",
      "\n",
      "    \u001B[0m\u001B[37m@classmethod\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "    \u001B[94mdef\u001B[39;49;00m \u001B[92msetUpClass\u001B[39;49;00m(\u001B[96mcls\u001B[39;49;00m):\u001B[90m\u001B[39;49;00m\n",
      "    \u001B[90m    \u001B[39;49;00m\u001B[33m\"\"\"Define the functions to be tested here.\"\"\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "        basedir = pathlib.Path(\u001B[91m__file__\u001B[39;49;00m).parent.parent.resolve()\u001B[90m\u001B[39;49;00m\n",
      "        model = MyModel()\u001B[90m\u001B[39;49;00m\n",
      "        model.eval()\u001B[90m\u001B[39;49;00m\n",
      "        model.load_state_dict(\u001B[90m\u001B[39;49;00m\n",
      ">           torch.load(\u001B[96mstr\u001B[39;49;00m(basedir) + \u001B[33m\"\u001B[39;49;00m\u001B[33m/checkpoints/mymodel.pth\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, weights_only=\u001B[94mTrue\u001B[39;49;00m)\u001B[90m\u001B[39;49;00m\n",
      "        )\u001B[90m\u001B[39;49;00m\n",
      "\n",
      "\u001B[1m\u001B[31mtests\\test_mymodel.py\u001B[0m:74: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:1521: in load\n",
      "    \u001B[0m\u001B[94mreturn\u001B[39;49;00m _load(\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:2119: in _load\n",
      "    \u001B[0mresult = unpickler.load()\u001B[90m\u001B[39;49;00m\n",
      "             ^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\_weights_only_unpickler.py\u001B[0m:532: in load\n",
      "    \u001B[0m\u001B[96mself\u001B[39;49;00m.append(\u001B[96mself\u001B[39;49;00m.persistent_load(pid))\u001B[90m\u001B[39;49;00m\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:2083: in persistent_load\n",
      "    \u001B[0mtyped_storage = load_tensor(\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:2049: in load_tensor\n",
      "    \u001B[0mwrap_storage = restore_location(storage, location)\u001B[90m\u001B[39;49;00m\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:698: in default_restore_location\n",
      "    \u001B[0mresult = fn(storage, location)\u001B[90m\u001B[39;49;00m\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:636: in _deserialize\n",
      "    \u001B[0mdevice = _validate_device(location, backend_name)\u001B[90m\u001B[39;49;00m\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "location = 'cuda:0', backend_name = 'cuda'\n",
      "\n",
      "    \u001B[0m\u001B[94mdef\u001B[39;49;00m \u001B[92m_validate_device\u001B[39;49;00m(location, backend_name):\u001B[90m\u001B[39;49;00m\n",
      "    \u001B[90m    \u001B[39;49;00m\u001B[33m\"\"\"\u001B[39;49;00m\n",
      "    \u001B[33m    Check whether the device index of specified backend is valid\u001B[39;49;00m\n",
      "    \u001B[33m\u001B[39;49;00m\n",
      "    \u001B[33m    In case of privateuse1 backend, your must first register a device_module for\u001B[39;49;00m\n",
      "    \u001B[33m    privateuse1 using torch._register_device_module. Implement the following\u001B[39;49;00m\n",
      "    \u001B[33m    methods in device_module like cuda: device_module._utils._get_device_index(location, True),\u001B[39;49;00m\n",
      "    \u001B[33m    device_module.device_count().\u001B[39;49;00m\n",
      "    \u001B[33m\u001B[39;49;00m\n",
      "    \u001B[33m    Args:\u001B[39;49;00m\n",
      "    \u001B[33m        location: string of device\u001B[39;49;00m\n",
      "    \u001B[33m        backend_name: the backend name or the name of privateuse1, which can be renamed\u001B[39;49;00m\n",
      "    \u001B[33m\u001B[39;49;00m\n",
      "    \u001B[33m    Returns:\u001B[39;49;00m\n",
      "    \u001B[33m        device_index: int\u001B[39;49;00m\n",
      "    \u001B[33m    \"\"\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "        \u001B[94mif\u001B[39;49;00m \u001B[95mnot\u001B[39;49;00m \u001B[96mhasattr\u001B[39;49;00m(torch, backend_name):\u001B[90m\u001B[39;49;00m\n",
      "            \u001B[94mraise\u001B[39;49;00m \u001B[96mRuntimeError\u001B[39;49;00m(\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33mf\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[33mThe \u001B[39;49;00m\u001B[33m{\u001B[39;49;00mbackend_name.upper()\u001B[33m}\u001B[39;49;00m\u001B[33m device module is not registered. \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33m\"\u001B[39;49;00m\u001B[33mIf you are running on a CPU-only machine, \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33m\"\u001B[39;49;00m\u001B[33mplease use torch.load with map_location=torch.device(\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m\u001B[33mcpu\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m\u001B[33m) \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33m\"\u001B[39;49;00m\u001B[33mto map your storages to the CPU.\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "            )\u001B[90m\u001B[39;49;00m\n",
      "        device_module = \u001B[96mgetattr\u001B[39;49;00m(torch, backend_name)\u001B[90m\u001B[39;49;00m\n",
      "        \u001B[94mif\u001B[39;49;00m \u001B[96mhasattr\u001B[39;49;00m(device_module, \u001B[33m\"\u001B[39;49;00m\u001B[33m_utils\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m) \u001B[95mand\u001B[39;49;00m \u001B[96mhasattr\u001B[39;49;00m(\u001B[90m\u001B[39;49;00m\n",
      "            device_module._utils, \u001B[33m\"\u001B[39;49;00m\u001B[33m_get_device_index\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "        ):\u001B[90m\u001B[39;49;00m\n",
      "            device_index = device_module._utils._get_device_index(location, \u001B[94mTrue\u001B[39;49;00m)\u001B[90m\u001B[39;49;00m\n",
      "            device = torch.device(backend_name, device_index)\u001B[90m\u001B[39;49;00m\n",
      "        \u001B[94melse\u001B[39;49;00m:\u001B[90m\u001B[39;49;00m\n",
      "            device = torch.device(location)\u001B[90m\u001B[39;49;00m\n",
      "            device_index = device.index \u001B[94mif\u001B[39;49;00m device.index \u001B[94melse\u001B[39;49;00m \u001B[94m0\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "        \u001B[94mif\u001B[39;49;00m \u001B[96mhasattr\u001B[39;49;00m(device_module, \u001B[33m\"\u001B[39;49;00m\u001B[33mis_available\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m) \u001B[95mand\u001B[39;49;00m \u001B[95mnot\u001B[39;49;00m device_module.is_available():\u001B[90m\u001B[39;49;00m\n",
      ">           \u001B[94mraise\u001B[39;49;00m \u001B[96mRuntimeError\u001B[39;49;00m(\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33mf\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[33mAttempting to deserialize object on a \u001B[39;49;00m\u001B[33m{\u001B[39;49;00mbackend_name.upper()\u001B[33m}\u001B[39;49;00m\u001B[33m \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33mf\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[33mdevice but torch.\u001B[39;49;00m\u001B[33m{\u001B[39;49;00mbackend_name\u001B[33m}\u001B[39;49;00m\u001B[33m.is_available() is False. \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33m\"\u001B[39;49;00m\u001B[33mIf you are running on a CPU-only machine, \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33m\"\u001B[39;49;00m\u001B[33mplease use torch.load with map_location=torch.device(\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m\u001B[33mcpu\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m\u001B[33m) \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33m\"\u001B[39;49;00m\u001B[33mto map your storages to the CPU.\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "            )\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31mE           RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.\u001B[0m\n",
      "\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:605: RuntimeError\n",
      "\u001B[36m\u001B[1m=========================== short test summary info ===========================\u001B[0m\n",
      "\u001B[31mERROR\u001B[0m tests/test_mymodel.py::\u001B[1mTestMyModel::test_accuracy_easy\u001B[0m - RuntimeError: Attempting to deserialize object on a CUDA device but torch.c...\n",
      "\u001B[31mERROR\u001B[0m tests/test_mymodel.py::\u001B[1mTestMyModel::test_accuracy_hard\u001B[0m - RuntimeError: Attempting to deserialize object on a CUDA device but torch.c...\n",
      "\u001B[31mERROR\u001B[0m tests/test_mymodel.py::\u001B[1mTestMyModel::test_accuracy_medium\u001B[0m - RuntimeError: Attempting to deserialize object on a CUDA device but torch.c...\n",
      "\u001B[31m============================== \u001B[31m\u001B[1m3 errors\u001B[0m\u001B[31m in 2.75s\u001B[0m\u001B[31m ==============================\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zaXbxcApKPNw",
    "outputId": "4a60cb85-9738-449d-d938-05a73656a5b6",
    "ExecuteTime": {
     "end_time": "2025-09-21T00:29:16.707147Z",
     "start_time": "2025-09-21T00:29:06.124282Z"
    }
   },
   "source": [
    "#Let's test your implementation of Vanilla CNN\n",
    "!pytest -s {GOOGLE_DRIVE_PATH + '/tests/test_vanilla_cnn.py'}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m============================= test session starts =============================\u001B[0m\n",
      "platform win32 -- Python 3.12.0, pytest-8.4.1, pluggy-1.5.0\n",
      "rootdir: C:\\Users\\julie\\CSE_7643_DL\\DL_PS2\\part2-pytorch\n",
      "plugins: anyio-4.7.0\n",
      "collected 1 item\n",
      "\n",
      "tests\\test_vanilla_cnn.py \u001B[32m.\u001B[0m\n",
      "\n",
      "\u001B[32m============================== \u001B[32m\u001B[1m1 passed\u001B[0m\u001B[32m in 9.45s\u001B[0m\u001B[32m ==============================\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D68rtzAZpzgc"
   },
   "source": [
    "# Data Wrangling\n",
    "So far we have worked with well-balanced datasets (samples of each class are\n",
    "evenly distributed). However, in practice, datasets are often not balanced.\n",
    "In this section, you will explore the limitation of standard training strategy\n",
    "on this type of dataset. This being an exploration, it is up to you to design\n",
    "experiments or tests to validate these methods are correct and effective.\n",
    "You will work with an unbalanced version of CIFAR-10 in this section, and you should use the ResNet-32 model in `./models/resnet.py`.\n",
    "\n",
    "## Class-Balanced Focal Loss\n",
    "You will implement one possible solution to the imbalance problem: ClassBalanced Focal Loss using this CVPR-19 paper [Class-Balanced Loss Based on Effective Number of Samples](https://arxiv.org/pdf/1901.05555.pdf). You may also refer to the original paper of [Focal Loss](https://arxiv.org/abs/1708.02002) for more details if you are interested. Please implement CB Focal\n",
    "Loss in `./losses/focal_loss.py`.\n",
    "\n",
    "**Note**: The CVPR-19 paper uses Sigmoid̲ CB focal loss (section 4). Softmax CB focal loss is not described in the paper, but it is easy to derive from the mentioned papers. You must implement the softmax version to pass the\n",
    "tests.\n",
    "\n",
    "Hint: Make sure you are using torch operations througout your focal loss implementation otherwise the torch computation graph will not be built properly."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FUEYEuHBpzgd",
    "ExecuteTime": {
     "end_time": "2025-09-22T18:05:40.961638Z",
     "start_time": "2025-09-22T18:05:38.662200Z"
    }
   },
   "source": [
    "# Test your Focal Loss implementation\n",
    "!pytest -s {GOOGLE_DRIVE_PATH + '/tests/test_focalloss.py'}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m============================= test session starts =============================\u001B[0m\n",
      "platform win32 -- Python 3.12.0, pytest-8.4.1, pluggy-1.5.0\n",
      "rootdir: C:\\Users\\julie\\CSE_7643_DL\\DL_PS2\\part2-pytorch\n",
      "plugins: anyio-4.7.0\n",
      "collected 2 items\n",
      "\n",
      "tests\\test_focalloss.py \u001B[32m.\u001B[0m\u001B[32m.\u001B[0m\n",
      "\n",
      "\u001B[32m============================== \u001B[32m\u001B[1m2 passed\u001B[0m\u001B[32m in 1.26s\u001B[0m\u001B[32m ==============================\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tidoClnYkFE4"
   },
   "source": [
    "Now, follow the instructions in the report template to obtain the best results possible for Resnet with regular CE loss (you may need to perform extra hyperparameter tuning). Then experiment with the beta parameter. Finally,  obtain the best possible results for Resnet using focal loss. You are welcome to change other hyperparameters in the config file as necessary. Make sure to set the `imbalance` config parameter as appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjZK5lqLFsor"
   },
   "source": [
    "# Submit Your Work\n",
    "After completing the notebook for this assignment (`assignment2_2.ipynb`), run the following cell to create a `.zip` file for you to download and then upload to Gradescope.\n",
    "\n",
    "**Please MANUALLY SAVE `*.py` files before executing the following cell:**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uPREUKv7FwPS",
    "ExecuteTime": {
     "end_time": "2025-09-24T06:29:29.003735Z",
     "start_time": "2025-09-24T06:29:28.475574Z"
    }
   },
   "source": [
    "from cs7643.submit import make_a2_2_submission\n",
    "\n",
    "make_a2_2_submission(GOOGLE_DRIVE_PATH)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing zip file to:  .\\assignment_2_2_submission.zip\n"
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "runtime_attributes": {
    "runtime_version": "2025.07"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
