{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MIkt4yxKpzgS"
   },
   "source": [
    "# CS 7643 Assignment 2 Part 2:  Implement and train a network on CIFAR-10 using Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5eLeqVzpzgV"
   },
   "source": [
    "Convolutional Neural Networks (CNNs) are one of the major advancements in\n",
    "computer vision over the past decade. In this assignment, you will complete\n",
    "a simple CNN architecture from scratch and learn how to implement CNNs\n",
    "with PyTorch, one of the most commonly used deep learning frameworks.\n",
    "You will also run different experiments on imbalanced datasets to evaluate\n",
    "your model and techniques to deal with imbalanced data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kx3nM2xMpzgW"
   },
   "source": [
    "# Setup Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l86tglWzpzgX"
   },
   "source": [
    "Before getting started we need to run some standard code to set up our environment. You'll need to execute this code again each time you start the notebook.\n",
    "\n",
    "First, run this cell to load the [autoreload](https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html?highlight=autoreload) extension. This enables us to modify `.py` source files and reintegrate them into the notebook, ensuring a smooth editing and debugging experience.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "j22uun9OpzgX",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1758413732313,
     "user_tz": 240,
     "elapsed": 74,
     "user": {
      "displayName": "Julie Cha",
      "userId": "02094140184777567318"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-09-21T00:27:33.839612Z",
     "start_time": "2025-09-21T00:27:33.788423Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9pOTy-9dpzgY"
   },
   "source": [
    "### Google Colab Setup\n",
    "Next we need to run a few commands to set up our environment on Google Colab. If you are running this notebook on a local machine you can skip this section.\n",
    "\n",
    "Run the following cell to mount your Google Drive. Follow the link, sign in to your Google account (the same account you used to store this notebook!)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zujgqHl3pzgZ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1758413770030,
     "user_tz": 240,
     "elapsed": 23129,
     "user": {
      "displayName": "Julie Cha",
      "userId": "02094140184777567318"
     }
    },
    "outputId": "368a1695-a05e-4551-bf41-5c66fd4bfa83",
    "ExecuteTime": {
     "end_time": "2025-09-21T00:28:12.239661Z",
     "start_time": "2025-09-21T00:28:12.177999Z"
    }
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[38], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgoogle\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcolab\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m drive\n\u001B[0;32m      2\u001B[0m drive\u001B[38;5;241m.\u001B[39mmount(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/content/drive\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'google.colab'"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAQYM7TWpzgZ"
   },
   "source": [
    "Now remember the path in your Google Drive where you uploaded this notebook, fill it in below. If all functions properly, executing the next cell should display the filenames from the assignment:\n",
    "\n",
    "```\n",
    "['CS7643-Assignment2-2.ipynb', 'cs7643', 'checkpoints', 'losses', 'configs', 'models', 'tests']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UiGZhhG8pzga",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1758413778024,
     "user_tz": 240,
     "elapsed": 2988,
     "user": {
      "displayName": "Julie Cha",
      "userId": "02094140184777567318"
     }
    },
    "outputId": "0ec53e81-80e6-40bc-9991-f6a1e895bc39",
    "ExecuteTime": {
     "end_time": "2025-09-21T00:28:14.913388Z",
     "start_time": "2025-09-21T00:28:14.849896Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "# TODO: Fill in the Google Drive path where you uploaded assignment1\n",
    "# Example: If you create a Fall2023 folder and put all the files under A1 folder, then 'Fall2023/A1'\\\n",
    "\n",
    "GOOGLE_DRIVE_PATH_POST_MYDRIVE = None\n",
    "# GOOGLE_DRIVE_PATH_POST_MYDRIVE = r\"CSE 7643 - DL/DL PS 2/DL_HW_2_collab/part2-pytorch\"\n",
    "\n",
    "GOOGLE_DRIVE_PATH = os.path.join('/content', 'drive', 'MyDrive', GOOGLE_DRIVE_PATH_POST_MYDRIVE)\n",
    "print(os.listdir(GOOGLE_DRIVE_PATH))"
   ],
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "join() argument must be str, bytes, or os.PathLike object, not 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[39], line 9\u001B[0m\n\u001B[0;32m      6\u001B[0m GOOGLE_DRIVE_PATH_POST_MYDRIVE \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# GOOGLE_DRIVE_PATH_POST_MYDRIVE = r\"CSE 7643 - DL/DL PS 2/DL_HW_2_collab/part2-pytorch\"\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m GOOGLE_DRIVE_PATH \u001B[38;5;241m=\u001B[39m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/content\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdrive\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mMyDrive\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mGOOGLE_DRIVE_PATH_POST_MYDRIVE\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m(os\u001B[38;5;241m.\u001B[39mlistdir(GOOGLE_DRIVE_PATH))\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\cs7643-a2\\Lib\\ntpath.py:149\u001B[0m, in \u001B[0;36mjoin\u001B[1;34m(path, *paths)\u001B[0m\n\u001B[0;32m    147\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result_drive \u001B[38;5;241m+\u001B[39m result_root \u001B[38;5;241m+\u001B[39m result_path\n\u001B[0;32m    148\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mAttributeError\u001B[39;00m, \u001B[38;5;167;01mBytesWarning\u001B[39;00m):\n\u001B[1;32m--> 149\u001B[0m     \u001B[43mgenericpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_arg_types\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mjoin\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpaths\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    150\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\cs7643-a2\\Lib\\genericpath.py:164\u001B[0m, in \u001B[0;36m_check_arg_types\u001B[1;34m(funcname, *args)\u001B[0m\n\u001B[0;32m    162\u001B[0m         hasbytes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    163\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 164\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfuncname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m() argument must be str, bytes, or \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    165\u001B[0m                         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mos.PathLike object, not \u001B[39m\u001B[38;5;132;01m{\u001B[39;00ms\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    166\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m hasstr \u001B[38;5;129;01mand\u001B[39;00m hasbytes:\n\u001B[0;32m    167\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCan\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt mix strings and bytes in path components\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mTypeError\u001B[0m: join() argument must be str, bytes, or os.PathLike object, not 'NoneType'"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svKml_u_mwNn"
   },
   "source": [
    "### Local Setup or Google Colab\n",
    "Run the cell below regardless of setup to set the path"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "itp51CmXmy03",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1758413782124,
     "user_tz": 240,
     "elapsed": 53,
     "user": {
      "displayName": "Julie Cha",
      "userId": "02094140184777567318"
     }
    },
    "outputId": "33fb5853-3e48-4759-a88c-df81678e32aa",
    "ExecuteTime": {
     "end_time": "2025-09-21T00:28:29.377654Z",
     "start_time": "2025-09-21T00:28:29.328058Z"
    }
   },
   "source": [
    "# if running locally set GOOGLE PATH\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "  print(f'Running in google colab. Our path is `{GOOGLE_DRIVE_PATH}`')\n",
    "else:\n",
    "  GOOGLE_DRIVE_PATH = '.'\n",
    "  print('Running locally.')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally.\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C48GISpDpzga"
   },
   "source": [
    "After successfully mounting your Google Drive and identifying the path to this assignment, execute the following cell to enable us to import from the `.py` files of this assignment. If it works correctly, it should print the message (note, you may need to retry this twice if it fails):\n",
    "\n",
    "```\n",
    "Roger that from cnn.py!\n",
    "Roger that from my_model.py!\n",
    "Roger that from resnet.py!\n",
    "Roger that from twolayer.py!\n",
    "\n",
    "Roger that from focal_loss.py!\n",
    "```\n",
    "\n",
    "as well as the last edit time for the files `cnn.py`, `my_model.py`, `resnet.py`, `twolayer.py`, and `focal_loss.py`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QeqHoG1Dpzga",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1758413821919,
     "user_tz": 240,
     "elapsed": 36353,
     "user": {
      "displayName": "Julie Cha",
      "userId": "02094140184777567318"
     }
    },
    "outputId": "55db4d2b-9639-4981-f773-5324bfbf97e0",
    "ExecuteTime": {
     "end_time": "2025-09-21T00:28:33.070273Z",
     "start_time": "2025-09-21T00:28:33.019194Z"
    }
   },
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "sys.path.append(GOOGLE_DRIVE_PATH)\n",
    "\n",
    "from cs7643.env_prob import say_hello_do_you_copy\n",
    "\n",
    "say_hello_do_you_copy(GOOGLE_DRIVE_PATH)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Models ------------------\n",
      "Roger that from cnn.py!\n",
      "Roger that from my_model.py!\n",
      "Roger that from resnet.py!\n",
      "Roger that from twolayer.py!\n",
      "cnn.py last edited on Sat Sep 20 19:48:59 2025\n",
      "my_model.py last edited on Sat Sep 20 19:51:37 2025\n",
      "resnet.py last edited on Mon Sep  8 20:15:29 2025\n",
      "twolayer.py last edited on Sat Sep 20 18:09:41 2025\n",
      "\n",
      "---------- Losses ------------------\n",
      "Roger that from focal_loss.py!\n",
      "focal_loss.py last edited on Mon Sep  8 20:15:29 2025\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rev2Ozk1KGj3"
   },
   "source": [
    "# Load the CIFAR10 dataset\n",
    "Data loading is the very first step of any machine learning pipelines. Run the following cell to download the CIFAR10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kHlccnRMKXTw",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1758413842741,
     "user_tz": 240,
     "elapsed": 14974,
     "user": {
      "displayName": "Julie Cha",
      "userId": "02094140184777567318"
     }
    },
    "outputId": "140e9d1b-c7bb-4b8b-ca0e-14c37412313d",
    "ExecuteTime": {
     "end_time": "2025-09-21T00:28:36.855008Z",
     "start_time": "2025-09-21T00:28:36.092480Z"
    }
   },
   "source": [
    "from cs7643.cifar10 import CIFAR10\n",
    "\n",
    "cifar10_ds = CIFAR10(GOOGLE_DRIVE_PATH + '/data/cifar10', download=True, train=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pf2FgYgT3W03"
   },
   "source": [
    "We will use GPUs to accelerate our computation in this notebook. Run the following to make sure GPUs are enabled:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kuHZ057d3Uwx",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1758413869728,
     "user_tz": 240,
     "elapsed": 210,
     "user": {
      "displayName": "Julie Cha",
      "userId": "02094140184777567318"
     }
    },
    "outputId": "b1c313fa-fc37-46a1-aa94-9e6cd492d914",
    "ExecuteTime": {
     "end_time": "2025-09-21T00:28:49.325066Z",
     "start_time": "2025-09-21T00:28:49.273633Z"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "device = 'mps' if torch.backends.mps.is_available() else ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device = \" + device)\n",
    "if device == 'cpu':\n",
    "    print(\"WARNING: Using CPU will cause slower train times\")\n",
    "\n",
    "# !nvidia-smi\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device = cpu\n",
      "WARNING: Using CPU will cause slower train times\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tgfHDh0pzgb"
   },
   "source": [
    "# Training\n",
    "The first thing of working with PyTorch is to get yourself familiarized with\n",
    "the basic training step of PyTorch. Read through the [PyTorch Tutorial](https://pytorch.org/tutorials/beginner/basics/intro.html) and complete __compute_loss_update_params_ function in `./solver.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AuL2J65znk9R"
   },
   "source": [
    "## PyTorch Model\n",
    "You will now implement some actual networks with PyTorch. We provide\n",
    "some starter files for you in `./models`. The models for you to implement are\n",
    "as follows:\n",
    "\n",
    "* **Two-Layer Network**. This is the same network you have implemented from scratch in assignment 1. You will build the model with two fully connected layers and a sigmoid activation function in between the two layers. Please implement the model as instructed in `./models/twolayer.py`.\n",
    "\n",
    "* **Vanilla Convolutional Neural Network**. You will build the model with a\n",
    "convolution layer, a ReLU activation, a max-pooling layer, followed by a fully connected layer for classification. Your convolution layer should use **32 output channels**, a **kernel size of 7** with **stride 1** and **zero padding**. You max-pooling should use a **kernel size of 2** and **stride of 2**. The fully connected layer should have **10 output features**. Please implement the model as instructed in `./models/cnn.py`.\n",
    "\n",
    "* Your Own Network. You are now free to build your own model. Notice that it's okay for you to borrow some insights from existing well-known networks, however, directly using those networks as-is is **NOT** allowed.\n",
    "In other words, you have to build your model from scratch, which also means using any sort of pre-trained weights is also **NOT** allowed. Please implement your model in `./models/my_model.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JgEN4027oF9j"
   },
   "source": [
    "We provide you configuration files for these three models respectively. For\n",
    "Two-Layer Network and Vanilla CNN, you need to train the model without modifying the configuration file. The script automatically saves the weights of the best model at the end of training. We will evaluate your implementation by loading your model weights and evaluating the model on CIFAR-10 test data. You should expect the accuracy of Two-Layer Network and Vanilla CNN to be around 0.3 and 0.4 respectively.\n",
    "\n",
    "For your own network, you are free to tune any hyper-parameters to\n",
    "obtain better accuracy. Your final accuracy must be above 0.5 to receive\n",
    "at least partial credit. Please refer to the GradeScope auto-test results\n",
    "for the requirement of full credits. Try to keep your submission **under\n",
    "100mb or GradeScope may not accept it**. All in all, please make sure\n",
    "the checkpoints of each model are saved into `./checkpoints`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vbYkRflMMQR-"
   },
   "source": [
    "Select a configuration file from the list then run the cell to train your model. To select a custom config, select \"Show code\" and specify the path to your config file. **Note that you may have to restart the jupyter kernel after updating the files above before running the below snippet.**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "G4HceY6Fy2vx",
    "ExecuteTime": {
     "end_time": "2025-09-20T23:51:49.257886Z",
     "start_time": "2025-09-20T23:51:43.285066Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1758414190179,
     "user_tz": 240,
     "elapsed": 308301,
     "user": {
      "displayName": "Julie Cha",
      "userId": "02094140184777567318"
     }
    },
    "outputId": "03502e9a-8e1b-437b-820e-e2eb3684d1f0"
   },
   "source": [
    "import yaml\n",
    "from solver import Solver\n",
    "\n",
    "#CHANGE HERE FOR EACH MODEL!!\n",
    "config_file = \"config_mymodel\" # feel free to change to  [\"config_mymodel\", \"config_twolayer\", \"config_vanilla_cnn\", or other]\n",
    "\n",
    "config_file = GOOGLE_DRIVE_PATH + \"/configs/\" + config_file + \".yaml\"\n",
    "\n",
    "print(\"Training a model using configuration file \" + config_file)\n",
    "\n",
    "with open(config_file, \"r\") as read_file:\n",
    "  config = yaml.safe_load(read_file)\n",
    "\n",
    "kwargs = {}\n",
    "for key in config:\n",
    "  for k, v in config[key].items():\n",
    "    if k != 'description':\n",
    "      kwargs[k] = v\n",
    "\n",
    "kwargs['device'] = device\n",
    "kwargs['path_prefix'] = GOOGLE_DRIVE_PATH\n",
    "\n",
    "print(kwargs)\n",
    "\n",
    "solver = Solver(**kwargs)\n",
    "solver.train()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training a model using configuration file /content/drive/MyDrive/CSE 7643 - DL/DL PS 2/DL_HW_2_collab/part2-pytorch/configs/config_mymodel.yaml\n",
      "{'batch_size': 128, 'learning_rate': 0.01, 'reg': 0.0005, 'epochs': 10, 'steps': [6, 8], 'warmup': 0, 'momentum': 0.9, 'gamma': 1, 'model': 'MyModel', 'imbalance': 'regular', 'save_best': True, 'loss_type': 'CE', 'device': 'cuda', 'path_prefix': '/content/drive/MyDrive/CSE 7643 - DL/DL PS 2/DL_HW_2_collab/part2-pytorch'}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 170M/170M [00:35<00:00, 4.86MB/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MyModel(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
      "  (fc3): Linear(in_features=60, out_features=10, bias=True)\n",
      ")\n",
      "Epoch: [0][0/391]\tTime 6.543 (6.543)\tLoss 2.3086 (2.3086)\tPrec @1 0.0625 (0.0625)\t\n",
      "Epoch: [0][10/391]\tTime 0.004 (0.608)\tLoss 2.2999 (2.3021)\tPrec @1 0.1484 (0.1087)\t\n",
      "Epoch: [0][20/391]\tTime 0.004 (0.320)\tLoss 2.2975 (2.2998)\tPrec @1 0.1172 (0.1090)\t\n",
      "Epoch: [0][30/391]\tTime 0.004 (0.218)\tLoss 2.2960 (2.2965)\tPrec @1 0.0781 (0.1137)\t\n",
      "Epoch: [0][40/391]\tTime 0.004 (0.166)\tLoss 2.2633 (2.2926)\tPrec @1 0.1406 (0.1139)\t\n",
      "Epoch: [0][50/391]\tTime 0.003 (0.134)\tLoss 2.2785 (2.2875)\tPrec @1 0.1328 (0.1134)\t\n",
      "Epoch: [0][60/391]\tTime 0.004 (0.113)\tLoss 2.2189 (2.2809)\tPrec @1 0.1953 (0.1195)\t\n",
      "Epoch: [0][70/391]\tTime 0.004 (0.097)\tLoss 2.1983 (2.2724)\tPrec @1 0.1562 (0.1261)\t\n",
      "Epoch: [0][80/391]\tTime 0.004 (0.086)\tLoss 2.1326 (2.2616)\tPrec @1 0.2109 (0.1339)\t\n",
      "Epoch: [0][90/391]\tTime 0.004 (0.077)\tLoss 2.1609 (2.2500)\tPrec @1 0.1953 (0.1410)\t\n",
      "Epoch: [0][100/391]\tTime 0.004 (0.070)\tLoss 2.0319 (2.2364)\tPrec @1 0.2266 (0.1470)\t\n",
      "Epoch: [0][110/391]\tTime 0.004 (0.064)\tLoss 2.0899 (2.2225)\tPrec @1 0.2031 (0.1514)\t\n",
      "Epoch: [0][120/391]\tTime 0.004 (0.059)\tLoss 2.0018 (2.2084)\tPrec @1 0.2266 (0.1575)\t\n",
      "Epoch: [0][130/391]\tTime 0.005 (0.055)\tLoss 1.9826 (2.1942)\tPrec @1 0.2344 (0.1638)\t\n",
      "Epoch: [0][140/391]\tTime 0.004 (0.051)\tLoss 2.0015 (2.1816)\tPrec @1 0.2734 (0.1698)\t\n",
      "Epoch: [0][150/391]\tTime 0.004 (0.048)\tLoss 1.9198 (2.1698)\tPrec @1 0.3750 (0.1760)\t\n",
      "Epoch: [0][160/391]\tTime 0.004 (0.045)\tLoss 1.9123 (2.1566)\tPrec @1 0.2734 (0.1813)\t\n",
      "Epoch: [0][170/391]\tTime 0.003 (0.043)\tLoss 1.9888 (2.1451)\tPrec @1 0.2656 (0.1870)\t\n",
      "Epoch: [0][180/391]\tTime 0.004 (0.041)\tLoss 1.9925 (2.1330)\tPrec @1 0.2266 (0.1929)\t\n",
      "Epoch: [0][190/391]\tTime 0.003 (0.039)\tLoss 1.9817 (2.1206)\tPrec @1 0.3281 (0.1985)\t\n",
      "Epoch: [0][200/391]\tTime 0.004 (0.037)\tLoss 1.9239 (2.1100)\tPrec @1 0.2734 (0.2022)\t\n",
      "Epoch: [0][210/391]\tTime 0.004 (0.035)\tLoss 1.7568 (2.0996)\tPrec @1 0.3984 (0.2072)\t\n",
      "Epoch: [0][220/391]\tTime 0.004 (0.034)\tLoss 1.9392 (2.0888)\tPrec @1 0.2969 (0.2101)\t\n",
      "Epoch: [0][230/391]\tTime 0.004 (0.033)\tLoss 1.8588 (2.0798)\tPrec @1 0.2812 (0.2132)\t\n",
      "Epoch: [0][240/391]\tTime 0.004 (0.031)\tLoss 1.8745 (2.0713)\tPrec @1 0.2891 (0.2162)\t\n",
      "Epoch: [0][250/391]\tTime 0.004 (0.030)\tLoss 1.8616 (2.0628)\tPrec @1 0.2969 (0.2195)\t\n",
      "Epoch: [0][260/391]\tTime 0.004 (0.029)\tLoss 1.8698 (2.0552)\tPrec @1 0.3359 (0.2228)\t\n",
      "Epoch: [0][270/391]\tTime 0.004 (0.028)\tLoss 1.8587 (2.0470)\tPrec @1 0.3047 (0.2259)\t\n",
      "Epoch: [0][280/391]\tTime 0.004 (0.028)\tLoss 1.8612 (2.0375)\tPrec @1 0.3125 (0.2295)\t\n",
      "Epoch: [0][290/391]\tTime 0.003 (0.027)\tLoss 1.7598 (2.0284)\tPrec @1 0.2734 (0.2332)\t\n",
      "Epoch: [0][300/391]\tTime 0.004 (0.026)\tLoss 1.7940 (2.0202)\tPrec @1 0.2812 (0.2360)\t\n",
      "Epoch: [0][310/391]\tTime 0.004 (0.025)\tLoss 1.6917 (2.0121)\tPrec @1 0.3906 (0.2396)\t\n",
      "Epoch: [0][320/391]\tTime 0.004 (0.025)\tLoss 1.5824 (2.0039)\tPrec @1 0.4297 (0.2432)\t\n",
      "Epoch: [0][330/391]\tTime 0.004 (0.024)\tLoss 1.7467 (1.9961)\tPrec @1 0.3359 (0.2467)\t\n",
      "Epoch: [0][340/391]\tTime 0.005 (0.023)\tLoss 1.7043 (1.9876)\tPrec @1 0.3125 (0.2500)\t\n",
      "Epoch: [0][350/391]\tTime 0.004 (0.023)\tLoss 1.7985 (1.9811)\tPrec @1 0.3516 (0.2531)\t\n",
      "Epoch: [0][360/391]\tTime 0.004 (0.022)\tLoss 1.6691 (1.9741)\tPrec @1 0.3516 (0.2565)\t\n",
      "Epoch: [0][370/391]\tTime 0.004 (0.022)\tLoss 1.5858 (1.9664)\tPrec @1 0.4297 (0.2597)\t\n",
      "Epoch: [0][380/391]\tTime 0.004 (0.021)\tLoss 1.5798 (1.9589)\tPrec @1 0.4609 (0.2629)\t\n",
      "Epoch: [0][390/391]\tTime 0.006 (0.021)\tLoss 1.7335 (1.9524)\tPrec @1 0.3750 (0.2660)\t\n",
      "Epoch: [0][0/100]\tTime 0.031 (0.031)\t\n",
      "Epoch: [0][10/100]\tTime 0.014 (0.021)\t\n",
      "Epoch: [0][20/100]\tTime 0.016 (0.021)\t\n",
      "Epoch: [0][30/100]\tTime 0.014 (0.022)\t\n",
      "Epoch: [0][40/100]\tTime 0.027 (0.022)\t\n",
      "Epoch: [0][50/100]\tTime 0.028 (0.022)\t\n",
      "Epoch: [0][60/100]\tTime 0.024 (0.022)\t\n",
      "Epoch: [0][70/100]\tTime 0.015 (0.022)\t\n",
      "Epoch: [0][80/100]\tTime 0.014 (0.021)\t\n",
      "Epoch: [0][90/100]\tTime 0.021 (0.021)\t\n",
      "Accuracy of Class 0: 0.4810\n",
      "Accuracy of Class 1: 0.6540\n",
      "Accuracy of Class 2: 0.0850\n",
      "Accuracy of Class 3: 0.0890\n",
      "Accuracy of Class 4: 0.3590\n",
      "Accuracy of Class 5: 0.3980\n",
      "Accuracy of Class 6: 0.4920\n",
      "Accuracy of Class 7: 0.6340\n",
      "Accuracy of Class 8: 0.5030\n",
      "Accuracy of Class 9: 0.3650\n",
      "* Prec @1: 0.4060\n",
      "Epoch: [1][0/391]\tTime 0.004 (0.004)\tLoss 1.6185 (1.6185)\tPrec @1 0.3984 (0.3984)\t\n",
      "Epoch: [1][10/391]\tTime 0.004 (0.004)\tLoss 1.7682 (1.6766)\tPrec @1 0.2969 (0.3743)\t\n",
      "Epoch: [1][20/391]\tTime 0.004 (0.004)\tLoss 1.8208 (1.6842)\tPrec @1 0.3750 (0.3754)\t\n",
      "Epoch: [1][30/391]\tTime 0.004 (0.004)\tLoss 1.5923 (1.6898)\tPrec @1 0.4062 (0.3742)\t\n",
      "Epoch: [1][40/391]\tTime 0.003 (0.004)\tLoss 1.7086 (1.6929)\tPrec @1 0.3672 (0.3721)\t\n",
      "Epoch: [1][50/391]\tTime 0.004 (0.004)\tLoss 1.6305 (1.6942)\tPrec @1 0.4062 (0.3718)\t\n",
      "Epoch: [1][60/391]\tTime 0.004 (0.004)\tLoss 1.7529 (1.6862)\tPrec @1 0.3672 (0.3755)\t\n",
      "Epoch: [1][70/391]\tTime 0.004 (0.004)\tLoss 1.8008 (1.6838)\tPrec @1 0.3359 (0.3746)\t\n",
      "Epoch: [1][80/391]\tTime 0.004 (0.004)\tLoss 1.6395 (1.6842)\tPrec @1 0.3906 (0.3735)\t\n",
      "Epoch: [1][90/391]\tTime 0.004 (0.004)\tLoss 1.6783 (1.6804)\tPrec @1 0.3516 (0.3750)\t\n",
      "Epoch: [1][100/391]\tTime 0.004 (0.004)\tLoss 1.6564 (1.6729)\tPrec @1 0.3750 (0.3777)\t\n",
      "Epoch: [1][110/391]\tTime 0.004 (0.004)\tLoss 1.6509 (1.6687)\tPrec @1 0.3984 (0.3798)\t\n",
      "Epoch: [1][120/391]\tTime 0.005 (0.004)\tLoss 1.7631 (1.6688)\tPrec @1 0.3672 (0.3789)\t\n",
      "Epoch: [1][130/391]\tTime 0.004 (0.004)\tLoss 1.4773 (1.6656)\tPrec @1 0.4141 (0.3787)\t\n",
      "Epoch: [1][140/391]\tTime 0.004 (0.004)\tLoss 1.6446 (1.6619)\tPrec @1 0.3906 (0.3797)\t\n",
      "Epoch: [1][150/391]\tTime 0.004 (0.004)\tLoss 1.6100 (1.6559)\tPrec @1 0.3984 (0.3819)\t\n",
      "Epoch: [1][160/391]\tTime 0.004 (0.004)\tLoss 1.6336 (1.6508)\tPrec @1 0.3984 (0.3853)\t\n",
      "Epoch: [1][170/391]\tTime 0.003 (0.004)\tLoss 1.5730 (1.6446)\tPrec @1 0.4141 (0.3880)\t\n",
      "Epoch: [1][180/391]\tTime 0.004 (0.004)\tLoss 1.6067 (1.6418)\tPrec @1 0.4141 (0.3898)\t\n",
      "Epoch: [1][190/391]\tTime 0.004 (0.004)\tLoss 1.6914 (1.6391)\tPrec @1 0.3594 (0.3906)\t\n",
      "Epoch: [1][200/391]\tTime 0.004 (0.004)\tLoss 1.4685 (1.6335)\tPrec @1 0.4453 (0.3935)\t\n",
      "Epoch: [1][210/391]\tTime 0.004 (0.004)\tLoss 1.7072 (1.6306)\tPrec @1 0.3906 (0.3952)\t\n",
      "Epoch: [1][220/391]\tTime 0.004 (0.004)\tLoss 1.5116 (1.6283)\tPrec @1 0.3906 (0.3965)\t\n",
      "Epoch: [1][230/391]\tTime 0.004 (0.004)\tLoss 1.4696 (1.6244)\tPrec @1 0.4922 (0.3977)\t\n",
      "Epoch: [1][240/391]\tTime 0.004 (0.004)\tLoss 1.5988 (1.6222)\tPrec @1 0.4141 (0.3982)\t\n",
      "Epoch: [1][250/391]\tTime 0.004 (0.004)\tLoss 1.5910 (1.6206)\tPrec @1 0.4219 (0.3987)\t\n",
      "Epoch: [1][260/391]\tTime 0.004 (0.004)\tLoss 1.5999 (1.6194)\tPrec @1 0.4297 (0.3997)\t\n",
      "Epoch: [1][270/391]\tTime 0.004 (0.004)\tLoss 1.5207 (1.6154)\tPrec @1 0.3750 (0.4007)\t\n",
      "Epoch: [1][280/391]\tTime 0.004 (0.004)\tLoss 1.5077 (1.6104)\tPrec @1 0.4375 (0.4027)\t\n",
      "Epoch: [1][290/391]\tTime 0.004 (0.004)\tLoss 1.5356 (1.6069)\tPrec @1 0.4531 (0.4049)\t\n",
      "Epoch: [1][300/391]\tTime 0.004 (0.004)\tLoss 1.6321 (1.6045)\tPrec @1 0.4219 (0.4057)\t\n",
      "Epoch: [1][310/391]\tTime 0.003 (0.004)\tLoss 1.4589 (1.6012)\tPrec @1 0.3750 (0.4069)\t\n",
      "Epoch: [1][320/391]\tTime 0.004 (0.004)\tLoss 1.4976 (1.5978)\tPrec @1 0.4844 (0.4079)\t\n",
      "Epoch: [1][330/391]\tTime 0.004 (0.004)\tLoss 1.5038 (1.5943)\tPrec @1 0.4453 (0.4091)\t\n",
      "Epoch: [1][340/391]\tTime 0.004 (0.004)\tLoss 1.6817 (1.5931)\tPrec @1 0.3516 (0.4095)\t\n",
      "Epoch: [1][350/391]\tTime 0.004 (0.004)\tLoss 1.4208 (1.5902)\tPrec @1 0.4609 (0.4108)\t\n",
      "Epoch: [1][360/391]\tTime 0.004 (0.004)\tLoss 1.5928 (1.5879)\tPrec @1 0.3984 (0.4115)\t\n",
      "Epoch: [1][370/391]\tTime 0.005 (0.004)\tLoss 1.5007 (1.5859)\tPrec @1 0.4531 (0.4128)\t\n",
      "Epoch: [1][380/391]\tTime 0.004 (0.004)\tLoss 1.2840 (1.5829)\tPrec @1 0.6250 (0.4143)\t\n",
      "Epoch: [1][390/391]\tTime 0.003 (0.004)\tLoss 1.6296 (1.5810)\tPrec @1 0.4125 (0.4150)\t\n",
      "Epoch: [1][0/100]\tTime 0.036 (0.036)\t\n",
      "Epoch: [1][10/100]\tTime 0.032 (0.025)\t\n",
      "Epoch: [1][20/100]\tTime 0.038 (0.026)\t\n",
      "Epoch: [1][30/100]\tTime 0.029 (0.028)\t\n",
      "Epoch: [1][40/100]\tTime 0.030 (0.029)\t\n",
      "Epoch: [1][50/100]\tTime 0.039 (0.028)\t\n",
      "Epoch: [1][60/100]\tTime 0.027 (0.028)\t\n",
      "Epoch: [1][70/100]\tTime 0.014 (0.027)\t\n",
      "Epoch: [1][80/100]\tTime 0.020 (0.026)\t\n",
      "Epoch: [1][90/100]\tTime 0.021 (0.025)\t\n",
      "Accuracy of Class 0: 0.5770\n",
      "Accuracy of Class 1: 0.6690\n",
      "Accuracy of Class 2: 0.2480\n",
      "Accuracy of Class 3: 0.1770\n",
      "Accuracy of Class 4: 0.2690\n",
      "Accuracy of Class 5: 0.5390\n",
      "Accuracy of Class 6: 0.7080\n",
      "Accuracy of Class 7: 0.6750\n",
      "Accuracy of Class 8: 0.6250\n",
      "Accuracy of Class 9: 0.5990\n",
      "* Prec @1: 0.5086\n",
      "Epoch: [2][0/391]\tTime 0.004 (0.004)\tLoss 1.3696 (1.3696)\tPrec @1 0.5391 (0.5391)\t\n",
      "Epoch: [2][10/391]\tTime 0.004 (0.004)\tLoss 1.4568 (1.4705)\tPrec @1 0.4453 (0.4652)\t\n",
      "Epoch: [2][20/391]\tTime 0.004 (0.004)\tLoss 1.3511 (1.4618)\tPrec @1 0.4531 (0.4587)\t\n",
      "Epoch: [2][30/391]\tTime 0.004 (0.004)\tLoss 1.4579 (1.4560)\tPrec @1 0.4766 (0.4672)\t\n",
      "Epoch: [2][40/391]\tTime 0.004 (0.004)\tLoss 1.3718 (1.4425)\tPrec @1 0.5156 (0.4769)\t\n",
      "Epoch: [2][50/391]\tTime 0.004 (0.004)\tLoss 1.2837 (1.4534)\tPrec @1 0.5000 (0.4703)\t\n",
      "Epoch: [2][60/391]\tTime 0.004 (0.004)\tLoss 1.2952 (1.4503)\tPrec @1 0.5312 (0.4709)\t\n",
      "Epoch: [2][70/391]\tTime 0.004 (0.004)\tLoss 1.3854 (1.4420)\tPrec @1 0.4531 (0.4733)\t\n",
      "Epoch: [2][80/391]\tTime 0.004 (0.004)\tLoss 1.4558 (1.4440)\tPrec @1 0.4531 (0.4720)\t\n",
      "Epoch: [2][90/391]\tTime 0.004 (0.004)\tLoss 1.3832 (1.4476)\tPrec @1 0.4766 (0.4710)\t\n",
      "Epoch: [2][100/391]\tTime 0.005 (0.004)\tLoss 1.5761 (1.4496)\tPrec @1 0.4297 (0.4722)\t\n",
      "Epoch: [2][110/391]\tTime 0.004 (0.004)\tLoss 1.4922 (1.4532)\tPrec @1 0.4453 (0.4701)\t\n",
      "Epoch: [2][120/391]\tTime 0.004 (0.004)\tLoss 1.4553 (1.4553)\tPrec @1 0.4375 (0.4698)\t\n",
      "Epoch: [2][130/391]\tTime 0.004 (0.004)\tLoss 1.3660 (1.4574)\tPrec @1 0.5000 (0.4705)\t\n",
      "Epoch: [2][140/391]\tTime 0.004 (0.004)\tLoss 1.3528 (1.4554)\tPrec @1 0.5000 (0.4716)\t\n",
      "Epoch: [2][150/391]\tTime 0.004 (0.004)\tLoss 1.5173 (1.4532)\tPrec @1 0.4766 (0.4722)\t\n",
      "Epoch: [2][160/391]\tTime 0.004 (0.004)\tLoss 1.6182 (1.4548)\tPrec @1 0.4531 (0.4722)\t\n",
      "Epoch: [2][170/391]\tTime 0.004 (0.004)\tLoss 1.4980 (1.4526)\tPrec @1 0.5156 (0.4731)\t\n",
      "Epoch: [2][180/391]\tTime 0.006 (0.004)\tLoss 1.5688 (1.4509)\tPrec @1 0.4375 (0.4729)\t\n",
      "Epoch: [2][190/391]\tTime 0.004 (0.004)\tLoss 1.4590 (1.4510)\tPrec @1 0.4688 (0.4726)\t\n",
      "Epoch: [2][200/391]\tTime 0.004 (0.004)\tLoss 1.4135 (1.4472)\tPrec @1 0.4922 (0.4742)\t\n",
      "Epoch: [2][210/391]\tTime 0.004 (0.004)\tLoss 1.5045 (1.4437)\tPrec @1 0.4453 (0.4754)\t\n",
      "Epoch: [2][220/391]\tTime 0.005 (0.004)\tLoss 1.4424 (1.4422)\tPrec @1 0.4766 (0.4762)\t\n",
      "Epoch: [2][230/391]\tTime 0.004 (0.004)\tLoss 1.4175 (1.4403)\tPrec @1 0.5234 (0.4771)\t\n",
      "Epoch: [2][240/391]\tTime 0.004 (0.004)\tLoss 1.1556 (1.4355)\tPrec @1 0.5234 (0.4787)\t\n",
      "Epoch: [2][250/391]\tTime 0.004 (0.004)\tLoss 1.6154 (1.4357)\tPrec @1 0.4141 (0.4790)\t\n",
      "Epoch: [2][260/391]\tTime 0.004 (0.004)\tLoss 1.1975 (1.4327)\tPrec @1 0.5859 (0.4805)\t\n",
      "Epoch: [2][270/391]\tTime 0.004 (0.004)\tLoss 1.2978 (1.4306)\tPrec @1 0.5078 (0.4811)\t\n",
      "Epoch: [2][280/391]\tTime 0.003 (0.004)\tLoss 1.3438 (1.4290)\tPrec @1 0.4609 (0.4822)\t\n",
      "Epoch: [2][290/391]\tTime 0.004 (0.004)\tLoss 1.6767 (1.4295)\tPrec @1 0.4062 (0.4820)\t\n",
      "Epoch: [2][300/391]\tTime 0.004 (0.004)\tLoss 1.3706 (1.4285)\tPrec @1 0.5391 (0.4820)\t\n",
      "Epoch: [2][310/391]\tTime 0.004 (0.004)\tLoss 1.2267 (1.4267)\tPrec @1 0.5547 (0.4824)\t\n",
      "Epoch: [2][320/391]\tTime 0.004 (0.004)\tLoss 1.3358 (1.4251)\tPrec @1 0.4531 (0.4829)\t\n",
      "Epoch: [2][330/391]\tTime 0.004 (0.004)\tLoss 1.4966 (1.4223)\tPrec @1 0.4766 (0.4836)\t\n",
      "Epoch: [2][340/391]\tTime 0.004 (0.004)\tLoss 1.3241 (1.4210)\tPrec @1 0.5391 (0.4841)\t\n",
      "Epoch: [2][350/391]\tTime 0.004 (0.004)\tLoss 1.4061 (1.4193)\tPrec @1 0.4922 (0.4852)\t\n",
      "Epoch: [2][360/391]\tTime 0.004 (0.004)\tLoss 1.3721 (1.4169)\tPrec @1 0.4609 (0.4858)\t\n",
      "Epoch: [2][370/391]\tTime 0.004 (0.004)\tLoss 1.5408 (1.4164)\tPrec @1 0.4453 (0.4861)\t\n",
      "Epoch: [2][380/391]\tTime 0.004 (0.004)\tLoss 1.5101 (1.4149)\tPrec @1 0.4062 (0.4867)\t\n",
      "Epoch: [2][390/391]\tTime 0.003 (0.004)\tLoss 1.4386 (1.4143)\tPrec @1 0.5000 (0.4872)\t\n",
      "Epoch: [2][0/100]\tTime 0.024 (0.024)\t\n",
      "Epoch: [2][10/100]\tTime 0.015 (0.024)\t\n",
      "Epoch: [2][20/100]\tTime 0.014 (0.022)\t\n",
      "Epoch: [2][30/100]\tTime 0.021 (0.023)\t\n",
      "Epoch: [2][40/100]\tTime 0.017 (0.022)\t\n",
      "Epoch: [2][50/100]\tTime 0.023 (0.022)\t\n",
      "Epoch: [2][60/100]\tTime 0.025 (0.023)\t\n",
      "Epoch: [2][70/100]\tTime 0.046 (0.023)\t\n",
      "Epoch: [2][80/100]\tTime 0.010 (0.024)\t\n",
      "Epoch: [2][90/100]\tTime 0.027 (0.025)\t\n",
      "Accuracy of Class 0: 0.7050\n",
      "Accuracy of Class 1: 0.6240\n",
      "Accuracy of Class 2: 0.3540\n",
      "Accuracy of Class 3: 0.2580\n",
      "Accuracy of Class 4: 0.4730\n",
      "Accuracy of Class 5: 0.4570\n",
      "Accuracy of Class 6: 0.6570\n",
      "Accuracy of Class 7: 0.7130\n",
      "Accuracy of Class 8: 0.6610\n",
      "Accuracy of Class 9: 0.4690\n",
      "* Prec @1: 0.5371\n",
      "Epoch: [3][0/391]\tTime 0.006 (0.006)\tLoss 1.2880 (1.2880)\tPrec @1 0.5312 (0.5312)\t\n",
      "Epoch: [3][10/391]\tTime 0.004 (0.004)\tLoss 1.4272 (1.3223)\tPrec @1 0.5312 (0.5178)\t\n",
      "Epoch: [3][20/391]\tTime 0.005 (0.005)\tLoss 1.3813 (1.3313)\tPrec @1 0.5234 (0.5182)\t\n",
      "Epoch: [3][30/391]\tTime 0.004 (0.004)\tLoss 1.3265 (1.3403)\tPrec @1 0.5391 (0.5134)\t\n",
      "Epoch: [3][40/391]\tTime 0.004 (0.004)\tLoss 1.4777 (1.3386)\tPrec @1 0.4453 (0.5139)\t\n",
      "Epoch: [3][50/391]\tTime 0.005 (0.004)\tLoss 1.3209 (1.3438)\tPrec @1 0.5156 (0.5100)\t\n",
      "Epoch: [3][60/391]\tTime 0.004 (0.004)\tLoss 1.3460 (1.3412)\tPrec @1 0.5000 (0.5118)\t\n",
      "Epoch: [3][70/391]\tTime 0.004 (0.004)\tLoss 1.4463 (1.3436)\tPrec @1 0.4531 (0.5117)\t\n",
      "Epoch: [3][80/391]\tTime 0.004 (0.004)\tLoss 1.3017 (1.3427)\tPrec @1 0.5547 (0.5147)\t\n",
      "Epoch: [3][90/391]\tTime 0.004 (0.004)\tLoss 1.3228 (1.3398)\tPrec @1 0.5312 (0.5172)\t\n",
      "Epoch: [3][100/391]\tTime 0.004 (0.004)\tLoss 1.2122 (1.3377)\tPrec @1 0.5547 (0.5169)\t\n",
      "Epoch: [3][110/391]\tTime 0.005 (0.004)\tLoss 1.3347 (1.3421)\tPrec @1 0.5078 (0.5156)\t\n",
      "Epoch: [3][120/391]\tTime 0.004 (0.004)\tLoss 1.2433 (1.3367)\tPrec @1 0.6016 (0.5183)\t\n",
      "Epoch: [3][130/391]\tTime 0.004 (0.004)\tLoss 1.3325 (1.3340)\tPrec @1 0.4531 (0.5187)\t\n",
      "Epoch: [3][140/391]\tTime 0.004 (0.004)\tLoss 1.3511 (1.3313)\tPrec @1 0.4922 (0.5191)\t\n",
      "Epoch: [3][150/391]\tTime 0.004 (0.004)\tLoss 1.3171 (1.3335)\tPrec @1 0.5781 (0.5181)\t\n",
      "Epoch: [3][160/391]\tTime 0.004 (0.004)\tLoss 1.3548 (1.3325)\tPrec @1 0.4922 (0.5181)\t\n",
      "Epoch: [3][170/391]\tTime 0.003 (0.004)\tLoss 1.0725 (1.3307)\tPrec @1 0.6016 (0.5197)\t\n",
      "Epoch: [3][180/391]\tTime 0.004 (0.004)\tLoss 1.3731 (1.3284)\tPrec @1 0.4766 (0.5209)\t\n",
      "Epoch: [3][190/391]\tTime 0.004 (0.004)\tLoss 1.3380 (1.3291)\tPrec @1 0.4766 (0.5206)\t\n",
      "Epoch: [3][200/391]\tTime 0.004 (0.004)\tLoss 1.1965 (1.3262)\tPrec @1 0.5469 (0.5221)\t\n",
      "Epoch: [3][210/391]\tTime 0.004 (0.004)\tLoss 1.2308 (1.3257)\tPrec @1 0.5781 (0.5224)\t\n",
      "Epoch: [3][220/391]\tTime 0.004 (0.004)\tLoss 1.2681 (1.3277)\tPrec @1 0.5781 (0.5223)\t\n",
      "Epoch: [3][230/391]\tTime 0.004 (0.004)\tLoss 1.2090 (1.3261)\tPrec @1 0.5156 (0.5229)\t\n",
      "Epoch: [3][240/391]\tTime 0.004 (0.004)\tLoss 1.3614 (1.3255)\tPrec @1 0.5000 (0.5233)\t\n",
      "Epoch: [3][250/391]\tTime 0.004 (0.004)\tLoss 1.2860 (1.3236)\tPrec @1 0.5703 (0.5238)\t\n",
      "Epoch: [3][260/391]\tTime 0.005 (0.004)\tLoss 1.3061 (1.3231)\tPrec @1 0.4844 (0.5245)\t\n",
      "Epoch: [3][270/391]\tTime 0.005 (0.004)\tLoss 1.2733 (1.3223)\tPrec @1 0.5234 (0.5245)\t\n",
      "Epoch: [3][280/391]\tTime 0.004 (0.004)\tLoss 1.3637 (1.3229)\tPrec @1 0.4922 (0.5242)\t\n",
      "Epoch: [3][290/391]\tTime 0.004 (0.004)\tLoss 1.4019 (1.3253)\tPrec @1 0.5156 (0.5229)\t\n",
      "Epoch: [3][300/391]\tTime 0.003 (0.004)\tLoss 1.4824 (1.3249)\tPrec @1 0.4766 (0.5235)\t\n",
      "Epoch: [3][310/391]\tTime 0.004 (0.004)\tLoss 1.3358 (1.3242)\tPrec @1 0.5625 (0.5241)\t\n",
      "Epoch: [3][320/391]\tTime 0.004 (0.004)\tLoss 1.4309 (1.3229)\tPrec @1 0.4844 (0.5247)\t\n",
      "Epoch: [3][330/391]\tTime 0.005 (0.004)\tLoss 1.1990 (1.3228)\tPrec @1 0.5312 (0.5249)\t\n",
      "Epoch: [3][340/391]\tTime 0.004 (0.004)\tLoss 1.3889 (1.3217)\tPrec @1 0.5000 (0.5252)\t\n",
      "Epoch: [3][350/391]\tTime 0.004 (0.004)\tLoss 1.1220 (1.3197)\tPrec @1 0.5938 (0.5255)\t\n",
      "Epoch: [3][360/391]\tTime 0.004 (0.004)\tLoss 1.4768 (1.3191)\tPrec @1 0.5000 (0.5261)\t\n",
      "Epoch: [3][370/391]\tTime 0.004 (0.004)\tLoss 1.3665 (1.3194)\tPrec @1 0.5781 (0.5263)\t\n",
      "Epoch: [3][380/391]\tTime 0.004 (0.004)\tLoss 1.2318 (1.3198)\tPrec @1 0.5547 (0.5265)\t\n",
      "Epoch: [3][390/391]\tTime 0.003 (0.004)\tLoss 1.2116 (1.3191)\tPrec @1 0.5875 (0.5267)\t\n",
      "Epoch: [3][0/100]\tTime 0.029 (0.029)\t\n",
      "Epoch: [3][10/100]\tTime 0.024 (0.021)\t\n",
      "Epoch: [3][20/100]\tTime 0.015 (0.022)\t\n",
      "Epoch: [3][30/100]\tTime 0.017 (0.022)\t\n",
      "Epoch: [3][40/100]\tTime 0.014 (0.022)\t\n",
      "Epoch: [3][50/100]\tTime 0.015 (0.021)\t\n",
      "Epoch: [3][60/100]\tTime 0.025 (0.021)\t\n",
      "Epoch: [3][70/100]\tTime 0.023 (0.022)\t\n",
      "Epoch: [3][80/100]\tTime 0.014 (0.022)\t\n",
      "Epoch: [3][90/100]\tTime 0.014 (0.021)\t\n",
      "Accuracy of Class 0: 0.6940\n",
      "Accuracy of Class 1: 0.8130\n",
      "Accuracy of Class 2: 0.3940\n",
      "Accuracy of Class 3: 0.3170\n",
      "Accuracy of Class 4: 0.4550\n",
      "Accuracy of Class 5: 0.2820\n",
      "Accuracy of Class 6: 0.7800\n",
      "Accuracy of Class 7: 0.6930\n",
      "Accuracy of Class 8: 0.7470\n",
      "Accuracy of Class 9: 0.5140\n",
      "* Prec @1: 0.5689\n",
      "Epoch: [4][0/391]\tTime 0.004 (0.004)\tLoss 1.0683 (1.0683)\tPrec @1 0.6172 (0.6172)\t\n",
      "Epoch: [4][10/391]\tTime 0.004 (0.004)\tLoss 1.1763 (1.2403)\tPrec @1 0.5469 (0.5455)\t\n",
      "Epoch: [4][20/391]\tTime 0.005 (0.004)\tLoss 1.2111 (1.2202)\tPrec @1 0.5312 (0.5539)\t\n",
      "Epoch: [4][30/391]\tTime 0.004 (0.004)\tLoss 1.3491 (1.2313)\tPrec @1 0.5469 (0.5522)\t\n",
      "Epoch: [4][40/391]\tTime 0.004 (0.004)\tLoss 1.2851 (1.2369)\tPrec @1 0.5391 (0.5518)\t\n",
      "Epoch: [4][50/391]\tTime 0.004 (0.004)\tLoss 1.2910 (1.2413)\tPrec @1 0.5000 (0.5527)\t\n",
      "Epoch: [4][60/391]\tTime 0.007 (0.004)\tLoss 1.3036 (1.2402)\tPrec @1 0.5547 (0.5521)\t\n",
      "Epoch: [4][70/391]\tTime 0.005 (0.004)\tLoss 1.3251 (1.2418)\tPrec @1 0.5234 (0.5536)\t\n",
      "Epoch: [4][80/391]\tTime 0.004 (0.004)\tLoss 1.2084 (1.2407)\tPrec @1 0.5781 (0.5548)\t\n",
      "Epoch: [4][90/391]\tTime 0.004 (0.004)\tLoss 1.2834 (1.2422)\tPrec @1 0.5938 (0.5542)\t\n",
      "Epoch: [4][100/391]\tTime 0.004 (0.004)\tLoss 1.2223 (1.2481)\tPrec @1 0.6016 (0.5531)\t\n",
      "Epoch: [4][110/391]\tTime 0.004 (0.004)\tLoss 1.1069 (1.2477)\tPrec @1 0.6250 (0.5522)\t\n",
      "Epoch: [4][120/391]\tTime 0.004 (0.004)\tLoss 1.2294 (1.2485)\tPrec @1 0.5703 (0.5520)\t\n",
      "Epoch: [4][130/391]\tTime 0.004 (0.004)\tLoss 1.3114 (1.2502)\tPrec @1 0.5547 (0.5525)\t\n",
      "Epoch: [4][140/391]\tTime 0.004 (0.004)\tLoss 1.3108 (1.2505)\tPrec @1 0.5312 (0.5520)\t\n",
      "Epoch: [4][150/391]\tTime 0.004 (0.004)\tLoss 1.3617 (1.2491)\tPrec @1 0.5234 (0.5524)\t\n",
      "Epoch: [4][160/391]\tTime 0.004 (0.004)\tLoss 1.4174 (1.2498)\tPrec @1 0.4141 (0.5528)\t\n",
      "Epoch: [4][170/391]\tTime 0.003 (0.004)\tLoss 1.2445 (1.2510)\tPrec @1 0.4844 (0.5520)\t\n",
      "Epoch: [4][180/391]\tTime 0.003 (0.004)\tLoss 1.2026 (1.2480)\tPrec @1 0.5391 (0.5530)\t\n",
      "Epoch: [4][190/391]\tTime 0.004 (0.004)\tLoss 1.3299 (1.2461)\tPrec @1 0.5547 (0.5538)\t\n",
      "Epoch: [4][200/391]\tTime 0.004 (0.004)\tLoss 1.3016 (1.2452)\tPrec @1 0.5469 (0.5543)\t\n",
      "Epoch: [4][210/391]\tTime 0.004 (0.004)\tLoss 1.2147 (1.2438)\tPrec @1 0.5625 (0.5558)\t\n",
      "Epoch: [4][220/391]\tTime 0.004 (0.004)\tLoss 1.2329 (1.2449)\tPrec @1 0.5469 (0.5551)\t\n",
      "Epoch: [4][230/391]\tTime 0.004 (0.004)\tLoss 1.3634 (1.2454)\tPrec @1 0.5078 (0.5552)\t\n",
      "Epoch: [4][240/391]\tTime 0.004 (0.004)\tLoss 1.1557 (1.2452)\tPrec @1 0.5781 (0.5547)\t\n",
      "Epoch: [4][250/391]\tTime 0.004 (0.004)\tLoss 1.1054 (1.2455)\tPrec @1 0.5625 (0.5538)\t\n",
      "Epoch: [4][260/391]\tTime 0.004 (0.004)\tLoss 0.9919 (1.2444)\tPrec @1 0.6641 (0.5545)\t\n",
      "Epoch: [4][270/391]\tTime 0.004 (0.004)\tLoss 1.0173 (1.2443)\tPrec @1 0.6016 (0.5546)\t\n",
      "Epoch: [4][280/391]\tTime 0.004 (0.004)\tLoss 1.3297 (1.2456)\tPrec @1 0.5312 (0.5543)\t\n",
      "Epoch: [4][290/391]\tTime 0.004 (0.004)\tLoss 1.1639 (1.2444)\tPrec @1 0.5938 (0.5550)\t\n",
      "Epoch: [4][300/391]\tTime 0.004 (0.004)\tLoss 1.3868 (1.2460)\tPrec @1 0.4922 (0.5546)\t\n",
      "Epoch: [4][310/391]\tTime 0.005 (0.004)\tLoss 1.2674 (1.2453)\tPrec @1 0.5938 (0.5550)\t\n",
      "Epoch: [4][320/391]\tTime 0.004 (0.004)\tLoss 1.1955 (1.2436)\tPrec @1 0.5547 (0.5556)\t\n",
      "Epoch: [4][330/391]\tTime 0.004 (0.004)\tLoss 1.2895 (1.2428)\tPrec @1 0.5234 (0.5565)\t\n",
      "Epoch: [4][340/391]\tTime 0.004 (0.004)\tLoss 1.1147 (1.2437)\tPrec @1 0.5625 (0.5559)\t\n",
      "Epoch: [4][350/391]\tTime 0.004 (0.004)\tLoss 1.1816 (1.2419)\tPrec @1 0.6172 (0.5564)\t\n",
      "Epoch: [4][360/391]\tTime 0.004 (0.004)\tLoss 1.1117 (1.2411)\tPrec @1 0.5938 (0.5564)\t\n",
      "Epoch: [4][370/391]\tTime 0.003 (0.004)\tLoss 1.1506 (1.2414)\tPrec @1 0.5781 (0.5558)\t\n",
      "Epoch: [4][380/391]\tTime 0.004 (0.004)\tLoss 1.1707 (1.2405)\tPrec @1 0.5312 (0.5563)\t\n",
      "Epoch: [4][390/391]\tTime 0.007 (0.004)\tLoss 1.1113 (1.2406)\tPrec @1 0.5500 (0.5562)\t\n",
      "Epoch: [4][0/100]\tTime 0.018 (0.018)\t\n",
      "Epoch: [4][10/100]\tTime 0.030 (0.022)\t\n",
      "Epoch: [4][20/100]\tTime 0.022 (0.022)\t\n",
      "Epoch: [4][30/100]\tTime 0.014 (0.023)\t\n",
      "Epoch: [4][40/100]\tTime 0.013 (0.022)\t\n",
      "Epoch: [4][50/100]\tTime 0.013 (0.021)\t\n",
      "Epoch: [4][60/100]\tTime 0.028 (0.021)\t\n",
      "Epoch: [4][70/100]\tTime 0.014 (0.020)\t\n",
      "Epoch: [4][80/100]\tTime 0.022 (0.020)\t\n",
      "Epoch: [4][90/100]\tTime 0.016 (0.020)\t\n",
      "Accuracy of Class 0: 0.7120\n",
      "Accuracy of Class 1: 0.7950\n",
      "Accuracy of Class 2: 0.5340\n",
      "Accuracy of Class 3: 0.4900\n",
      "Accuracy of Class 4: 0.3770\n",
      "Accuracy of Class 5: 0.5680\n",
      "Accuracy of Class 6: 0.7370\n",
      "Accuracy of Class 7: 0.5460\n",
      "Accuracy of Class 8: 0.6200\n",
      "Accuracy of Class 9: 0.5730\n",
      "* Prec @1: 0.5952\n",
      "Epoch: [5][0/391]\tTime 0.004 (0.004)\tLoss 1.1164 (1.1164)\tPrec @1 0.6641 (0.6641)\t\n",
      "Epoch: [5][10/391]\tTime 0.004 (0.004)\tLoss 1.2140 (1.1972)\tPrec @1 0.5547 (0.5774)\t\n",
      "Epoch: [5][20/391]\tTime 0.004 (0.004)\tLoss 1.2039 (1.2016)\tPrec @1 0.5859 (0.5707)\t\n",
      "Epoch: [5][30/391]\tTime 0.004 (0.004)\tLoss 1.4405 (1.2182)\tPrec @1 0.4844 (0.5612)\t\n",
      "Epoch: [5][40/391]\tTime 0.004 (0.004)\tLoss 1.3645 (1.2339)\tPrec @1 0.4844 (0.5593)\t\n",
      "Epoch: [5][50/391]\tTime 0.004 (0.004)\tLoss 1.0818 (1.2280)\tPrec @1 0.6328 (0.5607)\t\n",
      "Epoch: [5][60/391]\tTime 0.004 (0.004)\tLoss 1.1626 (1.2242)\tPrec @1 0.5625 (0.5611)\t\n",
      "Epoch: [5][70/391]\tTime 0.005 (0.004)\tLoss 0.9167 (1.2182)\tPrec @1 0.7500 (0.5643)\t\n",
      "Epoch: [5][80/391]\tTime 0.004 (0.004)\tLoss 1.4474 (1.2155)\tPrec @1 0.5078 (0.5652)\t\n",
      "Epoch: [5][90/391]\tTime 0.004 (0.004)\tLoss 1.4615 (1.2107)\tPrec @1 0.4375 (0.5668)\t\n",
      "Epoch: [5][100/391]\tTime 0.004 (0.004)\tLoss 1.3310 (1.2051)\tPrec @1 0.5391 (0.5673)\t\n",
      "Epoch: [5][110/391]\tTime 0.004 (0.004)\tLoss 1.2083 (1.2069)\tPrec @1 0.5234 (0.5652)\t\n",
      "Epoch: [5][120/391]\tTime 0.004 (0.004)\tLoss 1.1860 (1.2036)\tPrec @1 0.5781 (0.5669)\t\n",
      "Epoch: [5][130/391]\tTime 0.004 (0.004)\tLoss 1.2229 (1.2044)\tPrec @1 0.5547 (0.5676)\t\n",
      "Epoch: [5][140/391]\tTime 0.004 (0.004)\tLoss 1.2932 (1.2056)\tPrec @1 0.5859 (0.5685)\t\n",
      "Epoch: [5][150/391]\tTime 0.004 (0.004)\tLoss 1.0303 (1.2035)\tPrec @1 0.5859 (0.5691)\t\n",
      "Epoch: [5][160/391]\tTime 0.004 (0.004)\tLoss 1.0969 (1.2022)\tPrec @1 0.6094 (0.5696)\t\n",
      "Epoch: [5][170/391]\tTime 0.005 (0.004)\tLoss 1.2463 (1.2031)\tPrec @1 0.5469 (0.5700)\t\n",
      "Epoch: [5][180/391]\tTime 0.004 (0.004)\tLoss 1.2665 (1.2029)\tPrec @1 0.5469 (0.5701)\t\n",
      "Epoch: [5][190/391]\tTime 0.004 (0.004)\tLoss 1.2311 (1.2034)\tPrec @1 0.5469 (0.5703)\t\n",
      "Epoch: [5][200/391]\tTime 0.004 (0.004)\tLoss 1.3224 (1.2042)\tPrec @1 0.5156 (0.5693)\t\n",
      "Epoch: [5][210/391]\tTime 0.004 (0.004)\tLoss 1.0774 (1.2054)\tPrec @1 0.6172 (0.5691)\t\n",
      "Epoch: [5][220/391]\tTime 0.004 (0.004)\tLoss 0.9548 (1.2038)\tPrec @1 0.6484 (0.5696)\t\n",
      "Epoch: [5][230/391]\tTime 0.004 (0.004)\tLoss 1.0586 (1.2030)\tPrec @1 0.6016 (0.5697)\t\n",
      "Epoch: [5][240/391]\tTime 0.004 (0.004)\tLoss 1.0589 (1.2011)\tPrec @1 0.6562 (0.5701)\t\n",
      "Epoch: [5][250/391]\tTime 0.004 (0.004)\tLoss 1.1874 (1.2008)\tPrec @1 0.5547 (0.5704)\t\n",
      "Epoch: [5][260/391]\tTime 0.004 (0.004)\tLoss 1.1212 (1.1999)\tPrec @1 0.6172 (0.5713)\t\n",
      "Epoch: [5][270/391]\tTime 0.004 (0.004)\tLoss 1.2895 (1.2005)\tPrec @1 0.5625 (0.5712)\t\n",
      "Epoch: [5][280/391]\tTime 0.003 (0.004)\tLoss 1.3116 (1.2007)\tPrec @1 0.5156 (0.5713)\t\n",
      "Epoch: [5][290/391]\tTime 0.004 (0.004)\tLoss 1.2882 (1.1997)\tPrec @1 0.5234 (0.5716)\t\n",
      "Epoch: [5][300/391]\tTime 0.004 (0.004)\tLoss 1.2502 (1.2014)\tPrec @1 0.5312 (0.5708)\t\n",
      "Epoch: [5][310/391]\tTime 0.004 (0.004)\tLoss 1.3057 (1.2017)\tPrec @1 0.5469 (0.5709)\t\n",
      "Epoch: [5][320/391]\tTime 0.004 (0.004)\tLoss 1.2518 (1.2015)\tPrec @1 0.5703 (0.5713)\t\n",
      "Epoch: [5][330/391]\tTime 0.004 (0.004)\tLoss 1.1014 (1.1979)\tPrec @1 0.5938 (0.5728)\t\n",
      "Epoch: [5][340/391]\tTime 0.005 (0.004)\tLoss 1.2072 (1.1984)\tPrec @1 0.5625 (0.5728)\t\n",
      "Epoch: [5][350/391]\tTime 0.004 (0.004)\tLoss 1.2335 (1.1978)\tPrec @1 0.5234 (0.5730)\t\n",
      "Epoch: [5][360/391]\tTime 0.005 (0.004)\tLoss 1.2679 (1.1964)\tPrec @1 0.5781 (0.5739)\t\n",
      "Epoch: [5][370/391]\tTime 0.004 (0.004)\tLoss 1.1168 (1.1958)\tPrec @1 0.6172 (0.5745)\t\n",
      "Epoch: [5][380/391]\tTime 0.004 (0.004)\tLoss 1.1402 (1.1950)\tPrec @1 0.6484 (0.5750)\t\n",
      "Epoch: [5][390/391]\tTime 0.003 (0.004)\tLoss 1.1259 (1.1939)\tPrec @1 0.5750 (0.5751)\t\n",
      "Epoch: [5][0/100]\tTime 0.026 (0.026)\t\n",
      "Epoch: [5][10/100]\tTime 0.019 (0.020)\t\n",
      "Epoch: [5][20/100]\tTime 0.020 (0.022)\t\n",
      "Epoch: [5][30/100]\tTime 0.016 (0.022)\t\n",
      "Epoch: [5][40/100]\tTime 0.025 (0.021)\t\n",
      "Epoch: [5][50/100]\tTime 0.014 (0.021)\t\n",
      "Epoch: [5][60/100]\tTime 0.021 (0.021)\t\n",
      "Epoch: [5][70/100]\tTime 0.022 (0.021)\t\n",
      "Epoch: [5][80/100]\tTime 0.015 (0.020)\t\n",
      "Epoch: [5][90/100]\tTime 0.019 (0.020)\t\n",
      "Accuracy of Class 0: 0.6610\n",
      "Accuracy of Class 1: 0.6440\n",
      "Accuracy of Class 2: 0.5350\n",
      "Accuracy of Class 3: 0.3090\n",
      "Accuracy of Class 4: 0.4230\n",
      "Accuracy of Class 5: 0.6020\n",
      "Accuracy of Class 6: 0.8300\n",
      "Accuracy of Class 7: 0.6890\n",
      "Accuracy of Class 8: 0.7180\n",
      "Accuracy of Class 9: 0.6400\n",
      "* Prec @1: 0.6051\n",
      "Epoch: [6][0/391]\tTime 0.004 (0.004)\tLoss 1.2242 (1.2242)\tPrec @1 0.5938 (0.5938)\t\n",
      "Epoch: [6][10/391]\tTime 0.004 (0.004)\tLoss 1.0582 (1.0911)\tPrec @1 0.6094 (0.6179)\t\n",
      "Epoch: [6][20/391]\tTime 0.004 (0.004)\tLoss 1.0410 (1.0904)\tPrec @1 0.6016 (0.6194)\t\n",
      "Epoch: [6][30/391]\tTime 0.003 (0.004)\tLoss 1.1188 (1.1070)\tPrec @1 0.5625 (0.6111)\t\n",
      "Epoch: [6][40/391]\tTime 0.003 (0.004)\tLoss 1.1353 (1.1121)\tPrec @1 0.6484 (0.6094)\t\n",
      "Epoch: [6][50/391]\tTime 0.003 (0.004)\tLoss 0.9459 (1.0976)\tPrec @1 0.7266 (0.6157)\t\n",
      "Epoch: [6][60/391]\tTime 0.004 (0.004)\tLoss 1.0510 (1.0962)\tPrec @1 0.6484 (0.6162)\t\n",
      "Epoch: [6][70/391]\tTime 0.003 (0.004)\tLoss 1.1414 (1.0952)\tPrec @1 0.5469 (0.6152)\t\n",
      "Epoch: [6][80/391]\tTime 0.003 (0.004)\tLoss 0.9355 (1.0898)\tPrec @1 0.6641 (0.6158)\t\n",
      "Epoch: [6][90/391]\tTime 0.003 (0.004)\tLoss 1.1139 (1.0903)\tPrec @1 0.5703 (0.6156)\t\n",
      "Epoch: [6][100/391]\tTime 0.004 (0.004)\tLoss 0.9832 (1.0909)\tPrec @1 0.6719 (0.6162)\t\n",
      "Epoch: [6][110/391]\tTime 0.004 (0.004)\tLoss 1.0613 (1.0879)\tPrec @1 0.6172 (0.6173)\t\n",
      "Epoch: [6][120/391]\tTime 0.005 (0.004)\tLoss 0.8524 (1.0873)\tPrec @1 0.6953 (0.6173)\t\n",
      "Epoch: [6][130/391]\tTime 0.004 (0.004)\tLoss 0.8837 (1.0868)\tPrec @1 0.7344 (0.6159)\t\n",
      "Epoch: [6][140/391]\tTime 0.004 (0.004)\tLoss 1.0180 (1.0840)\tPrec @1 0.6953 (0.6167)\t\n",
      "Epoch: [6][150/391]\tTime 0.004 (0.004)\tLoss 1.2741 (1.0824)\tPrec @1 0.5938 (0.6180)\t\n",
      "Epoch: [6][160/391]\tTime 0.005 (0.004)\tLoss 1.0086 (1.0825)\tPrec @1 0.6641 (0.6181)\t\n",
      "Epoch: [6][170/391]\tTime 0.004 (0.004)\tLoss 1.0872 (1.0825)\tPrec @1 0.6250 (0.6188)\t\n",
      "Epoch: [6][180/391]\tTime 0.004 (0.004)\tLoss 1.0906 (1.0814)\tPrec @1 0.6016 (0.6184)\t\n",
      "Epoch: [6][190/391]\tTime 0.004 (0.004)\tLoss 0.9697 (1.0796)\tPrec @1 0.6406 (0.6186)\t\n",
      "Epoch: [6][200/391]\tTime 0.004 (0.004)\tLoss 1.2489 (1.0789)\tPrec @1 0.5859 (0.6185)\t\n",
      "Epoch: [6][210/391]\tTime 0.005 (0.004)\tLoss 1.0621 (1.0807)\tPrec @1 0.6250 (0.6184)\t\n",
      "Epoch: [6][220/391]\tTime 0.004 (0.004)\tLoss 0.9910 (1.0798)\tPrec @1 0.6406 (0.6185)\t\n",
      "Epoch: [6][230/391]\tTime 0.004 (0.004)\tLoss 1.1167 (1.0793)\tPrec @1 0.6016 (0.6196)\t\n",
      "Epoch: [6][240/391]\tTime 0.006 (0.004)\tLoss 0.9853 (1.0794)\tPrec @1 0.6328 (0.6197)\t\n",
      "Epoch: [6][250/391]\tTime 0.004 (0.004)\tLoss 1.0675 (1.0806)\tPrec @1 0.6406 (0.6198)\t\n",
      "Epoch: [6][260/391]\tTime 0.004 (0.004)\tLoss 1.3154 (1.0806)\tPrec @1 0.5703 (0.6205)\t\n",
      "Epoch: [6][270/391]\tTime 0.004 (0.004)\tLoss 1.2719 (1.0787)\tPrec @1 0.5703 (0.6208)\t\n",
      "Epoch: [6][280/391]\tTime 0.004 (0.004)\tLoss 1.0831 (1.0791)\tPrec @1 0.6250 (0.6210)\t\n",
      "Epoch: [6][290/391]\tTime 0.004 (0.004)\tLoss 1.1312 (1.0798)\tPrec @1 0.6094 (0.6202)\t\n",
      "Epoch: [6][300/391]\tTime 0.004 (0.004)\tLoss 1.0968 (1.0798)\tPrec @1 0.6016 (0.6200)\t\n",
      "Epoch: [6][310/391]\tTime 0.004 (0.004)\tLoss 0.9535 (1.0787)\tPrec @1 0.6484 (0.6199)\t\n",
      "Epoch: [6][320/391]\tTime 0.004 (0.004)\tLoss 1.0073 (1.0784)\tPrec @1 0.6328 (0.6203)\t\n",
      "Epoch: [6][330/391]\tTime 0.004 (0.004)\tLoss 0.9593 (1.0779)\tPrec @1 0.6406 (0.6203)\t\n",
      "Epoch: [6][340/391]\tTime 0.003 (0.004)\tLoss 1.1651 (1.0785)\tPrec @1 0.5781 (0.6202)\t\n",
      "Epoch: [6][350/391]\tTime 0.004 (0.004)\tLoss 0.9614 (1.0775)\tPrec @1 0.6875 (0.6205)\t\n",
      "Epoch: [6][360/391]\tTime 0.004 (0.004)\tLoss 1.1072 (1.0769)\tPrec @1 0.5859 (0.6205)\t\n",
      "Epoch: [6][370/391]\tTime 0.004 (0.004)\tLoss 1.0459 (1.0770)\tPrec @1 0.6172 (0.6207)\t\n",
      "Epoch: [6][380/391]\tTime 0.004 (0.004)\tLoss 1.1459 (1.0766)\tPrec @1 0.6406 (0.6207)\t\n",
      "Epoch: [6][390/391]\tTime 0.004 (0.004)\tLoss 1.1030 (1.0771)\tPrec @1 0.6250 (0.6207)\t\n",
      "Epoch: [6][0/100]\tTime 0.030 (0.030)\t\n",
      "Epoch: [6][10/100]\tTime 0.015 (0.021)\t\n",
      "Epoch: [6][20/100]\tTime 0.037 (0.025)\t\n",
      "Epoch: [6][30/100]\tTime 0.032 (0.029)\t\n",
      "Epoch: [6][40/100]\tTime 0.029 (0.029)\t\n",
      "Epoch: [6][50/100]\tTime 0.022 (0.029)\t\n",
      "Epoch: [6][60/100]\tTime 0.027 (0.028)\t\n",
      "Epoch: [6][70/100]\tTime 0.028 (0.027)\t\n",
      "Epoch: [6][80/100]\tTime 0.021 (0.026)\t\n",
      "Epoch: [6][90/100]\tTime 0.014 (0.025)\t\n",
      "Accuracy of Class 0: 0.6890\n",
      "Accuracy of Class 1: 0.7950\n",
      "Accuracy of Class 2: 0.4880\n",
      "Accuracy of Class 3: 0.4440\n",
      "Accuracy of Class 4: 0.5630\n",
      "Accuracy of Class 5: 0.5490\n",
      "Accuracy of Class 6: 0.7910\n",
      "Accuracy of Class 7: 0.6850\n",
      "Accuracy of Class 8: 0.7940\n",
      "Accuracy of Class 9: 0.7050\n",
      "* Prec @1: 0.6503\n",
      "Epoch: [7][0/391]\tTime 0.004 (0.004)\tLoss 1.2203 (1.2203)\tPrec @1 0.5938 (0.5938)\t\n",
      "Epoch: [7][10/391]\tTime 0.004 (0.004)\tLoss 1.0946 (1.0637)\tPrec @1 0.6172 (0.6065)\t\n",
      "Epoch: [7][20/391]\tTime 0.004 (0.004)\tLoss 1.1144 (1.0534)\tPrec @1 0.6484 (0.6261)\t\n",
      "Epoch: [7][30/391]\tTime 0.004 (0.004)\tLoss 1.1402 (1.0622)\tPrec @1 0.6250 (0.6225)\t\n",
      "Epoch: [7][40/391]\tTime 0.004 (0.004)\tLoss 1.0054 (1.0747)\tPrec @1 0.6562 (0.6199)\t\n",
      "Epoch: [7][50/391]\tTime 0.004 (0.004)\tLoss 1.0331 (1.0753)\tPrec @1 0.6484 (0.6169)\t\n",
      "Epoch: [7][60/391]\tTime 0.004 (0.004)\tLoss 0.8928 (1.0747)\tPrec @1 0.7109 (0.6162)\t\n",
      "Epoch: [7][70/391]\tTime 0.004 (0.004)\tLoss 1.0770 (1.0715)\tPrec @1 0.6172 (0.6182)\t\n",
      "Epoch: [7][80/391]\tTime 0.004 (0.004)\tLoss 0.8648 (1.0648)\tPrec @1 0.7109 (0.6215)\t\n",
      "Epoch: [7][90/391]\tTime 0.003 (0.004)\tLoss 1.2508 (1.0622)\tPrec @1 0.5625 (0.6221)\t\n",
      "Epoch: [7][100/391]\tTime 0.003 (0.004)\tLoss 1.0534 (1.0662)\tPrec @1 0.6484 (0.6220)\t\n",
      "Epoch: [7][110/391]\tTime 0.004 (0.004)\tLoss 1.0872 (1.0625)\tPrec @1 0.6406 (0.6239)\t\n",
      "Epoch: [7][120/391]\tTime 0.004 (0.004)\tLoss 1.0169 (1.0593)\tPrec @1 0.6641 (0.6265)\t\n",
      "Epoch: [7][130/391]\tTime 0.004 (0.004)\tLoss 1.0734 (1.0581)\tPrec @1 0.6094 (0.6271)\t\n",
      "Epoch: [7][140/391]\tTime 0.004 (0.004)\tLoss 1.0731 (1.0560)\tPrec @1 0.5938 (0.6274)\t\n",
      "Epoch: [7][150/391]\tTime 0.003 (0.004)\tLoss 1.1121 (1.0597)\tPrec @1 0.5469 (0.6265)\t\n",
      "Epoch: [7][160/391]\tTime 0.004 (0.004)\tLoss 0.9247 (1.0579)\tPrec @1 0.6953 (0.6264)\t\n",
      "Epoch: [7][170/391]\tTime 0.004 (0.004)\tLoss 1.1094 (1.0565)\tPrec @1 0.6016 (0.6270)\t\n",
      "Epoch: [7][180/391]\tTime 0.004 (0.004)\tLoss 0.9521 (1.0585)\tPrec @1 0.6562 (0.6259)\t\n",
      "Epoch: [7][190/391]\tTime 0.005 (0.004)\tLoss 0.9337 (1.0581)\tPrec @1 0.6172 (0.6258)\t\n",
      "Epoch: [7][200/391]\tTime 0.004 (0.004)\tLoss 0.9162 (1.0579)\tPrec @1 0.6562 (0.6257)\t\n",
      "Epoch: [7][210/391]\tTime 0.004 (0.004)\tLoss 1.0865 (1.0583)\tPrec @1 0.5938 (0.6253)\t\n",
      "Epoch: [7][220/391]\tTime 0.004 (0.004)\tLoss 0.8948 (1.0556)\tPrec @1 0.6875 (0.6262)\t\n",
      "Epoch: [7][230/391]\tTime 0.004 (0.004)\tLoss 1.0276 (1.0553)\tPrec @1 0.6016 (0.6258)\t\n",
      "Epoch: [7][240/391]\tTime 0.004 (0.004)\tLoss 1.1710 (1.0568)\tPrec @1 0.5859 (0.6252)\t\n",
      "Epoch: [7][250/391]\tTime 0.004 (0.004)\tLoss 1.0577 (1.0572)\tPrec @1 0.5547 (0.6242)\t\n",
      "Epoch: [7][260/391]\tTime 0.004 (0.004)\tLoss 0.9702 (1.0566)\tPrec @1 0.7266 (0.6240)\t\n",
      "Epoch: [7][270/391]\tTime 0.004 (0.004)\tLoss 1.0230 (1.0585)\tPrec @1 0.6797 (0.6242)\t\n",
      "Epoch: [7][280/391]\tTime 0.004 (0.004)\tLoss 1.0414 (1.0569)\tPrec @1 0.6484 (0.6246)\t\n",
      "Epoch: [7][290/391]\tTime 0.004 (0.004)\tLoss 1.0123 (1.0576)\tPrec @1 0.6406 (0.6247)\t\n",
      "Epoch: [7][300/391]\tTime 0.004 (0.004)\tLoss 1.1205 (1.0580)\tPrec @1 0.5781 (0.6245)\t\n",
      "Epoch: [7][310/391]\tTime 0.004 (0.004)\tLoss 1.0760 (1.0573)\tPrec @1 0.6016 (0.6249)\t\n",
      "Epoch: [7][320/391]\tTime 0.004 (0.004)\tLoss 1.0937 (1.0577)\tPrec @1 0.6328 (0.6249)\t\n",
      "Epoch: [7][330/391]\tTime 0.004 (0.004)\tLoss 1.0624 (1.0580)\tPrec @1 0.6172 (0.6250)\t\n",
      "Epoch: [7][340/391]\tTime 0.003 (0.004)\tLoss 1.1607 (1.0570)\tPrec @1 0.5859 (0.6256)\t\n",
      "Epoch: [7][350/391]\tTime 0.004 (0.004)\tLoss 1.1662 (1.0569)\tPrec @1 0.6484 (0.6260)\t\n",
      "Epoch: [7][360/391]\tTime 0.004 (0.004)\tLoss 1.1071 (1.0570)\tPrec @1 0.6016 (0.6256)\t\n",
      "Epoch: [7][370/391]\tTime 0.004 (0.004)\tLoss 1.1674 (1.0574)\tPrec @1 0.6016 (0.6255)\t\n",
      "Epoch: [7][380/391]\tTime 0.004 (0.004)\tLoss 0.9636 (1.0568)\tPrec @1 0.6719 (0.6257)\t\n",
      "Epoch: [7][390/391]\tTime 0.003 (0.004)\tLoss 1.3603 (1.0581)\tPrec @1 0.6000 (0.6255)\t\n",
      "Epoch: [7][0/100]\tTime 0.033 (0.033)\t\n",
      "Epoch: [7][10/100]\tTime 0.015 (0.023)\t\n",
      "Epoch: [7][20/100]\tTime 0.026 (0.021)\t\n",
      "Epoch: [7][30/100]\tTime 0.028 (0.021)\t\n",
      "Epoch: [7][40/100]\tTime 0.026 (0.022)\t\n",
      "Epoch: [7][50/100]\tTime 0.031 (0.023)\t\n",
      "Epoch: [7][60/100]\tTime 0.023 (0.024)\t\n",
      "Epoch: [7][70/100]\tTime 0.033 (0.025)\t\n",
      "Epoch: [7][80/100]\tTime 0.020 (0.024)\t\n",
      "Epoch: [7][90/100]\tTime 0.024 (0.024)\t\n",
      "Accuracy of Class 0: 0.7160\n",
      "Accuracy of Class 1: 0.7710\n",
      "Accuracy of Class 2: 0.5260\n",
      "Accuracy of Class 3: 0.4140\n",
      "Accuracy of Class 4: 0.5930\n",
      "Accuracy of Class 5: 0.5590\n",
      "Accuracy of Class 6: 0.7970\n",
      "Accuracy of Class 7: 0.6910\n",
      "Accuracy of Class 8: 0.7960\n",
      "Accuracy of Class 9: 0.7020\n",
      "* Prec @1: 0.6565\n",
      "Epoch: [8][0/391]\tTime 0.005 (0.005)\tLoss 0.8769 (0.8769)\tPrec @1 0.7109 (0.7109)\t\n",
      "Epoch: [8][10/391]\tTime 0.005 (0.004)\tLoss 0.9706 (1.0324)\tPrec @1 0.6406 (0.6364)\t\n",
      "Epoch: [8][20/391]\tTime 0.004 (0.005)\tLoss 1.3265 (1.0379)\tPrec @1 0.5469 (0.6313)\t\n",
      "Epoch: [8][30/391]\tTime 0.004 (0.004)\tLoss 1.1393 (1.0403)\tPrec @1 0.5938 (0.6280)\t\n",
      "Epoch: [8][40/391]\tTime 0.004 (0.004)\tLoss 1.0357 (1.0454)\tPrec @1 0.6641 (0.6275)\t\n",
      "Epoch: [8][50/391]\tTime 0.004 (0.004)\tLoss 0.9627 (1.0547)\tPrec @1 0.6328 (0.6233)\t\n",
      "Epoch: [8][60/391]\tTime 0.004 (0.004)\tLoss 1.0209 (1.0505)\tPrec @1 0.6250 (0.6262)\t\n",
      "Epoch: [8][70/391]\tTime 0.004 (0.004)\tLoss 0.9476 (1.0504)\tPrec @1 0.6094 (0.6274)\t\n",
      "Epoch: [8][80/391]\tTime 0.004 (0.004)\tLoss 0.9663 (1.0561)\tPrec @1 0.6719 (0.6251)\t\n",
      "Epoch: [8][90/391]\tTime 0.004 (0.004)\tLoss 1.0341 (1.0503)\tPrec @1 0.6250 (0.6253)\t\n",
      "Epoch: [8][100/391]\tTime 0.004 (0.004)\tLoss 0.9936 (1.0489)\tPrec @1 0.7031 (0.6269)\t\n",
      "Epoch: [8][110/391]\tTime 0.004 (0.004)\tLoss 0.9895 (1.0476)\tPrec @1 0.6562 (0.6284)\t\n",
      "Epoch: [8][120/391]\tTime 0.004 (0.004)\tLoss 1.1676 (1.0485)\tPrec @1 0.5703 (0.6289)\t\n",
      "Epoch: [8][130/391]\tTime 0.004 (0.004)\tLoss 1.1022 (1.0492)\tPrec @1 0.6250 (0.6282)\t\n",
      "Epoch: [8][140/391]\tTime 0.004 (0.004)\tLoss 1.1103 (1.0503)\tPrec @1 0.6406 (0.6277)\t\n",
      "Epoch: [8][150/391]\tTime 0.004 (0.004)\tLoss 1.2187 (1.0542)\tPrec @1 0.5703 (0.6271)\t\n",
      "Epoch: [8][160/391]\tTime 0.004 (0.004)\tLoss 1.0337 (1.0547)\tPrec @1 0.6484 (0.6266)\t\n",
      "Epoch: [8][170/391]\tTime 0.004 (0.004)\tLoss 1.0860 (1.0532)\tPrec @1 0.6641 (0.6271)\t\n",
      "Epoch: [8][180/391]\tTime 0.004 (0.004)\tLoss 1.0307 (1.0509)\tPrec @1 0.6328 (0.6278)\t\n",
      "Epoch: [8][190/391]\tTime 0.004 (0.004)\tLoss 0.9978 (1.0495)\tPrec @1 0.6953 (0.6291)\t\n",
      "Epoch: [8][200/391]\tTime 0.003 (0.004)\tLoss 1.2024 (1.0513)\tPrec @1 0.6328 (0.6283)\t\n",
      "Epoch: [8][210/391]\tTime 0.004 (0.004)\tLoss 0.9306 (1.0505)\tPrec @1 0.6484 (0.6286)\t\n",
      "Epoch: [8][220/391]\tTime 0.005 (0.004)\tLoss 0.8440 (1.0487)\tPrec @1 0.7266 (0.6293)\t\n",
      "Epoch: [8][230/391]\tTime 0.004 (0.004)\tLoss 1.0824 (1.0471)\tPrec @1 0.6172 (0.6304)\t\n",
      "Epoch: [8][240/391]\tTime 0.004 (0.004)\tLoss 0.9050 (1.0466)\tPrec @1 0.7266 (0.6307)\t\n",
      "Epoch: [8][250/391]\tTime 0.004 (0.004)\tLoss 0.9893 (1.0463)\tPrec @1 0.6328 (0.6311)\t\n",
      "Epoch: [8][260/391]\tTime 0.004 (0.004)\tLoss 1.0502 (1.0454)\tPrec @1 0.6484 (0.6317)\t\n",
      "Epoch: [8][270/391]\tTime 0.004 (0.004)\tLoss 1.0890 (1.0458)\tPrec @1 0.5781 (0.6313)\t\n",
      "Epoch: [8][280/391]\tTime 0.004 (0.004)\tLoss 1.0154 (1.0459)\tPrec @1 0.6484 (0.6310)\t\n",
      "Epoch: [8][290/391]\tTime 0.004 (0.004)\tLoss 1.1282 (1.0451)\tPrec @1 0.5547 (0.6313)\t\n",
      "Epoch: [8][300/391]\tTime 0.005 (0.004)\tLoss 1.1335 (1.0450)\tPrec @1 0.6094 (0.6312)\t\n",
      "Epoch: [8][310/391]\tTime 0.004 (0.004)\tLoss 1.0406 (1.0449)\tPrec @1 0.6250 (0.6310)\t\n",
      "Epoch: [8][320/391]\tTime 0.004 (0.004)\tLoss 1.0512 (1.0453)\tPrec @1 0.5938 (0.6307)\t\n",
      "Epoch: [8][330/391]\tTime 0.004 (0.004)\tLoss 1.0421 (1.0468)\tPrec @1 0.6328 (0.6300)\t\n",
      "Epoch: [8][340/391]\tTime 0.004 (0.004)\tLoss 1.1237 (1.0462)\tPrec @1 0.6172 (0.6302)\t\n",
      "Epoch: [8][350/391]\tTime 0.004 (0.004)\tLoss 1.0133 (1.0438)\tPrec @1 0.6562 (0.6310)\t\n",
      "Epoch: [8][360/391]\tTime 0.004 (0.004)\tLoss 0.9445 (1.0442)\tPrec @1 0.6250 (0.6310)\t\n",
      "Epoch: [8][370/391]\tTime 0.004 (0.004)\tLoss 1.0479 (1.0441)\tPrec @1 0.6406 (0.6315)\t\n",
      "Epoch: [8][380/391]\tTime 0.004 (0.004)\tLoss 1.1700 (1.0443)\tPrec @1 0.5938 (0.6316)\t\n",
      "Epoch: [8][390/391]\tTime 0.003 (0.004)\tLoss 0.9516 (1.0444)\tPrec @1 0.6250 (0.6315)\t\n",
      "Epoch: [8][0/100]\tTime 0.028 (0.028)\t\n",
      "Epoch: [8][10/100]\tTime 0.022 (0.023)\t\n",
      "Epoch: [8][20/100]\tTime 0.021 (0.022)\t\n",
      "Epoch: [8][30/100]\tTime 0.024 (0.022)\t\n",
      "Epoch: [8][40/100]\tTime 0.021 (0.022)\t\n",
      "Epoch: [8][50/100]\tTime 0.027 (0.021)\t\n",
      "Epoch: [8][60/100]\tTime 0.014 (0.021)\t\n",
      "Epoch: [8][70/100]\tTime 0.014 (0.021)\t\n",
      "Epoch: [8][80/100]\tTime 0.014 (0.021)\t\n",
      "Epoch: [8][90/100]\tTime 0.014 (0.021)\t\n",
      "Accuracy of Class 0: 0.7320\n",
      "Accuracy of Class 1: 0.7730\n",
      "Accuracy of Class 2: 0.5210\n",
      "Accuracy of Class 3: 0.4230\n",
      "Accuracy of Class 4: 0.5690\n",
      "Accuracy of Class 5: 0.5650\n",
      "Accuracy of Class 6: 0.7870\n",
      "Accuracy of Class 7: 0.6960\n",
      "Accuracy of Class 8: 0.8010\n",
      "Accuracy of Class 9: 0.7060\n",
      "* Prec @1: 0.6573\n",
      "Epoch: [9][0/391]\tTime 0.004 (0.004)\tLoss 1.0893 (1.0893)\tPrec @1 0.6094 (0.6094)\t\n",
      "Epoch: [9][10/391]\tTime 0.004 (0.004)\tLoss 1.0888 (1.0550)\tPrec @1 0.6016 (0.6328)\t\n",
      "Epoch: [9][20/391]\tTime 0.005 (0.004)\tLoss 1.1422 (1.0481)\tPrec @1 0.5703 (0.6321)\t\n",
      "Epoch: [9][30/391]\tTime 0.004 (0.004)\tLoss 1.0868 (1.0526)\tPrec @1 0.6016 (0.6278)\t\n",
      "Epoch: [9][40/391]\tTime 0.005 (0.004)\tLoss 1.0367 (1.0435)\tPrec @1 0.6094 (0.6303)\t\n",
      "Epoch: [9][50/391]\tTime 0.008 (0.004)\tLoss 1.2322 (1.0450)\tPrec @1 0.5781 (0.6301)\t\n",
      "Epoch: [9][60/391]\tTime 0.004 (0.004)\tLoss 1.0858 (1.0472)\tPrec @1 0.6094 (0.6296)\t\n",
      "Epoch: [9][70/391]\tTime 0.004 (0.004)\tLoss 0.9230 (1.0413)\tPrec @1 0.6328 (0.6301)\t\n",
      "Epoch: [9][80/391]\tTime 0.004 (0.004)\tLoss 1.1025 (1.0412)\tPrec @1 0.6094 (0.6313)\t\n",
      "Epoch: [9][90/391]\tTime 0.005 (0.004)\tLoss 1.0342 (1.0385)\tPrec @1 0.6719 (0.6329)\t\n",
      "Epoch: [9][100/391]\tTime 0.004 (0.004)\tLoss 1.0158 (1.0403)\tPrec @1 0.6719 (0.6320)\t\n",
      "Epoch: [9][110/391]\tTime 0.004 (0.004)\tLoss 1.0753 (1.0359)\tPrec @1 0.6250 (0.6344)\t\n",
      "Epoch: [9][120/391]\tTime 0.004 (0.004)\tLoss 1.0577 (1.0347)\tPrec @1 0.5938 (0.6340)\t\n",
      "Epoch: [9][130/391]\tTime 0.004 (0.004)\tLoss 0.9179 (1.0360)\tPrec @1 0.6953 (0.6329)\t\n",
      "Epoch: [9][140/391]\tTime 0.004 (0.004)\tLoss 0.9689 (1.0356)\tPrec @1 0.6484 (0.6328)\t\n",
      "Epoch: [9][150/391]\tTime 0.004 (0.004)\tLoss 1.0098 (1.0379)\tPrec @1 0.6328 (0.6316)\t\n",
      "Epoch: [9][160/391]\tTime 0.004 (0.004)\tLoss 1.0519 (1.0396)\tPrec @1 0.6562 (0.6310)\t\n",
      "Epoch: [9][170/391]\tTime 0.004 (0.004)\tLoss 0.9904 (1.0391)\tPrec @1 0.6719 (0.6313)\t\n",
      "Epoch: [9][180/391]\tTime 0.004 (0.004)\tLoss 1.0624 (1.0384)\tPrec @1 0.7031 (0.6320)\t\n",
      "Epoch: [9][190/391]\tTime 0.004 (0.004)\tLoss 1.0548 (1.0361)\tPrec @1 0.6250 (0.6331)\t\n",
      "Epoch: [9][200/391]\tTime 0.004 (0.004)\tLoss 0.9941 (1.0367)\tPrec @1 0.6562 (0.6330)\t\n",
      "Epoch: [9][210/391]\tTime 0.004 (0.004)\tLoss 1.2146 (1.0388)\tPrec @1 0.5859 (0.6327)\t\n",
      "Epoch: [9][220/391]\tTime 0.004 (0.004)\tLoss 0.8381 (1.0354)\tPrec @1 0.6641 (0.6338)\t\n",
      "Epoch: [9][230/391]\tTime 0.004 (0.004)\tLoss 1.0703 (1.0343)\tPrec @1 0.5625 (0.6342)\t\n",
      "Epoch: [9][240/391]\tTime 0.004 (0.004)\tLoss 0.9972 (1.0335)\tPrec @1 0.6250 (0.6345)\t\n",
      "Epoch: [9][250/391]\tTime 0.004 (0.004)\tLoss 1.1500 (1.0360)\tPrec @1 0.6016 (0.6334)\t\n",
      "Epoch: [9][260/391]\tTime 0.004 (0.004)\tLoss 1.1859 (1.0378)\tPrec @1 0.6172 (0.6327)\t\n",
      "Epoch: [9][270/391]\tTime 0.005 (0.004)\tLoss 1.1362 (1.0378)\tPrec @1 0.5703 (0.6324)\t\n",
      "Epoch: [9][280/391]\tTime 0.005 (0.004)\tLoss 1.1138 (1.0385)\tPrec @1 0.6016 (0.6322)\t\n",
      "Epoch: [9][290/391]\tTime 0.004 (0.004)\tLoss 1.0807 (1.0378)\tPrec @1 0.6094 (0.6326)\t\n",
      "Epoch: [9][300/391]\tTime 0.005 (0.004)\tLoss 1.1143 (1.0370)\tPrec @1 0.6016 (0.6323)\t\n",
      "Epoch: [9][310/391]\tTime 0.005 (0.004)\tLoss 1.1904 (1.0367)\tPrec @1 0.5781 (0.6325)\t\n",
      "Epoch: [9][320/391]\tTime 0.004 (0.004)\tLoss 1.0758 (1.0378)\tPrec @1 0.5781 (0.6321)\t\n",
      "Epoch: [9][330/391]\tTime 0.004 (0.004)\tLoss 0.9966 (1.0378)\tPrec @1 0.6562 (0.6323)\t\n",
      "Epoch: [9][340/391]\tTime 0.004 (0.004)\tLoss 1.0242 (1.0385)\tPrec @1 0.6094 (0.6318)\t\n",
      "Epoch: [9][350/391]\tTime 0.004 (0.004)\tLoss 1.2059 (1.0398)\tPrec @1 0.5703 (0.6315)\t\n",
      "Epoch: [9][360/391]\tTime 0.004 (0.004)\tLoss 1.0812 (1.0405)\tPrec @1 0.6094 (0.6311)\t\n",
      "Epoch: [9][370/391]\tTime 0.004 (0.004)\tLoss 1.0653 (1.0413)\tPrec @1 0.6250 (0.6309)\t\n",
      "Epoch: [9][380/391]\tTime 0.004 (0.004)\tLoss 1.0361 (1.0416)\tPrec @1 0.6250 (0.6307)\t\n",
      "Epoch: [9][390/391]\tTime 0.004 (0.004)\tLoss 1.1369 (1.0431)\tPrec @1 0.6000 (0.6303)\t\n",
      "Epoch: [9][0/100]\tTime 0.025 (0.025)\t\n",
      "Epoch: [9][10/100]\tTime 0.017 (0.020)\t\n",
      "Epoch: [9][20/100]\tTime 0.014 (0.021)\t\n",
      "Epoch: [9][30/100]\tTime 0.024 (0.021)\t\n",
      "Epoch: [9][40/100]\tTime 0.013 (0.021)\t\n",
      "Epoch: [9][50/100]\tTime 0.018 (0.021)\t\n",
      "Epoch: [9][60/100]\tTime 0.016 (0.020)\t\n",
      "Epoch: [9][70/100]\tTime 0.018 (0.020)\t\n",
      "Epoch: [9][80/100]\tTime 0.014 (0.020)\t\n",
      "Epoch: [9][90/100]\tTime 0.017 (0.020)\t\n",
      "Accuracy of Class 0: 0.7170\n",
      "Accuracy of Class 1: 0.7720\n",
      "Accuracy of Class 2: 0.5240\n",
      "Accuracy of Class 3: 0.4120\n",
      "Accuracy of Class 4: 0.5590\n",
      "Accuracy of Class 5: 0.5540\n",
      "Accuracy of Class 6: 0.8070\n",
      "Accuracy of Class 7: 0.6950\n",
      "Accuracy of Class 8: 0.8010\n",
      "Accuracy of Class 9: 0.7290\n",
      "* Prec @1: 0.6570\n",
      "Best Prec @1 Acccuracy: 0.6573\n",
      "Accuracy of Class 0: 0.7320\n",
      "Accuracy of Class 1: 0.7730\n",
      "Accuracy of Class 2: 0.5210\n",
      "Accuracy of Class 3: 0.4230\n",
      "Accuracy of Class 4: 0.5690\n",
      "Accuracy of Class 5: 0.5650\n",
      "Accuracy of Class 6: 0.7870\n",
      "Accuracy of Class 7: 0.6960\n",
      "Accuracy of Class 8: 0.8010\n",
      "Accuracy of Class 9: 0.7060\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zWfbgzB4Uiu"
   },
   "source": [
    "Let's test your models implementation. **Make sure to train your models and create checkpoints before running the following tests**."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Db0t0IChKK0h",
    "outputId": "133b0ce1-b1af-48c5-801c-edc8805d67ef",
    "ExecuteTime": {
     "end_time": "2025-09-21T00:29:32.613262Z",
     "start_time": "2025-09-21T00:29:21.802146Z"
    }
   },
   "source": [
    "#Let's test your implementation of two layer\n",
    "!pytest -s {GOOGLE_DRIVE_PATH + '/tests/test_twolayer.py'}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m============================= test session starts =============================\u001B[0m\n",
      "platform win32 -- Python 3.12.0, pytest-8.4.1, pluggy-1.5.0\n",
      "rootdir: C:\\Users\\julie\\CSE_7643_DL\\DL_PS2\\part2-pytorch\n",
      "plugins: anyio-4.7.0\n",
      "collected 1 item\n",
      "\n",
      "tests\\test_twolayer.py \u001B[32m.\u001B[0m\n",
      "\n",
      "\u001B[32m============================== \u001B[32m\u001B[1m1 passed\u001B[0m\u001B[32m in 9.65s\u001B[0m\u001B[32m ==============================\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "X97MN9JvcMQY",
    "outputId": "08cd7e8f-7f5a-4a44-ab93-1c22bc29486c",
    "ExecuteTime": {
     "end_time": "2025-09-21T00:29:38.861677Z",
     "start_time": "2025-09-21T00:29:34.878405Z"
    }
   },
   "source": [
    "#Let's test your implementation of my_model\n",
    "!pytest -s { GOOGLE_DRIVE_PATH + '/tests/test_mymodel.py'}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m============================= test session starts =============================\u001B[0m\n",
      "platform win32 -- Python 3.12.0, pytest-8.4.1, pluggy-1.5.0\n",
      "rootdir: C:\\Users\\julie\\CSE_7643_DL\\DL_PS2\\part2-pytorch\n",
      "plugins: anyio-4.7.0\n",
      "collected 3 items\n",
      "\n",
      "tests\\test_mymodel.py \u001B[31mE\u001B[0m\u001B[31mE\u001B[0m\u001B[31mE\u001B[0m\n",
      "\n",
      "=================================== ERRORS ====================================\n",
      "\u001B[31m\u001B[1m______________ ERROR at setup of TestMyModel.test_accuracy_easy _______________\u001B[0m\n",
      "\n",
      "cls = <class 'tests.test_mymodel.TestMyModel'>\n",
      "\n",
      "    \u001B[0m\u001B[37m@classmethod\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "    \u001B[94mdef\u001B[39;49;00m \u001B[92msetUpClass\u001B[39;49;00m(\u001B[96mcls\u001B[39;49;00m):\u001B[90m\u001B[39;49;00m\n",
      "    \u001B[90m    \u001B[39;49;00m\u001B[33m\"\"\"Define the functions to be tested here.\"\"\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "        basedir = pathlib.Path(\u001B[91m__file__\u001B[39;49;00m).parent.parent.resolve()\u001B[90m\u001B[39;49;00m\n",
      "        model = MyModel()\u001B[90m\u001B[39;49;00m\n",
      "        model.eval()\u001B[90m\u001B[39;49;00m\n",
      "        model.load_state_dict(\u001B[90m\u001B[39;49;00m\n",
      ">           torch.load(\u001B[96mstr\u001B[39;49;00m(basedir) + \u001B[33m\"\u001B[39;49;00m\u001B[33m/checkpoints/mymodel.pth\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, weights_only=\u001B[94mTrue\u001B[39;49;00m)\u001B[90m\u001B[39;49;00m\n",
      "        )\u001B[90m\u001B[39;49;00m\n",
      "\n",
      "\u001B[1m\u001B[31mtests\\test_mymodel.py\u001B[0m:74: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:1521: in load\n",
      "    \u001B[0m\u001B[94mreturn\u001B[39;49;00m _load(\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:2119: in _load\n",
      "    \u001B[0mresult = unpickler.load()\u001B[90m\u001B[39;49;00m\n",
      "             ^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\_weights_only_unpickler.py\u001B[0m:532: in load\n",
      "    \u001B[0m\u001B[96mself\u001B[39;49;00m.append(\u001B[96mself\u001B[39;49;00m.persistent_load(pid))\u001B[90m\u001B[39;49;00m\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:2083: in persistent_load\n",
      "    \u001B[0mtyped_storage = load_tensor(\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:2049: in load_tensor\n",
      "    \u001B[0mwrap_storage = restore_location(storage, location)\u001B[90m\u001B[39;49;00m\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:698: in default_restore_location\n",
      "    \u001B[0mresult = fn(storage, location)\u001B[90m\u001B[39;49;00m\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:636: in _deserialize\n",
      "    \u001B[0mdevice = _validate_device(location, backend_name)\u001B[90m\u001B[39;49;00m\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "location = 'cuda:0', backend_name = 'cuda'\n",
      "\n",
      "    \u001B[0m\u001B[94mdef\u001B[39;49;00m \u001B[92m_validate_device\u001B[39;49;00m(location, backend_name):\u001B[90m\u001B[39;49;00m\n",
      "    \u001B[90m    \u001B[39;49;00m\u001B[33m\"\"\"\u001B[39;49;00m\n",
      "    \u001B[33m    Check whether the device index of specified backend is valid\u001B[39;49;00m\n",
      "    \u001B[33m\u001B[39;49;00m\n",
      "    \u001B[33m    In case of privateuse1 backend, your must first register a device_module for\u001B[39;49;00m\n",
      "    \u001B[33m    privateuse1 using torch._register_device_module. Implement the following\u001B[39;49;00m\n",
      "    \u001B[33m    methods in device_module like cuda: device_module._utils._get_device_index(location, True),\u001B[39;49;00m\n",
      "    \u001B[33m    device_module.device_count().\u001B[39;49;00m\n",
      "    \u001B[33m\u001B[39;49;00m\n",
      "    \u001B[33m    Args:\u001B[39;49;00m\n",
      "    \u001B[33m        location: string of device\u001B[39;49;00m\n",
      "    \u001B[33m        backend_name: the backend name or the name of privateuse1, which can be renamed\u001B[39;49;00m\n",
      "    \u001B[33m\u001B[39;49;00m\n",
      "    \u001B[33m    Returns:\u001B[39;49;00m\n",
      "    \u001B[33m        device_index: int\u001B[39;49;00m\n",
      "    \u001B[33m    \"\"\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "        \u001B[94mif\u001B[39;49;00m \u001B[95mnot\u001B[39;49;00m \u001B[96mhasattr\u001B[39;49;00m(torch, backend_name):\u001B[90m\u001B[39;49;00m\n",
      "            \u001B[94mraise\u001B[39;49;00m \u001B[96mRuntimeError\u001B[39;49;00m(\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33mf\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[33mThe \u001B[39;49;00m\u001B[33m{\u001B[39;49;00mbackend_name.upper()\u001B[33m}\u001B[39;49;00m\u001B[33m device module is not registered. \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33m\"\u001B[39;49;00m\u001B[33mIf you are running on a CPU-only machine, \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33m\"\u001B[39;49;00m\u001B[33mplease use torch.load with map_location=torch.device(\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m\u001B[33mcpu\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m\u001B[33m) \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33m\"\u001B[39;49;00m\u001B[33mto map your storages to the CPU.\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "            )\u001B[90m\u001B[39;49;00m\n",
      "        device_module = \u001B[96mgetattr\u001B[39;49;00m(torch, backend_name)\u001B[90m\u001B[39;49;00m\n",
      "        \u001B[94mif\u001B[39;49;00m \u001B[96mhasattr\u001B[39;49;00m(device_module, \u001B[33m\"\u001B[39;49;00m\u001B[33m_utils\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m) \u001B[95mand\u001B[39;49;00m \u001B[96mhasattr\u001B[39;49;00m(\u001B[90m\u001B[39;49;00m\n",
      "            device_module._utils, \u001B[33m\"\u001B[39;49;00m\u001B[33m_get_device_index\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "        ):\u001B[90m\u001B[39;49;00m\n",
      "            device_index = device_module._utils._get_device_index(location, \u001B[94mTrue\u001B[39;49;00m)\u001B[90m\u001B[39;49;00m\n",
      "            device = torch.device(backend_name, device_index)\u001B[90m\u001B[39;49;00m\n",
      "        \u001B[94melse\u001B[39;49;00m:\u001B[90m\u001B[39;49;00m\n",
      "            device = torch.device(location)\u001B[90m\u001B[39;49;00m\n",
      "            device_index = device.index \u001B[94mif\u001B[39;49;00m device.index \u001B[94melse\u001B[39;49;00m \u001B[94m0\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "        \u001B[94mif\u001B[39;49;00m \u001B[96mhasattr\u001B[39;49;00m(device_module, \u001B[33m\"\u001B[39;49;00m\u001B[33mis_available\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m) \u001B[95mand\u001B[39;49;00m \u001B[95mnot\u001B[39;49;00m device_module.is_available():\u001B[90m\u001B[39;49;00m\n",
      ">           \u001B[94mraise\u001B[39;49;00m \u001B[96mRuntimeError\u001B[39;49;00m(\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33mf\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[33mAttempting to deserialize object on a \u001B[39;49;00m\u001B[33m{\u001B[39;49;00mbackend_name.upper()\u001B[33m}\u001B[39;49;00m\u001B[33m \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33mf\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[33mdevice but torch.\u001B[39;49;00m\u001B[33m{\u001B[39;49;00mbackend_name\u001B[33m}\u001B[39;49;00m\u001B[33m.is_available() is False. \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33m\"\u001B[39;49;00m\u001B[33mIf you are running on a CPU-only machine, \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33m\"\u001B[39;49;00m\u001B[33mplease use torch.load with map_location=torch.device(\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m\u001B[33mcpu\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m\u001B[33m) \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33m\"\u001B[39;49;00m\u001B[33mto map your storages to the CPU.\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "            )\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31mE           RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.\u001B[0m\n",
      "\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:605: RuntimeError\n",
      "\u001B[31m\u001B[1m______________ ERROR at setup of TestMyModel.test_accuracy_hard _______________\u001B[0m\n",
      "\n",
      "cls = <class 'tests.test_mymodel.TestMyModel'>\n",
      "\n",
      "    \u001B[0m\u001B[37m@classmethod\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "    \u001B[94mdef\u001B[39;49;00m \u001B[92msetUpClass\u001B[39;49;00m(\u001B[96mcls\u001B[39;49;00m):\u001B[90m\u001B[39;49;00m\n",
      "    \u001B[90m    \u001B[39;49;00m\u001B[33m\"\"\"Define the functions to be tested here.\"\"\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "        basedir = pathlib.Path(\u001B[91m__file__\u001B[39;49;00m).parent.parent.resolve()\u001B[90m\u001B[39;49;00m\n",
      "        model = MyModel()\u001B[90m\u001B[39;49;00m\n",
      "        model.eval()\u001B[90m\u001B[39;49;00m\n",
      "        model.load_state_dict(\u001B[90m\u001B[39;49;00m\n",
      ">           torch.load(\u001B[96mstr\u001B[39;49;00m(basedir) + \u001B[33m\"\u001B[39;49;00m\u001B[33m/checkpoints/mymodel.pth\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, weights_only=\u001B[94mTrue\u001B[39;49;00m)\u001B[90m\u001B[39;49;00m\n",
      "        )\u001B[90m\u001B[39;49;00m\n",
      "\n",
      "\u001B[1m\u001B[31mtests\\test_mymodel.py\u001B[0m:74: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:1521: in load\n",
      "    \u001B[0m\u001B[94mreturn\u001B[39;49;00m _load(\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:2119: in _load\n",
      "    \u001B[0mresult = unpickler.load()\u001B[90m\u001B[39;49;00m\n",
      "             ^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\_weights_only_unpickler.py\u001B[0m:532: in load\n",
      "    \u001B[0m\u001B[96mself\u001B[39;49;00m.append(\u001B[96mself\u001B[39;49;00m.persistent_load(pid))\u001B[90m\u001B[39;49;00m\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:2083: in persistent_load\n",
      "    \u001B[0mtyped_storage = load_tensor(\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:2049: in load_tensor\n",
      "    \u001B[0mwrap_storage = restore_location(storage, location)\u001B[90m\u001B[39;49;00m\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:698: in default_restore_location\n",
      "    \u001B[0mresult = fn(storage, location)\u001B[90m\u001B[39;49;00m\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:636: in _deserialize\n",
      "    \u001B[0mdevice = _validate_device(location, backend_name)\u001B[90m\u001B[39;49;00m\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "location = 'cuda:0', backend_name = 'cuda'\n",
      "\n",
      "    \u001B[0m\u001B[94mdef\u001B[39;49;00m \u001B[92m_validate_device\u001B[39;49;00m(location, backend_name):\u001B[90m\u001B[39;49;00m\n",
      "    \u001B[90m    \u001B[39;49;00m\u001B[33m\"\"\"\u001B[39;49;00m\n",
      "    \u001B[33m    Check whether the device index of specified backend is valid\u001B[39;49;00m\n",
      "    \u001B[33m\u001B[39;49;00m\n",
      "    \u001B[33m    In case of privateuse1 backend, your must first register a device_module for\u001B[39;49;00m\n",
      "    \u001B[33m    privateuse1 using torch._register_device_module. Implement the following\u001B[39;49;00m\n",
      "    \u001B[33m    methods in device_module like cuda: device_module._utils._get_device_index(location, True),\u001B[39;49;00m\n",
      "    \u001B[33m    device_module.device_count().\u001B[39;49;00m\n",
      "    \u001B[33m\u001B[39;49;00m\n",
      "    \u001B[33m    Args:\u001B[39;49;00m\n",
      "    \u001B[33m        location: string of device\u001B[39;49;00m\n",
      "    \u001B[33m        backend_name: the backend name or the name of privateuse1, which can be renamed\u001B[39;49;00m\n",
      "    \u001B[33m\u001B[39;49;00m\n",
      "    \u001B[33m    Returns:\u001B[39;49;00m\n",
      "    \u001B[33m        device_index: int\u001B[39;49;00m\n",
      "    \u001B[33m    \"\"\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "        \u001B[94mif\u001B[39;49;00m \u001B[95mnot\u001B[39;49;00m \u001B[96mhasattr\u001B[39;49;00m(torch, backend_name):\u001B[90m\u001B[39;49;00m\n",
      "            \u001B[94mraise\u001B[39;49;00m \u001B[96mRuntimeError\u001B[39;49;00m(\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33mf\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[33mThe \u001B[39;49;00m\u001B[33m{\u001B[39;49;00mbackend_name.upper()\u001B[33m}\u001B[39;49;00m\u001B[33m device module is not registered. \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33m\"\u001B[39;49;00m\u001B[33mIf you are running on a CPU-only machine, \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33m\"\u001B[39;49;00m\u001B[33mplease use torch.load with map_location=torch.device(\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m\u001B[33mcpu\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m\u001B[33m) \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33m\"\u001B[39;49;00m\u001B[33mto map your storages to the CPU.\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "            )\u001B[90m\u001B[39;49;00m\n",
      "        device_module = \u001B[96mgetattr\u001B[39;49;00m(torch, backend_name)\u001B[90m\u001B[39;49;00m\n",
      "        \u001B[94mif\u001B[39;49;00m \u001B[96mhasattr\u001B[39;49;00m(device_module, \u001B[33m\"\u001B[39;49;00m\u001B[33m_utils\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m) \u001B[95mand\u001B[39;49;00m \u001B[96mhasattr\u001B[39;49;00m(\u001B[90m\u001B[39;49;00m\n",
      "            device_module._utils, \u001B[33m\"\u001B[39;49;00m\u001B[33m_get_device_index\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "        ):\u001B[90m\u001B[39;49;00m\n",
      "            device_index = device_module._utils._get_device_index(location, \u001B[94mTrue\u001B[39;49;00m)\u001B[90m\u001B[39;49;00m\n",
      "            device = torch.device(backend_name, device_index)\u001B[90m\u001B[39;49;00m\n",
      "        \u001B[94melse\u001B[39;49;00m:\u001B[90m\u001B[39;49;00m\n",
      "            device = torch.device(location)\u001B[90m\u001B[39;49;00m\n",
      "            device_index = device.index \u001B[94mif\u001B[39;49;00m device.index \u001B[94melse\u001B[39;49;00m \u001B[94m0\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "        \u001B[94mif\u001B[39;49;00m \u001B[96mhasattr\u001B[39;49;00m(device_module, \u001B[33m\"\u001B[39;49;00m\u001B[33mis_available\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m) \u001B[95mand\u001B[39;49;00m \u001B[95mnot\u001B[39;49;00m device_module.is_available():\u001B[90m\u001B[39;49;00m\n",
      ">           \u001B[94mraise\u001B[39;49;00m \u001B[96mRuntimeError\u001B[39;49;00m(\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33mf\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[33mAttempting to deserialize object on a \u001B[39;49;00m\u001B[33m{\u001B[39;49;00mbackend_name.upper()\u001B[33m}\u001B[39;49;00m\u001B[33m \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33mf\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[33mdevice but torch.\u001B[39;49;00m\u001B[33m{\u001B[39;49;00mbackend_name\u001B[33m}\u001B[39;49;00m\u001B[33m.is_available() is False. \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33m\"\u001B[39;49;00m\u001B[33mIf you are running on a CPU-only machine, \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33m\"\u001B[39;49;00m\u001B[33mplease use torch.load with map_location=torch.device(\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m\u001B[33mcpu\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m\u001B[33m) \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33m\"\u001B[39;49;00m\u001B[33mto map your storages to the CPU.\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "            )\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31mE           RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.\u001B[0m\n",
      "\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:605: RuntimeError\n",
      "\u001B[31m\u001B[1m_____________ ERROR at setup of TestMyModel.test_accuracy_medium ______________\u001B[0m\n",
      "\n",
      "cls = <class 'tests.test_mymodel.TestMyModel'>\n",
      "\n",
      "    \u001B[0m\u001B[37m@classmethod\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "    \u001B[94mdef\u001B[39;49;00m \u001B[92msetUpClass\u001B[39;49;00m(\u001B[96mcls\u001B[39;49;00m):\u001B[90m\u001B[39;49;00m\n",
      "    \u001B[90m    \u001B[39;49;00m\u001B[33m\"\"\"Define the functions to be tested here.\"\"\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "        basedir = pathlib.Path(\u001B[91m__file__\u001B[39;49;00m).parent.parent.resolve()\u001B[90m\u001B[39;49;00m\n",
      "        model = MyModel()\u001B[90m\u001B[39;49;00m\n",
      "        model.eval()\u001B[90m\u001B[39;49;00m\n",
      "        model.load_state_dict(\u001B[90m\u001B[39;49;00m\n",
      ">           torch.load(\u001B[96mstr\u001B[39;49;00m(basedir) + \u001B[33m\"\u001B[39;49;00m\u001B[33m/checkpoints/mymodel.pth\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, weights_only=\u001B[94mTrue\u001B[39;49;00m)\u001B[90m\u001B[39;49;00m\n",
      "        )\u001B[90m\u001B[39;49;00m\n",
      "\n",
      "\u001B[1m\u001B[31mtests\\test_mymodel.py\u001B[0m:74: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:1521: in load\n",
      "    \u001B[0m\u001B[94mreturn\u001B[39;49;00m _load(\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:2119: in _load\n",
      "    \u001B[0mresult = unpickler.load()\u001B[90m\u001B[39;49;00m\n",
      "             ^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\_weights_only_unpickler.py\u001B[0m:532: in load\n",
      "    \u001B[0m\u001B[96mself\u001B[39;49;00m.append(\u001B[96mself\u001B[39;49;00m.persistent_load(pid))\u001B[90m\u001B[39;49;00m\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:2083: in persistent_load\n",
      "    \u001B[0mtyped_storage = load_tensor(\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:2049: in load_tensor\n",
      "    \u001B[0mwrap_storage = restore_location(storage, location)\u001B[90m\u001B[39;49;00m\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:698: in default_restore_location\n",
      "    \u001B[0mresult = fn(storage, location)\u001B[90m\u001B[39;49;00m\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:636: in _deserialize\n",
      "    \u001B[0mdevice = _validate_device(location, backend_name)\u001B[90m\u001B[39;49;00m\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001B[90m\u001B[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "location = 'cuda:0', backend_name = 'cuda'\n",
      "\n",
      "    \u001B[0m\u001B[94mdef\u001B[39;49;00m \u001B[92m_validate_device\u001B[39;49;00m(location, backend_name):\u001B[90m\u001B[39;49;00m\n",
      "    \u001B[90m    \u001B[39;49;00m\u001B[33m\"\"\"\u001B[39;49;00m\n",
      "    \u001B[33m    Check whether the device index of specified backend is valid\u001B[39;49;00m\n",
      "    \u001B[33m\u001B[39;49;00m\n",
      "    \u001B[33m    In case of privateuse1 backend, your must first register a device_module for\u001B[39;49;00m\n",
      "    \u001B[33m    privateuse1 using torch._register_device_module. Implement the following\u001B[39;49;00m\n",
      "    \u001B[33m    methods in device_module like cuda: device_module._utils._get_device_index(location, True),\u001B[39;49;00m\n",
      "    \u001B[33m    device_module.device_count().\u001B[39;49;00m\n",
      "    \u001B[33m\u001B[39;49;00m\n",
      "    \u001B[33m    Args:\u001B[39;49;00m\n",
      "    \u001B[33m        location: string of device\u001B[39;49;00m\n",
      "    \u001B[33m        backend_name: the backend name or the name of privateuse1, which can be renamed\u001B[39;49;00m\n",
      "    \u001B[33m\u001B[39;49;00m\n",
      "    \u001B[33m    Returns:\u001B[39;49;00m\n",
      "    \u001B[33m        device_index: int\u001B[39;49;00m\n",
      "    \u001B[33m    \"\"\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "        \u001B[94mif\u001B[39;49;00m \u001B[95mnot\u001B[39;49;00m \u001B[96mhasattr\u001B[39;49;00m(torch, backend_name):\u001B[90m\u001B[39;49;00m\n",
      "            \u001B[94mraise\u001B[39;49;00m \u001B[96mRuntimeError\u001B[39;49;00m(\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33mf\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[33mThe \u001B[39;49;00m\u001B[33m{\u001B[39;49;00mbackend_name.upper()\u001B[33m}\u001B[39;49;00m\u001B[33m device module is not registered. \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33m\"\u001B[39;49;00m\u001B[33mIf you are running on a CPU-only machine, \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33m\"\u001B[39;49;00m\u001B[33mplease use torch.load with map_location=torch.device(\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m\u001B[33mcpu\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m\u001B[33m) \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33m\"\u001B[39;49;00m\u001B[33mto map your storages to the CPU.\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "            )\u001B[90m\u001B[39;49;00m\n",
      "        device_module = \u001B[96mgetattr\u001B[39;49;00m(torch, backend_name)\u001B[90m\u001B[39;49;00m\n",
      "        \u001B[94mif\u001B[39;49;00m \u001B[96mhasattr\u001B[39;49;00m(device_module, \u001B[33m\"\u001B[39;49;00m\u001B[33m_utils\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m) \u001B[95mand\u001B[39;49;00m \u001B[96mhasattr\u001B[39;49;00m(\u001B[90m\u001B[39;49;00m\n",
      "            device_module._utils, \u001B[33m\"\u001B[39;49;00m\u001B[33m_get_device_index\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "        ):\u001B[90m\u001B[39;49;00m\n",
      "            device_index = device_module._utils._get_device_index(location, \u001B[94mTrue\u001B[39;49;00m)\u001B[90m\u001B[39;49;00m\n",
      "            device = torch.device(backend_name, device_index)\u001B[90m\u001B[39;49;00m\n",
      "        \u001B[94melse\u001B[39;49;00m:\u001B[90m\u001B[39;49;00m\n",
      "            device = torch.device(location)\u001B[90m\u001B[39;49;00m\n",
      "            device_index = device.index \u001B[94mif\u001B[39;49;00m device.index \u001B[94melse\u001B[39;49;00m \u001B[94m0\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "        \u001B[94mif\u001B[39;49;00m \u001B[96mhasattr\u001B[39;49;00m(device_module, \u001B[33m\"\u001B[39;49;00m\u001B[33mis_available\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m) \u001B[95mand\u001B[39;49;00m \u001B[95mnot\u001B[39;49;00m device_module.is_available():\u001B[90m\u001B[39;49;00m\n",
      ">           \u001B[94mraise\u001B[39;49;00m \u001B[96mRuntimeError\u001B[39;49;00m(\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33mf\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[33mAttempting to deserialize object on a \u001B[39;49;00m\u001B[33m{\u001B[39;49;00mbackend_name.upper()\u001B[33m}\u001B[39;49;00m\u001B[33m \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33mf\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[33mdevice but torch.\u001B[39;49;00m\u001B[33m{\u001B[39;49;00mbackend_name\u001B[33m}\u001B[39;49;00m\u001B[33m.is_available() is False. \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33m\"\u001B[39;49;00m\u001B[33mIf you are running on a CPU-only machine, \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33m\"\u001B[39;49;00m\u001B[33mplease use torch.load with map_location=torch.device(\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m\u001B[33mcpu\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m\u001B[33m) \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "                \u001B[33m\"\u001B[39;49;00m\u001B[33mto map your storages to the CPU.\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[90m\u001B[39;49;00m\n",
      "            )\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31mE           RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.\u001B[0m\n",
      "\n",
      "\u001B[1m\u001B[31m..\\..\\..\\anaconda3\\envs\\cs7643-a2\\Lib\\site-packages\\torch\\serialization.py\u001B[0m:605: RuntimeError\n",
      "\u001B[36m\u001B[1m=========================== short test summary info ===========================\u001B[0m\n",
      "\u001B[31mERROR\u001B[0m tests/test_mymodel.py::\u001B[1mTestMyModel::test_accuracy_easy\u001B[0m - RuntimeError: Attempting to deserialize object on a CUDA device but torch.c...\n",
      "\u001B[31mERROR\u001B[0m tests/test_mymodel.py::\u001B[1mTestMyModel::test_accuracy_hard\u001B[0m - RuntimeError: Attempting to deserialize object on a CUDA device but torch.c...\n",
      "\u001B[31mERROR\u001B[0m tests/test_mymodel.py::\u001B[1mTestMyModel::test_accuracy_medium\u001B[0m - RuntimeError: Attempting to deserialize object on a CUDA device but torch.c...\n",
      "\u001B[31m============================== \u001B[31m\u001B[1m3 errors\u001B[0m\u001B[31m in 2.75s\u001B[0m\u001B[31m ==============================\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zaXbxcApKPNw",
    "outputId": "4a60cb85-9738-449d-d938-05a73656a5b6",
    "ExecuteTime": {
     "end_time": "2025-09-21T00:29:16.707147Z",
     "start_time": "2025-09-21T00:29:06.124282Z"
    }
   },
   "source": [
    "#Let's test your implementation of Vanilla CNN\n",
    "!pytest -s {GOOGLE_DRIVE_PATH + '/tests/test_vanilla_cnn.py'}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m============================= test session starts =============================\u001B[0m\n",
      "platform win32 -- Python 3.12.0, pytest-8.4.1, pluggy-1.5.0\n",
      "rootdir: C:\\Users\\julie\\CSE_7643_DL\\DL_PS2\\part2-pytorch\n",
      "plugins: anyio-4.7.0\n",
      "collected 1 item\n",
      "\n",
      "tests\\test_vanilla_cnn.py \u001B[32m.\u001B[0m\n",
      "\n",
      "\u001B[32m============================== \u001B[32m\u001B[1m1 passed\u001B[0m\u001B[32m in 9.45s\u001B[0m\u001B[32m ==============================\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D68rtzAZpzgc"
   },
   "source": [
    "# Data Wrangling\n",
    "So far we have worked with well-balanced datasets (samples of each class are\n",
    "evenly distributed). However, in practice, datasets are often not balanced.\n",
    "In this section, you will explore the limitation of standard training strategy\n",
    "on this type of dataset. This being an exploration, it is up to you to design\n",
    "experiments or tests to validate these methods are correct and effective.\n",
    "You will work with an unbalanced version of CIFAR-10 in this section, and you should use the ResNet-32 model in `./models/resnet.py`.\n",
    "\n",
    "## Class-Balanced Focal Loss\n",
    "You will implement one possible solution to the imbalance problem: ClassBalanced Focal Loss using this CVPR-19 paper [Class-Balanced Loss Based on Effective Number of Samples](https://arxiv.org/pdf/1901.05555.pdf). You may also refer to the original paper of [Focal Loss](https://arxiv.org/abs/1708.02002) for more details if you are interested. Please implement CB Focal\n",
    "Loss in `./losses/focal_loss.py`.\n",
    "\n",
    "**Note**: The CVPR-19 paper uses Sigmoid̲ CB focal loss (section 4). Softmax CB focal loss is not described in the paper, but it is easy to derive from the mentioned papers. You must implement the softmax version to pass the\n",
    "tests.\n",
    "\n",
    "Hint: Make sure you are using torch operations througout your focal loss implementation otherwise the torch computation graph will not be built properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FUEYEuHBpzgd"
   },
   "outputs": [],
   "source": [
    "# Test your Focal Loss implementation\n",
    "!pytest -s {GOOGLE_DRIVE_PATH + '/tests/test_focalloss.py'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tidoClnYkFE4"
   },
   "source": [
    "Now, follow the instructions in the report template to obtain the best results possible for Resnet with regular CE loss (you may need to perform extra hyperparameter tuning). Then experiment with the beta parameter. Finally,  obtain the best possible results for Resnet using focal loss. You are welcome to change other hyperparameters in the config file as necessary. Make sure to set the `imbalance` config parameter as appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjZK5lqLFsor"
   },
   "source": [
    "# Submit Your Work\n",
    "After completing the notebook for this assignment (`assignment2_2.ipynb`), run the following cell to create a `.zip` file for you to download and then upload to Gradescope.\n",
    "\n",
    "**Please MANUALLY SAVE `*.py` files before executing the following cell:**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uPREUKv7FwPS",
    "ExecuteTime": {
     "end_time": "2025-09-21T00:36:18.705885Z",
     "start_time": "2025-09-21T00:36:18.639622Z"
    }
   },
   "source": [
    "from cs7643.submit import make_a2_2_submission\n",
    "\n",
    "make_a2_2_submission(GOOGLE_DRIVE_PATH)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing zip file to:  .\\assignment_2_2_submission.zip\n"
     ]
    }
   ],
   "execution_count": 48
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "runtime_attributes": {
    "runtime_version": "2025.07"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
